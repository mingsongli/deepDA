{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No module named 'bayspline'\n",
      ">>  Import package => OKAY\n",
      "\n",
      "petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95\n",
      ">>  Loading configuration file => OKAY\n",
      "\n",
      "['sed_CaCO3', 'atm_pCO2']\n",
      ">>  nc_keyvalue {'biogem': 'fields_biogem_2d'}...\n",
      ">>  biogem: fields_biogem_2d\n",
      ">>  nc_keyvalue {'biogem': 'fields_biogem_3d'}...\n",
      ">>  biogem: fields_biogem_3d\n",
      ">>  Number of 2d prior variables is: 9. List:\n",
      "      ['ocn_sur_temp', 'atm_temp', 'atm_pCO2', 'ocn_sur_sal', 'misc_pH', 'carb_sur_ohm_cal', 'ocn_ben_temp', 'sed_CaCO3', 'ocn_sur_ALK']\n",
      ">>  Number of 3d prior variables is: 0. List:\n",
      "      []\n",
      ">>  Read nc file: /volumes/Backup/DeepDA/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95/_loc_0_proxy_frac_0.95_Rscale_2.0_MC_0.nc\n",
      ">>  Read nc file: /volumes/Backup/DeepDA/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95/_loc_0_proxy_frac_0.95_Rscale_2.0_MC_1.nc\n",
      ">>  Read nc file: /volumes/Backup/DeepDA/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95/_loc_0_proxy_frac_0.95_Rscale_2.0_MC_2.nc\n",
      ">>  Read nc file: /volumes/Backup/DeepDA/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95/_loc_0_proxy_frac_0.95_Rscale_2.0_MC_3.nc\n",
      ">>  Read nc file: /volumes/Backup/DeepDA/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95/_loc_0_proxy_frac_0.95_Rscale_2.0_MC_4.nc\n",
      ">>  Read nc file: /volumes/Backup/DeepDA/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95/_loc_0_proxy_frac_0.95_Rscale_2.0_MC_5.nc\n",
      "First variable: all MC mean\n",
      "[27.448299 27.55855  27.371462 27.37949  27.38793  27.339651]\n",
      "All variable. Mean of variables x reconi\n",
      "[[  27.414231   31.897312]\n",
      " [  23.56266    28.759906]\n",
      " [ 869.176605 1499.046366]\n",
      " [  33.699404   33.643553]\n",
      " [   7.775956    7.588081]\n",
      " [   7.874978    5.983112]\n",
      " [  11.126479   15.995344]\n",
      " [  46.890497   40.70612 ]\n",
      " [   0.002177    0.002125]]\n",
      "\n",
      "Step #1: read data - Done\n",
      "\n",
      "\n",
      "DA - Summary of global mean and standard deviation\n",
      "\n",
      "ocn_sur_temp\n",
      "  _locR 0 proxy_frac 0.95 scaled r 2.0\n",
      "    27.414 ± 0.994: prePETM\n",
      "    31.897 ± 0.819: peakPETM\n",
      "atm_temp\n",
      "  _locR 0 proxy_frac 0.95 scaled r 2.0\n",
      "    23.563 ± 1.159: prePETM\n",
      "    28.760 ± 0.957: peakPETM\n",
      "atm_pCO2\n",
      "  _locR 0 proxy_frac 0.95 scaled r 2.0\n",
      "    869.177 ± 194.166: prePETM\n",
      "    1499.047 ± 177.774: peakPETM\n",
      "ocn_sur_sal\n",
      "  _locR 0 proxy_frac 0.95 scaled r 2.0\n",
      "    33.699 ± 0.016: prePETM\n",
      "    33.644 ± 0.014: peakPETM\n",
      "misc_pH\n",
      "  _locR 0 proxy_frac 0.95 scaled r 2.0\n",
      "    7.776 ± 0.128: prePETM\n",
      "    7.588 ± 0.126: peakPETM\n",
      "carb_sur_ohm_cal\n",
      "  _locR 0 proxy_frac 0.95 scaled r 2.0\n",
      "    7.875 ± 2.361: prePETM\n",
      "    5.983 ± 2.350: peakPETM\n",
      "ocn_ben_temp\n",
      "  _locR 0 proxy_frac 0.95 scaled r 2.0\n",
      "    11.126 ± 1.081: prePETM\n",
      "    15.995 ± 0.890: peakPETM\n",
      "sed_CaCO3\n",
      "  _locR 0 proxy_frac 0.95 scaled r 2.0\n",
      "    46.890 ± 31.980: prePETM\n",
      "    40.706 ± 31.981: peakPETM\n",
      "ocn_sur_ALK\n",
      "  _locR 0 proxy_frac 0.95 scaled r 2.0\n",
      "    0.002 ± 0.000: prePETM\n",
      "    0.002 ± 0.000: peakPETM\n",
      "\n",
      "Step #2: summary - Done\n",
      "\n",
      "DA - Read proxy, prior, and posterior, standardize\n",
      "\n",
      "Read first hdf5 file /volumes/Backup/DeepDA/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95/_loc_0_proxy_frac_0.95_Rscale_2.0_MC_0.hdf5 to get the number of withold datasets.\n",
      " Site withhold length ： 1\n",
      "['prePETMmean', 'prePETMstd', 'peakPETM', 'peakPETMstd']\n",
      "    /volumes/Backup/DeepDA/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95/_loc_0_proxy_frac_0.95_Rscale_2.0_MC_0.nc\n",
      "Site withhold:       ['sq']\n",
      "Proxy        :       ['d18o_morozovella']\n",
      "    /volumes/Backup/DeepDA/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95/_loc_0_proxy_frac_0.95_Rscale_2.0_MC_1.nc\n",
      "Site withhold:       ['sq']\n",
      "Proxy        :       ['d18o_acarinina']\n",
      "    /volumes/Backup/DeepDA/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95/_loc_0_proxy_frac_0.95_Rscale_2.0_MC_2.nc\n",
      "Site withhold:       ['lodo']\n",
      "Proxy        :       ['d18o_morozovella']\n",
      "    /volumes/Backup/DeepDA/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95/_loc_0_proxy_frac_0.95_Rscale_2.0_MC_3.nc\n",
      "Site withhold:       ['Milville']\n",
      "Proxy        :       ['d18o_acarinina']\n",
      "    /volumes/Backup/DeepDA/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95/_loc_0_proxy_frac_0.95_Rscale_2.0_MC_4.nc\n",
      "Site withhold:       ['WL']\n",
      "Proxy        :       ['d18o_acarinina']\n",
      "    /volumes/Backup/DeepDA/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95/_loc_0_proxy_frac_0.95_Rscale_2.0_MC_5.nc\n",
      "Site withhold:       ['BR']\n",
      "Proxy        :       ['d18o_acarinina']\n",
      "\n",
      "Step #3: evaluation data preparation - Done\n",
      "\n",
      "\n",
      "prePETMmean\n",
      "\n",
      "proxy i d18O\n",
      "df_ob_pi_mean d18O -3.0042247915000004\n",
      "df_ob_pi_std  d18O 0.6913532124557944\n",
      "\n",
      "RMSE of Ob vs. Xb nan\n",
      "CE of Ob vs. Xb nan\n",
      "r^2 of Ob vs. Xb --\n",
      "\n",
      "RMSE of Ob vs. Xa nan\n",
      "CE of Ob vs. Xb nan\n",
      "r^2 of Ob vs. Xa --\n",
      " --- \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../DeepDA_lib/DeepDA_psm.py:791: RuntimeWarning: Mean of empty slice\n",
      "  return np.sqrt(np.nanmean((predictions - targets) ** 2))\n",
      "../DeepDA_lib/DeepDA_psm.py:782: RuntimeWarning: Mean of empty slice\n",
      "  denom = np.nansum( np.power(data - np.nanmean(data, axis=0), 2), axis = 0 )\n",
      "../DeepDA_lib/DeepDA_psm.py:783: RuntimeWarning: invalid value encountered in true_divide\n",
      "  CE = 1. - np.divide(numer, denom)\n",
      "/Users/mingsongli/miniconda3/envs/deepda/lib/python3.6/site-packages/numpy/ma/core.py:5244: RuntimeWarning: Mean of empty slice.\n",
      "  dtype=dtype, **kwargs)[()]\n",
      "/Users/mingsongli/miniconda3/envs/deepda/lib/python3.6/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "attributes of masked are not writeable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-aeb427bd9d60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                                                   \u001b[0;34m'R^2 Xb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr_2_xb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                                   \u001b[0;34m'R^2 Xa'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr_2_xa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                                   'dR^2':dr2}, index=[df_ind_i])\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m                     \u001b[0mdf_evaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_evaluation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_reconi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepda/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepda/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepda/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             val = sanitize_array(\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             )\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepda/lib/python3.6/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_upcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoften_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# set hardmask False if it was True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepda/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36msoften_mask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3568\u001b[0m         \"\"\"\n\u001b[0;32m-> 3569\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hardmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3570\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepda/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, attr, value)\u001b[0m\n\u001b[1;32m   6536\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__singleton\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6537\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 6538\u001b[0;31m                 f\"attributes of {self!r} are not writeable\")\n\u001b[0m\u001b[1;32m   6539\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6540\u001b[0m             \u001b[0;31m# duplicate instance - we can end up here from __array_finalize__,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: attributes of masked are not writeable"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DeepDA_verify is to verify DA output\n",
    "\n",
    "It read proxy, prior, and posterior from DA outputs files and configuration files.\n",
    "Then, it calculates the statistics (corrcoef and CE) of the DA results and save the outputs.\n",
    "\n",
    "By Mingsong Li\n",
    "    Penn State \n",
    "    Now at Peking University\n",
    "    2/17/2020\n",
    "    \n",
    "Updated Mar. 03, 2020\n",
    "Updated Oct. 11, 2020  # plot enhanced\n",
    "Updated Oct. 12, 2020  # multi jobs\n",
    "Updated June 30, 2021 \n",
    "Updated July 15, 2021  # ZSCORE\n",
    "\n",
    "#df_ob_pi   = df_ob[df_eval['proxy'] == proxy_i]   : only work for single proxy experiment\n",
    "'''\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from DeepDA_lib import modules_nc\n",
    "from DeepDA_lib import DeepDA_psm\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "import h5py\n",
    "#import time\n",
    "import yaml\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "from sys import platform as sys_pf\n",
    "import matplotlib.pyplot as plt\n",
    "if sys_pf == 'darwin':\n",
    "    import matplotlib\n",
    "    matplotlib.use(\"TkAgg\")\n",
    "    import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "try:\n",
    "    import bayspline\n",
    "except ImportError as e1:\n",
    "    print('Warning:', e1)\n",
    "try:\n",
    "    import bayspar\n",
    "except ImportError as e2:\n",
    "    print('Warning:', e2)\n",
    "try:\n",
    "    import bayfox\n",
    "except ImportError as e3:\n",
    "    print('Warning:', e3)\n",
    "try:\n",
    "    import baymag\n",
    "except ImportError as e4:\n",
    "    print('Warning:', e4)\n",
    "\n",
    "print('>>  Import package => OKAY')\n",
    "print('')\n",
    "\n",
    "###################################################################\n",
    "#####################    User defined start   #####################\n",
    "###################################################################\n",
    "\n",
    "# DA output folders\n",
    "if sys_pf == 'darwin':\n",
    "    xlsxdir = '/volumes/DA/DeepDA/wrk/'\n",
    "    xlsxdir = '/volumes/Backup/DeepDA/'\n",
    "else:\n",
    "    xlsxdir = '/mnt/d/DeepDA/wrk/'\n",
    "\n",
    "# Experiment style: \n",
    "#    0 = given lsit\n",
    "#    1 = all folders\n",
    "#    \n",
    "expstyle = 0\n",
    "#expstyle = 1\n",
    "\n",
    "# needed when explist style is 0\n",
    "#explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210630_all_bays_MCsd100_pHcor_omega5_frac0.7']\n",
    "explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95']  # 1 unselected proxy\n",
    "Typelist = ['d18O']\n",
    "#explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_caco3_bays_MCsd100_pHcor_omega5_frac0.95'] #\n",
    "#Typelist = ['caco3']\n",
    "#explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_tex_bays_MCsd100_pHcor_omega5_frac0.95']\n",
    "#Typelist = ['TEX86'] \n",
    "#explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_mgca_bays_MCsd100_pHcor_omega5_frac0.95']\n",
    "#Typelist = ['MgCa']\n",
    "\n",
    "label_all = ('prePETM', 'peakPETM','postPETM', 'PETM_body')  # slice name\n",
    "warmcomp = [0,1]  # ID for petm warming \n",
    "#Typelist = ['d18O','TEX86','MgCa','caco3']  # proxy type list\n",
    "\n",
    "pn = len(Typelist)\n",
    "dum_jmax = 36\n",
    "dum_imax = 36\n",
    "\n",
    "AnalysisStd = True   # True: standardize; False: use raw analysis data\n",
    "\n",
    "# output\n",
    "savesummary = True\n",
    "savesummary_slice=  False\n",
    "# for evaluation save and plot\n",
    "showplot = False\n",
    "\n",
    "#pn = 4  # use the first pn data\n",
    "\n",
    "axis_lim = np.array([[-6,1],[0,1],[0,7],[0,100]])   # axis limit for the plot\n",
    "axis_limz = np.array([-4,4])   # set axis limit for the zscore plot\n",
    "\n",
    "###################################################################\n",
    "#####################    User defined end     #####################\n",
    "###################################################################\n",
    "label_all_len = len(label_all)\n",
    "\n",
    "if expstyle == 0:\n",
    "    explist = explist\n",
    "    \n",
    "elif expstyle == 1:\n",
    "    # read content\n",
    "    dir1 = [o for o in os.listdir(xlsxdir) if os.path.isdir(os.path.join(xlsxdir,o))]\n",
    "    explist = dir1\n",
    "    #print(dir1[0])\n",
    "\n",
    "for diri in range(len(explist)):\n",
    "    \n",
    "    # run the first 5 folders\n",
    "    #if diri < 5:\n",
    "    #    continue\n",
    "    en = explist[diri]\n",
    "    print(en)\n",
    "\n",
    "    dum_ijmax = dum_imax * dum_jmax\n",
    "    config_name_f = \"../DeepDA_config.yml\"\n",
    "    f = open(config_name_f, 'r')\n",
    "    yml_dict_f = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    f.close()\n",
    "\n",
    "    dir_data_save = yml_dict_f['core']['wrkdir']\n",
    "\n",
    "    config_name = dir_data_save + '/' + en + '.yml'\n",
    "    f = open(config_name, 'r')\n",
    "    yml_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    f.close()\n",
    "    print('>>  Loading configuration file => OKAY')\n",
    "    print('')\n",
    "    # Read parameters from configurations\n",
    "    #MCn = yml_dict['MonteCarlo']['number']\n",
    "    MCn = 6\n",
    "    log_level = 2\n",
    "    nens = yml_dict['core']['nens']\n",
    "\n",
    "    nexp = yml_dict['core']['nexp']\n",
    "    dir_data_save = yml_dict['core']['wrkdir']\n",
    "    log_level = yml_dict['log_level']\n",
    "    recon_period = yml_dict['core']['recon_period']\n",
    "    recon_timescale = yml_dict['core']['recon_timescale_interval']\n",
    "    recon_period_full = np.arange(recon_period[0],recon_period[1]+1,recon_timescale)\n",
    "    recon_period_len = recon_period_full.shape[0]\n",
    "    recon_timescale = yml_dict['core']['recon_timescale_interval']\n",
    "    save_ens_full = yml_dict['core']['save_ens_full']\n",
    "    proxy_assim2 = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_assim2']\n",
    "    proxy_psm_type    = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_psm_type']\n",
    "    proxy_blacklist   = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_blacklist']\n",
    "    proxy_order       = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_order']\n",
    "    proxy_list = [item for item in proxy_order if item not in proxy_blacklist]\n",
    "    proxy_err_eval   = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_err_eval']\n",
    "    lon_label = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['lon_label']\n",
    "    lat_label = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['lat_label']\n",
    "\n",
    "    proxy_frac      = yml_dict['proxies']['proxy_frac']\n",
    "    prior_source = yml_dict['prior']['prior_source'] #\n",
    "    dum_lon_offset = yml_dict['prior'][prior_source]['dum_lon_offset'] # longitude offset\n",
    "    limit_hard_keys = list(yml_dict['prior'][prior_source]['limit_hard'].keys())\n",
    "    psm_baymag_ln =  yml_dict['psm']['bayesreg_mgca_pooled_red']['psm_baymag_ln']\n",
    "    print(limit_hard_keys)\n",
    "\n",
    "    data_period_id    = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['data_period_id']\n",
    "    data_period_idstd = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['data_period_idstd']\n",
    "    geologic_age = yml_dict['core']['geologic_age']\n",
    "\n",
    "    # read preprior HDF5 file\n",
    "    dir_proxy_data = dir_data_save +'/'+ yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['dbversion']\n",
    "    proxy_err_eval = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_err_eval']\n",
    "\n",
    "    # ========= dataset for plot =========\n",
    "    cGENIEGrid = yml_dict['core']['proj_dir'] + '/data_misc/cGENIEGrid.csv'\n",
    "    cGENIEGrid = pandas.read_csv(cGENIEGrid)\n",
    "    cGENIEGridB_lat36 = cGENIEGrid['lat']\n",
    "    cGENIEGridB_lon36 = cGENIEGrid['lon']\n",
    "    cGENIEGrid = cGENIEGrid.to_numpy()\n",
    "    #print('>>  OKAY.')\n",
    "\n",
    "    # Read global mean and plot to show results\n",
    "    ########## Prior #########\n",
    "    prior_state_variable = yml_dict['prior'][prior_source]['state_variable']  # note: ['2d': xxx; '3d': xxx]\n",
    "    dum_lon_offset = yml_dict['prior'][prior_source]['dum_lon_offset'] # longitude offset\n",
    "    \n",
    "    # ========= Monte Carlo =========\n",
    "    local_rad_list = yml_dict['core']['local_rad_list'] #\n",
    "    locRadn= len(local_rad_list)\n",
    "    local_rad_list = np.asarray(local_rad_list)\n",
    "    #print(local_rad_list)\n",
    "    #print(locRadn)\n",
    "    proxy_frac_list   = yml_dict['proxies']['proxy_frac']\n",
    "    proxy_fracn = len(proxy_frac_list)\n",
    "    proxy_frac_list = np.asarray(proxy_frac_list)\n",
    "    Rscale_style = yml_dict['core']['Rscale_style']\n",
    "    \n",
    "    if Rscale_style == 1:\n",
    "        Rscale_list = yml_dict['core']['Rscale']\n",
    "        Rscalen = len(Rscale_list)\n",
    "        Rscale_list = np.asarray(Rscale_list)\n",
    "        \n",
    "        # debug\n",
    "        Rscale_list = np.array([2.0,1.0])\n",
    "        Rscalen = len(Rscale_list)\n",
    "        \n",
    "    elif Rscale_style == 2:\n",
    "        Rscalen = 1\n",
    "        Rscale_list = [0]\n",
    "    # save prior variable list\n",
    "    prior_variable_dict = []  # variable list\n",
    "    prior_nc_file_list = []  # nc file list\n",
    "    prior_variable_dict_3d = []  # variable list\n",
    "    prior_nc_file_list_3d = []  # nc file list\n",
    "\n",
    "    for key, value in prior_state_variable.items():\n",
    "        nc_keyvalue = prior_state_variable[key]['ncname']  # note: 2d dict\n",
    "        print('>>  nc_keyvalue {}...'.format(nc_keyvalue))\n",
    "        for key1, value1 in nc_keyvalue.items():\n",
    "            print('>>  {}: {}'.format(key1,value1))\n",
    "            for i in range(len(prior_state_variable[key][value1])):\n",
    "                if key in ['2d']:\n",
    "                    prior_variable_dict.append(prior_state_variable[key][value1][i])\n",
    "                    prior_nc_file_list.append(key1+'/'+value1+'.nc')\n",
    "                elif key in ['3d']:\n",
    "                    prior_variable_dict_3d.append(prior_state_variable[key][value1][i])\n",
    "                    prior_nc_file_list_3d.append(key1+'/'+value1+'.nc')\n",
    "\n",
    "    # variable list\n",
    "    prior_variable_len = len(prior_variable_dict)\n",
    "    prior_variable3d_len = len(prior_variable_dict_3d)\n",
    "    print('>>  Number of 2d prior variables is: {}. List:'.format(prior_variable_len))\n",
    "    print('      {}'.format(prior_variable_dict))\n",
    "    print('>>  Number of 3d prior variables is: {}. List:'.format(prior_variable3d_len))\n",
    "    print('      {}'.format(prior_variable_dict_3d))\n",
    "\n",
    "    MC_dir =  dir_data_save + '/' + en + '/'\n",
    "\n",
    "    Xa2d_full_np   = np.full((locRadn,proxy_fracn,Rscalen,MCn*nens,prior_variable_len,recon_period_len),np.nan)  # save mean of each variable (column) of each MC run (row)\n",
    "    Xa2d_mean_np   = np.full((locRadn,proxy_fracn,Rscalen,MCn,prior_variable_len,recon_period_len),np.nan)  # save mean of each variable (column) of each MC run (row)\n",
    "    Xa2d_std_np    = np.full((locRadn,proxy_fracn,Rscalen,MCn,prior_variable_len,recon_period_len),np.nan)  # save mean of each variable (column) of each MC run (row)\n",
    "    Xa2d_all_np    = np.full((dum_jmax, dum_imax,locRadn,proxy_fracn,Rscalen,MCn, prior_variable_len, recon_period_len),np.nan)  # save mean of each variable (column) of each MC run (row)\n",
    "    Xa2d_allstd_np = np.full((dum_jmax, dum_imax, locRadn,proxy_fracn,Rscalen,MCn, prior_variable_len, recon_period_len),np.nan)  # save mean of each variable (column) of each MC run (row)\n",
    "    Xa2d_mean_np2  = np.full((locRadn,proxy_fracn,Rscalen,prior_variable_len,recon_period_len),np.nan)  # save mean of each variable (column) of each MC run (row)\n",
    "    Xa2d_std_np2   = np.full((locRadn,proxy_fracn,Rscalen,prior_variable_len,recon_period_len),np.nan)  # save mean of each variable (column) of each MC run (row)\n",
    "    df_evaluation  = pandas.DataFrame()\n",
    "    df_zscore_all  = pandas.DataFrame()\n",
    "    for locRadi in range(locRadn):\n",
    "        locRad = local_rad_list[locRadi]\n",
    "        if locRad is None:\n",
    "            locRadv = 0 # for filename only\n",
    "        else:\n",
    "            locRadv = locRad\n",
    "        for proxy_fraci in range(proxy_fracn):\n",
    "            proxy_frac = proxy_frac_list[proxy_fraci]\n",
    "\n",
    "            for Rscalei in range(Rscalen):\n",
    "                Rscale = Rscale_list[Rscalei]\n",
    "                \n",
    "                savefilename_add = '_loc_'+ str(locRadv)+'_proxy_frac_'+ str(proxy_frac)+'_Rscale_'+str(Rscale)\n",
    "                \n",
    "                for MCi in range(MCn):\n",
    "                    # NetCDF file name\n",
    "                    filename_short = '_loc_', str(locRadv),'_proxy_frac_', str(proxy_frac),'_Rscale_',str(Rscale),'_MC_',str(MCi) \n",
    "                    nc_filename = MC_dir + ''.join(filename_short) + '.nc'\n",
    "                    hdf5name    = MC_dir + ''.join(filename_short) + '.hdf5'\n",
    "\n",
    "                    print('>>  Read nc file: {}'.format(nc_filename))\n",
    "                    \n",
    "                    for Xa2d_vari in range(prior_variable_len):\n",
    "                        \n",
    "                        Xa_full_name_vari = prior_variable_dict[Xa2d_vari] +'_Xa_full'\n",
    "                        Xa_mean_name_vari = prior_variable_dict[Xa2d_vari] +'_Xa_mean'\n",
    "                        Xa_variance_name_vari = prior_variable_dict[Xa2d_vari] +'_Xa_variance'\n",
    "                        Xa_full_vari = Dataset(nc_filename).variables[Xa_full_name_vari][:]\n",
    "                        Xa_mean_vari = Dataset(nc_filename).variables[Xa_mean_name_vari][:]\n",
    "                        Xa_variance_vari = Dataset(nc_filename).variables[Xa_variance_name_vari][:]\n",
    "\n",
    "                        if prior_variable_dict[Xa2d_vari] in limit_hard_keys:\n",
    "                            # some variables have hard limitation: e.g., CaCO3 = [0, 100]                        \n",
    "                            lim_min = yml_dict['prior'][prior_source]['limit_hard'][prior_variable_dict[Xa2d_vari]]['lim_min']\n",
    "                            lim_max = yml_dict['prior'][prior_source]['limit_hard'][prior_variable_dict[Xa2d_vari]]['lim_max']\n",
    "                            #print('limit min {} and max {}'.format(lim_min, lim_max))\n",
    "                            if lim_min:\n",
    "                                if np.any(Xa_full_vari<lim_min):\n",
    "                                    Xa_full_vari[Xa_full_vari<lim_min] = lim_min\n",
    "                                    Xa_mean_vari = np.mean(Xa_full_vari,axis=2)\n",
    "                                    Xa_variance_vari = np.var(Xa_full_vari,axis=2)\n",
    "                                    print('>>    Force {} value to be >= {}'.format(prior_variable_dict[Xa2d_vari],lim_min))\n",
    "                            if lim_max:\n",
    "                                if np.any(Xa_full_vari>lim_max):\n",
    "                                    Xa_full_vari[Xa_full_vari>lim_max] = lim_max\n",
    "                                    Xa_mean_vari = np.mean(Xa_full_vari,axis=2)\n",
    "                                    Xa_variance_vari = np.var(Xa_full_vari,axis=2)\n",
    "                                    print('>>    Force {} value to be <= {}'.format(prior_variable_dict[Xa2d_vari], lim_max))\n",
    "\n",
    "                        for reconi in range(recon_period_len):\n",
    "\n",
    "                            Xa_full_reconi = Xa_full_vari[:,:,:,0,reconi].reshape((dum_ijmax,nens))\n",
    "                            Xa_full_reconi_mean = np.nanmean(Xa_full_reconi,axis=0)\n",
    "\n",
    "                            Xa_mean_reconi = Xa_mean_vari[:,:,0,reconi]\n",
    "                            Xa2d_all_np[:,:,locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = np.copy(Xa_mean_vari[:,:,0,reconi])\n",
    "                            Xa_mean_reconi_mean = np.nanmean(Xa_mean_reconi)\n",
    "\n",
    "                            Xa_variance_reconi = Xa_variance_vari[:,:,0,reconi]\n",
    "                            Xa2d_allstd_np[:,:,locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = Xa_variance_vari[:,:,0,reconi]\n",
    "                            Xa_std_reconi_mean = np.sqrt(np.nanmean(Xa_variance_reconi))\n",
    "\n",
    "                            #print('>>  reconi = {}, mean is {}, std is {}'.format(reconi, Xa_mean_reconi_mean, Xa_std_reconi_mean))\n",
    "                            Xa2d_full_np[locRadi,proxy_fraci,Rscalei,MCi*nens:(MCi+1)*nens,Xa2d_vari,reconi] = Xa_full_reconi_mean\n",
    "                            Xa2d_mean_np[locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = Xa_mean_reconi_mean\n",
    "                            Xa2d_std_np[locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = Xa_std_reconi_mean\n",
    "                print('First variable: all MC mean')\n",
    "                print(Xa2d_mean_np[locRadi,proxy_fraci,Rscalei,:,0,0])\n",
    "\n",
    "                Xa2d_all_np = np.ma.masked_where(Xa2d_all_np > 9.0e+36, Xa2d_all_np)\n",
    "                Xa2d_allstd_np = np.ma.masked_where(Xa2d_all_np > 9.0e+36, Xa2d_allstd_np)\n",
    "                for Xa2d_vari in range(prior_variable_len):\n",
    "                    for reconi in range(recon_period_len):\n",
    "                        Xa2d_mean_np2[locRadi,proxy_fraci,Rscalei,Xa2d_vari,reconi] = np.nanmean(Xa2d_all_np[:,:,locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi])\n",
    "                        Xa2d_std_np2[locRadi,proxy_fraci,Rscalei,Xa2d_vari,reconi] = np.sqrt(np.nanmean(Xa2d_allstd_np[:,:,locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi]))\n",
    "\n",
    "                np.set_printoptions(precision=6, suppress=True)\n",
    "                if log_level > 1:\n",
    "                    print('All variable. Mean of variables x reconi')\n",
    "                    print('{}'.format(Xa2d_mean_np2[locRadi,proxy_fraci,Rscalei,:,:]))\n",
    "                #print('std  of variables x reconi')\n",
    "                #print('{}'.format(Xa2d_std_np2))\n",
    "    \n",
    "                print('')\n",
    "                print('Step #1: read data - Done')\n",
    "                print('')\n",
    "\n",
    "                # Calculate mean and std of each variable for each time slice\n",
    "                # plot the ensemble values\n",
    "\n",
    "                df = pandas.DataFrame()\n",
    "                print('')\n",
    "                print('DA - Summary of global mean and standard deviation')\n",
    "                print('')\n",
    "                \n",
    "                if showplot:\n",
    "                    fig, (ax0, ax1, ax2, ax3) = plt.subplots(nrows=4, figsize=(3, 6))\n",
    "                    if recon_period_len>1:\n",
    "                        fig2, (ax10, ax11, ax12, ax13) = plt.subplots(nrows=4, figsize=(3, 6))\n",
    "                    params = {'mathtext.default': 'regular' }\n",
    "                    plt.rcParams.update(params)\n",
    "                    #plt.rcParams.update({'figure.figsize':(5,3), 'figure.dpi':110})\n",
    "                    #fig.suptitle('DA')\n",
    "\n",
    "                # 2d variables\n",
    "                for Xa2d_vari in range(prior_variable_len):\n",
    "\n",
    "                    print(prior_variable_dict[Xa2d_vari])\n",
    "                    datadf = {'field':prior_variable_dict[Xa2d_vari],'mean':[np.nan],'std':[np.nan],\n",
    "                              '2.5%':[np.nan],'5%':[np.nan],'25%':[np.nan],'median':[np.nan],'75%':[np.nan],'95%':[np.nan],'97.5%':[np.nan],'label':''}\n",
    "                    df2 = pandas.DataFrame(datadf, index=[Xa2d_vari])\n",
    "                    df = pandas.concat([df,df2])\n",
    "\n",
    "                    sst_std_mc = np.std(Xa2d_mean_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,:],axis=0)\n",
    "                    if log_level > 2:\n",
    "                        print('  _locR '+str(locRadv)+' proxy_frac '+str(proxy_frac)+' scaled r '+str(Rscale))\n",
    "\n",
    "                    for reconi in range(recon_period_len):\n",
    "\n",
    "                        meani = np.nanmean(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi])\n",
    "                        stdi = np.std(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi])\n",
    "                        perc = np.percentile(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi],np.array([2.5, 5, 25, 50, 75, 95, 97.5]))\n",
    "                        datadf = {'field':'','mean':[meani],'std':[stdi],\n",
    "                                  '2.5%':[perc[0]],'5%':[perc[1]],'25%':[perc[2]],'median':[perc[3]],'75%':[perc[4]],'95%':[perc[5]],'97.5%':[perc[6]],'label':label_all[reconi]}\n",
    "                        df2 = pandas.DataFrame(data = datadf, index=[Xa2d_vari])\n",
    "                        df = pandas.concat([df,df2])\n",
    "                        if log_level > 2:\n",
    "                            print('    {:.3f} ± {:.3f}: {}'.format(meani, stdi, label_all[reconi]))\n",
    "\n",
    "                        if recon_period_len>2:\n",
    "                            warmpeak = Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,1]-Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,0]\n",
    "                            #warmbody = Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,2]-Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,0]\n",
    "                            coolpeak = Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,2]-Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,1]\n",
    "                            warmpeakmean = np.nanmean(warmpeak)\n",
    "                            warmpeakstd  = np.std(warmpeak)\n",
    "                            warmperc = np.percentile(warmpeak,np.array([2.5, 5, 25, 50, 75, 95, 97.5]))\n",
    "                            coolpeakmean = np.nanmean(coolpeak)\n",
    "                            coolpeakstd  = np.std(coolpeak)\n",
    "                            coolperc = np.percentile(coolpeak,np.array([2.5, 5, 25, 50, 75, 95, 97.5]))\n",
    "\n",
    "                    if recon_period_len>2:\n",
    "                        df2 = pandas.DataFrame({'field':'','mean':[warmpeakmean],'std':[warmpeakstd],\n",
    "                                                '2.5%':[warmperc[0]],'5%':[warmperc[1]],'25%':[warmperc[2]],'median':[warmperc[3]],'75%':[warmperc[4]],'95%':[warmperc[5]],'97.5%':[warmperc[6]],'label':'Peak_warming'}, index=[Xa2d_vari])\n",
    "                        df3 = pandas.DataFrame({'field':'','mean':[coolpeakmean],'std':[coolpeakstd],\n",
    "                                                '2.5%':[coolperc[0]],'5%':[coolperc[1]],'25%':[coolperc[2]],'median':[coolperc[3]],'75%':[coolperc[4]],'95%':[coolperc[5]],'97.5%':[coolperc[6]],'label':'Peak_cooling'}, index=[Xa2d_vari])\n",
    "                        df = pandas.concat([df,df2,df3])\n",
    "                        if log_level > 2:\n",
    "                            print('    {:.6f} ± {:.6f}: peak warming'.format(warmpeakmean,warmpeakstd))\n",
    "                            print('    {:.6f} ± {:.6f}: peak cooling'.format(coolpeakmean,coolpeakstd))\n",
    "\n",
    "                    if showplot:\n",
    "                        for reconi in range(recon_period_len):\n",
    "                            if reconi == 3:\n",
    "                                continue\n",
    "                            kwargs = dict(alpha=0.5, bins=50)\n",
    "\n",
    "                            if Xa2d_vari == 0:\n",
    "                                ax0.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                                ax0.set_ylabel('#')\n",
    "                                ax0.set_xlabel('SST (\\u00B0C)')\n",
    "                                ax0.tick_params(labelsize='small')\n",
    "                                ax0.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                            if Xa2d_vari == 1:\n",
    "                                ax1.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                                ax1.set_ylabel('#')\n",
    "                                ax1.set_xlabel('SAT (\\u00B0C)')\n",
    "                                ax1.tick_params(labelsize='small')\n",
    "                                ax1.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                            if Xa2d_vari == 2:\n",
    "                                ax2.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                                ax2.set_ylabel('#')\n",
    "                                ax2.set_xlabel('$\\it{p}$CO$_2$ (ppm)')\n",
    "                                ax2.set_xlim(0, 2800)\n",
    "                                ax2.legend(prop={'size': 6.5})  \n",
    "                                ax2.tick_params(labelsize='small')\n",
    "                                ax2.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                            #if Xa2d_vari == 3:\n",
    "                            #    ax3.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                            #    ax3.set_ylabel('Number')\n",
    "                            #    ax3.set_xlabel('Salinity (PSU)')\n",
    "                            if Xa2d_vari == 4:\n",
    "                                ax3.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                                ax3.set_ylabel('#')\n",
    "                                ax3.set_xlabel('pH')     \n",
    "                                ax3.tick_params(labelsize='small')\n",
    "                                ax3.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                            #if Xa2d_vari == 6:\n",
    "                            #    ax5.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                            #    ax5.set_ylabel('Number')\n",
    "                            #    ax5.set_xlabel('$CaCO_3$ (%)')\n",
    "                        fig.tight_layout()\n",
    "\n",
    "                        if recon_period_len>1:\n",
    "                            if Xa2d_vari == 0:                    \n",
    "                                ax10.hist(warmpeak, **kwargs, color = \"#ff7f0e\", label = 'warming')\n",
    "                                ax10.hist(coolpeak, **kwargs, color = \"#2ca02c\", label = 'cooling')\n",
    "                                ax10.set_ylabel('#')\n",
    "                                ax10.set_xlabel('\\u0394SST (\\u00B0C)')                        \n",
    "                                ax10.legend(prop={'size': 6.5});\n",
    "                                ax10.tick_params(labelsize='small')\n",
    "                                ax10.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                            if Xa2d_vari == 1:\n",
    "                                ax11.hist(warmpeak, **kwargs, color = \"#ff7f0e\")\n",
    "                                ax11.hist(coolpeak, **kwargs, color = \"#2ca02c\")\n",
    "                                ax11.set_ylabel('#')\n",
    "                                ax11.set_xlabel('\\u0394SAT (\\u00B0C)')\n",
    "                                ax11.tick_params(labelsize='small')\n",
    "                                ax11.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                            if Xa2d_vari == 2:\n",
    "                                ax12.hist(warmpeak, **kwargs, color = \"#ff7f0e\")\n",
    "                                ax12.hist(coolpeak, **kwargs, color = \"#2ca02c\")\n",
    "                                ax12.set_ylabel('#')\n",
    "                                ax12.set_xlabel('\\u0394$\\it{p}$CO$_2$ (ppm)')\n",
    "                                ax12.tick_params(labelsize='small')\n",
    "                                ax12.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                            if Xa2d_vari == 4:\n",
    "                                ax13.hist(warmpeak, **kwargs, color = \"#ff7f0e\")\n",
    "                                ax13.hist(coolpeak, **kwargs, color = \"#2ca02c\")\n",
    "                                ax13.set_ylabel('#')\n",
    "                                ax13.set_xlabel('\\u0394pH')\n",
    "                                ax13.tick_params(labelsize='small')\n",
    "                                ax13.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                            fig2.tight_layout()\n",
    "\n",
    "                if showplot:\n",
    "                    fig.savefig(yml_dict['core']['proj_dir']+'/wrk/'+en+'.summary.pdf')\n",
    "                    if recon_period_len > 1:\n",
    "                        fig2.savefig(yml_dict['core']['proj_dir']+'/wrk/'+en+'.delta.pdf')\n",
    "            \n",
    "                # print and save excel\n",
    "                if savesummary_slice:\n",
    "                    print('saved @')\n",
    "                    fullname = yml_dict['core']['proj_dir']+'/wrk/'+en+savefilename_add+'.summary.csv'\n",
    "                    print(fullname)\n",
    "                    df.to_csv(fullname)\n",
    "\n",
    "                print('')\n",
    "                print('Step #2: summary - Done')\n",
    "                print('')\n",
    "    \n",
    "\n",
    "\n",
    "                ### Purpose of this block\n",
    "                # Prepare data for verification\n",
    "                #\n",
    "                ### Steps\n",
    "                # 1. Prepare matrix for data saving: proxy, prior, posterior; std or not\n",
    "                # 2. calculate and save each Monte Carlo runs\n",
    "\n",
    "                #####################    User defined start   #####################\n",
    "                if log_level > 1:\n",
    "                    print('DA - Read proxy, prior, and posterior, standardize')\n",
    "                    print('')\n",
    "                #####################    User defined end     #####################\n",
    "\n",
    "                df_eval = pandas.DataFrame()\n",
    "                df_ob   = pandas.DataFrame()\n",
    "                df_xb   = pandas.DataFrame()\n",
    "                df_xa   = pandas.DataFrame()\n",
    "                \n",
    "                # Get the sites_withhold_len\n",
    "                \n",
    "                #locRad = local_rad_list[0]\n",
    "                #if locRad is None:\n",
    "                #    locRadv = 0 # for filename only\n",
    "                #else:\n",
    "                #    locRadv = locRad\n",
    "\n",
    "                #proxy_frac = proxy_frac_list[0]\n",
    "                #Rscale = Rscale_list[0]\n",
    "                filename_short = '_loc_', str(locRadv),'_proxy_frac_', str(proxy_frac),'_Rscale_',str(Rscale),'_MC_0.hdf5'\n",
    "                hdf5name = MC_dir + ''.join(filename_short)\n",
    "                if log_level > 1:\n",
    "                    print('Read first hdf5 file {} to get the number of withold datasets.'.format(hdf5name))\n",
    "                sites_eval = pandas.read_hdf(hdf5name, 'sites_eval')\n",
    "                sites_withhold_len  = len(sites_eval)\n",
    "                if log_level > 1:\n",
    "                    print(' Site withhold length ： {}'.format(sites_withhold_len))\n",
    "\n",
    "                data_psm_d18o_find = 0\n",
    "                data_psm_mgca_find = 0\n",
    "                if 'Marine sediments_mgca_pooled_bcp' in proxy_list or 'Marine sediments_mgca_pooled_red' in proxy_list:\n",
    "                    data_psm_mgca_find = 1\n",
    "\n",
    "                if 'Marine sediments_d18o_pooled' in proxy_list:\n",
    "                    data_psm_d18o_find = 1\n",
    "\n",
    "                # Prepare empty matrix for saving the data of proxy, prior, and posterior\n",
    "                ob_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, recon_period_len*2, sites_withhold_len), np.nan)\n",
    "                xb_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, sites_withhold_len), np.nan)   # save full prior for withhold data\n",
    "                xa_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, recon_period_len, sites_withhold_len), np.nan)\n",
    "\n",
    "                df_ind = 0\n",
    "\n",
    "                # columns name for the observation\n",
    "                df_ind_recon = []\n",
    "\n",
    "                for reconi in range(recon_period_len):\n",
    "                    df_ind_recon_i = [data_period_id[reconi]] + [data_period_idstd[reconi]]\n",
    "                    df_ind_recon = df_ind_recon + df_ind_recon_i\n",
    "\n",
    "                if log_level > 2:\n",
    "                    print(df_ind_recon)\n",
    "\n",
    "\n",
    "                for MCi in range(MCn):\n",
    "                #for MCi in range(1):\n",
    "                    # NetCDF file name\n",
    "                    filename_short = '_loc_', str(locRadv),'_proxy_frac_', str(proxy_frac),'_Rscale_',str(Rscale),'_MC_' + str(MCi)\n",
    "                    nc_filename = MC_dir + ''.join(filename_short) + '.nc'\n",
    "                    print('    {}'.format(nc_filename))\n",
    "                    hdf5name    = MC_dir + ''.join(filename_short) + '.hdf5'\n",
    "\n",
    "                    if data_psm_mgca_find == 1:\n",
    "                        with h5py.File(hdf5name, 'r') as f:\n",
    "                            Xb_sal = np.copy(f.get('Xb_sal'))\n",
    "                            if log_level > 3:\n",
    "                                print(Xb_sal.shape)\n",
    "                            Xb_omega = np.copy((f.get('Xb_omega')))\n",
    "                            Xb_ph = np.copy(f.get('Xb_ph'))\n",
    "                        Xa_sal_full = Dataset(nc_filename).variables['ocn_sur_sal_Xa_full']\n",
    "                        Xa_ph_full  = Dataset(nc_filename).variables['misc_pH_Xa_full']\n",
    "                        Xa_omega_full = Dataset(nc_filename).variables['carb_sur_ohm_cal_Xa_full']\n",
    "\n",
    "                    elif data_psm_d18o_find == 1:\n",
    "                        with h5py.File(hdf5name, 'r') as f:\n",
    "                            Xb_sal = np.copy(f.get('Xb_sal'))\n",
    "                            if log_level > 3:\n",
    "                                print(Xb_sal.shape)\n",
    "                            Xb_ph = np.copy(f.get('Xb_ph'))\n",
    "                        Xa_sal_full = Dataset(nc_filename).variables['ocn_sur_sal_Xa_full']\n",
    "                        Xa_ph_full  = Dataset(nc_filename).variables['misc_pH_Xa_full']\n",
    "\n",
    "\n",
    "                    ### Read Proxy ###\n",
    "                    proxies = pandas.read_hdf(hdf5name, 'proxies')\n",
    "                    #prior_variable_dict = pandas.read_hdf(hdf5name, 'prior_variable_dict')\n",
    "\n",
    "                    if proxy_frac <= 1.0:\n",
    "                        sites_eval = pandas.read_hdf(hdf5name, 'sites_eval')\n",
    "                        sites_withhold_len  = len(sites_eval)\n",
    "                        if log_level > 1:\n",
    "                            print('Site withhold:       {}'.format(sites_eval['Site'].values))\n",
    "                            print('Proxy        :       {}'.format(sites_eval['Proxy'].values))\n",
    "\n",
    "                    proxy_psm_type_dict_df = pandas.read_hdf(hdf5name, 'proxy_psm_type_dict_df')\n",
    "                    proxy_psm_type_dict_list = proxy_psm_type_dict_df[0].values.tolist()\n",
    "\n",
    "                    for j in range(sites_withhold_len):\n",
    "                        data_psm_type = sites_eval['Proxy'][j]\n",
    "                        for key, value in proxy_assim2.items():\n",
    "                            if data_psm_type in value:\n",
    "                                #print(proxy_psm_type[key])\n",
    "                                key0 = key\n",
    "                                psm_required_variable_key = list(yml_dict['psm'][proxy_psm_type[key]]['psm_required_variables'].keys())[0]\n",
    "                                xb_key = psm_required_variable_key+'_Xb_full'\n",
    "                                xa_key = psm_required_variable_key+'_Xa_full'\n",
    "                                #print('xa_key is {}'.format(xa_key))\n",
    "                                Xb_full_field0 = Dataset(nc_filename).variables[xb_key] #\n",
    "                                Xb_full_field0 = Xb_full_field0[:,:,:,0].reshape(dum_imax*dum_jmax, nens)\n",
    "                                Xa_full_field0 = Dataset(nc_filename).variables[xa_key]\n",
    "\n",
    "                        if proxy_psm_type[key0] in ['bayesreg_tex86', 'cgenie_caco3']:\n",
    "                            if proxy_psm_type[key0] in ['bayesreg_tex86']:\n",
    "                                proxy_i = 'tex86'\n",
    "                            else:\n",
    "                                proxy_i = 'caco3'\n",
    "                            Ye = DeepDA_psm.cal_ye_cgenie(yml_dict,sites_eval,j,Xb_full_field0,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                            xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(Ye)\n",
    "\n",
    "                            #print('Prior Ye is {:.6f}'.format(np.mean(Ye)))\n",
    "\n",
    "                            for reconi in range(recon_period_len):\n",
    "\n",
    "                                Xa_reconi = np.copy(Xa_full_field0[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "\n",
    "                                Ye = DeepDA_psm.cal_ye_cgenie(yml_dict,sites_eval,j,Xa_reconi,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                                #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j]   = np.mean(Ye)\n",
    "                                #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi+1][j] = np.var(Ye)\n",
    "                                xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(Ye)\n",
    "                                #print('Analysis Ye is {:.6f}'.format(np.mean(Ye)))\n",
    "                                #ob_stat[j][reconi*2]   = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                                ob_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j] = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                                # error\n",
    "                                if ~np.isnan(sites_eval[data_period_id[reconi]][j]):\n",
    "\n",
    "                                    if proxy_psm_type[key0] in ['bayesreg_tex86']:\n",
    "\n",
    "                                        if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                            ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_tex86(31) + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                        else:\n",
    "                                            ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_tex86(31)\n",
    "\n",
    "                                    if proxy_psm_type[key0] in ['cgenie_caco3','cgenie_caco3_13c']:\n",
    "\n",
    "                                        psm_error = yml_dict['psm'][proxy_psm_type[key0]]['psm_error']\n",
    "\n",
    "                                        if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                            ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = psm_error + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                        else:\n",
    "                                            ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = psm_error\n",
    "\n",
    "                        elif proxy_psm_type[key0] in ['bayesreg_d18o_pooled']:\n",
    "\n",
    "                            proxy_i = 'd18o'\n",
    "\n",
    "                            Ye = DeepDA_psm.cal_ye_cgenie_d18O(yml_dict,sites_eval,j,Xb_full_field0,Xb_sal,Xb_ph,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                            xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(Ye)\n",
    "\n",
    "                            for reconi in range(recon_period_len):\n",
    "\n",
    "                                Xa_reconi = np.copy(Xa_full_field0[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                                Xa_sal_i  = np.copy(Xa_sal_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                                Xa_ph_i   = np.copy(Xa_ph_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "\n",
    "                                Ye = DeepDA_psm.cal_ye_cgenie_d18O(yml_dict,sites_eval,j,Xa_reconi,Xa_sal_i,Xa_ph_i,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                                xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(Ye)\n",
    "\n",
    "                                ob_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j] = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                                # error\n",
    "                                if ~np.isnan(sites_eval[data_period_id[reconi]][j]):\n",
    "\n",
    "                                    if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_d18o(15) + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                    else:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_d18o(15)\n",
    "\n",
    "                        elif proxy_psm_type[key0] in ['bayesreg_mgca_pooled_bcp', 'bayesreg_mgca_pooled_red']:\n",
    "                            proxy_i = 'mgca'\n",
    "                            spp = 'all'\n",
    "                            cleaningr = np.tile(np.array([1]),nens)\n",
    "                            cleaningb = np.tile(np.array([0]),nens)\n",
    "\n",
    "                            if proxy_psm_type[key0] in ['bayesreg_mgca_pooled_red']:\n",
    "                                clearning_one = cleaningr\n",
    "                                proxy_explain = 'reductive'\n",
    "\n",
    "                            elif proxy_psm_type[key0] in ['bayesreg_mgca_pooled_bcp']:\n",
    "                                clearning_one = cleaningb\n",
    "                                proxy_explain = 'barker'\n",
    "\n",
    "                            Ye = DeepDA_psm.cal_ye_cgenie_mgca(yml_dict,sites_eval,j,Xb_full_field0,proxy_psm_type[key0],dum_lon_offset,dum_imax,dum_jmax,Xb_sal,Xb_ph,Xb_omega,geologic_age)\n",
    "\n",
    "                            if psm_baymag_ln in ['yes']:\n",
    "                                xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(np.exp(Ye))\n",
    "                            else:\n",
    "                                xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(Ye)\n",
    "\n",
    "                            #Xa_sal_full = Dataset(nc_filename).variables['ocn_sur_sal_Xa_full']\n",
    "                            #Xa_ph_full  = Dataset(nc_filename).variables['misc_pH_Xa_full']\n",
    "                            #Xa_omega_full = Dataset(nc_filename).variables['carb_sur_ohm_cal_Xa_full']\n",
    "\n",
    "                            for reconi in range(recon_period_len):\n",
    "\n",
    "                                Xa_reconi  =   Xa_full_field0[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens))\n",
    "                                Xa_sal_i   =   np.copy(Xa_sal_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                                Xa_ph_i    =   np.copy(Xa_ph_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                                Xa_omega_i =   np.copy(Xa_omega_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "\n",
    "                                Ye = DeepDA_psm.cal_ye_cgenie_mgca(yml_dict,sites_eval,j,Xa_reconi,proxy_psm_type[key0],dum_lon_offset,dum_imax,dum_jmax,Xa_sal_i,Xa_ph_i,Xa_omega_i,geologic_age)\n",
    "\n",
    "                                if psm_baymag_ln in ['yes']:\n",
    "                                    xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(np.exp(Ye))\n",
    "                                else:\n",
    "                                    xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(Ye)\n",
    "\n",
    "                                #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j]   = np.mean(Ye)\n",
    "                                #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi+1][j] = np.var(Ye)\n",
    "\n",
    "                                ob_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j] = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                                if ~np.isnan(sites_eval[data_period_id[reconi]][j]):\n",
    "                                    ob_err0 = DeepDA_psm.obs_estimate_r_fixed_mgca_pooled((15, 16), clearning_one[0], np.nanmean(Xb_sal), np.nanmean(Xb_ph), np.nanmean(Xb_omega), spp, geologic_age)\n",
    "                                    if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = ob_err0 + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                    else:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = ob_err0\n",
    "\n",
    "                        # save proxy, prior, and posterior data and then standardized\n",
    "\n",
    "                        # info\n",
    "                        df_i = pandas.DataFrame({'site':sites_eval['Site'][j],'proxy':proxy_i,'locRad':locRadv,'proxy_frac':proxy_frac,'Rscale':Rscale,'MC':MCi}, index=[df_ind])\n",
    "                        df_eval = pandas.concat([df_eval,df_i])\n",
    "\n",
    "                        df_ind += 1\n",
    "\n",
    "                    # obs\n",
    "                    ob_data = np.swapaxes(ob_stat[locRadi,proxy_fraci,Rscalei,MCi,:,:],0,1)\n",
    "                    df_obi = pandas.DataFrame(data=ob_data,columns=df_ind_recon)\n",
    "                    df_ob = pandas.concat([df_ob,df_obi])\n",
    "\n",
    "                    #xb_std = np.copy(xb_stat[locRadi][proxy_fraci][Rscalei][MCi][:][:])\n",
    "                    #ob_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, recon_period_len*2, sites_withhold_len), np.nan)\n",
    "                    #xb_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, sites_withhold_len), np.nan)   # save full prior for withhold data\n",
    "                    #xa_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, recon_period_len, sites_withhold_len), np.nan)\n",
    "\n",
    "                    # xb\n",
    "                    xb_data = np.swapaxes(xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,:],0,1)  # withhold x nens\n",
    "                    df_xb_i  = pandas.DataFrame(data=xb_data)\n",
    "                    df_xb = pandas.concat([df_xb,df_xb_i])\n",
    "\n",
    "                    # xa\n",
    "                    xa_data = np.swapaxes(xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,:,:],0,2)  # withhold x recon x nens\n",
    "                    xa_data1 = xa_data.reshape((sites_withhold_len, recon_period_len*nens))\n",
    "                    df_xa_i  = pandas.DataFrame(data=xa_data1)\n",
    "                    df_xa = pandas.concat([df_xa,df_xa_i])\n",
    "\n",
    "                df_ob = df_ob.reset_index()\n",
    "                df_xb = df_xb.reset_index()\n",
    "                df_xa = df_xa.reset_index()\n",
    "                print('')\n",
    "                print('Step #3: evaluation data preparation - Done')\n",
    "                print('')\n",
    "                if log_level > 3:\n",
    "                    print('df_eval')\n",
    "                    print(df_eval)\n",
    "                    print('df_ob')\n",
    "                    print(df_ob)\n",
    "                    print('df_xb')\n",
    "                    print(df_xb)\n",
    "\n",
    "            ###############################################################\n",
    "            # calculate RMSE, CE, R^2 for each time slice\n",
    "            ###############################################################\n",
    "            ###############################################################\n",
    "\n",
    "                \n",
    "                df_reconi = pandas.DataFrame()\n",
    "\n",
    "                df_ind_i = 0\n",
    "                df_zscore_mc   = pandas.DataFrame()\n",
    "                \n",
    "                for reconi in range(recon_period_len):\n",
    "                    df_zscore   = pandas.DataFrame()\n",
    "                    data_period_id_i = data_period_id[reconi]\n",
    "                    if log_level > 1:\n",
    "                        print('')\n",
    "                        print(data_period_id_i)\n",
    "                        print('')\n",
    "\n",
    "                    for proxy_j in range(pn):\n",
    "                        df_zscore_j = pandas.DataFrame()\n",
    "                        \n",
    "                        proxy_i = Typelist[proxy_j]\n",
    "                        print('proxy i {}'.format(proxy_i))\n",
    "\n",
    "                        df_eval_pi = df_eval[df_eval['proxy'] == proxy_i]\n",
    "                        #df_ob_pi   = df_ob[df_eval['proxy'] == proxy_i]    \n",
    "                        #df_xb_pi   = df_xb[df_eval['proxy'] == proxy_i]\n",
    "                        #df_xa_pi   = df_xa[df_eval['proxy'] == proxy_i]\n",
    "                        df_ob_pi   = df_ob \n",
    "                        df_xb_pi   = df_xb\n",
    "                        df_xa_pi   = df_xa\n",
    "\n",
    "                        # show 1 data\n",
    "                        df_ob_pi_all = df_ob_pi[data_period_id_i]\n",
    "                        \n",
    "                        df_xb_pi_all = df_xb_pi.mean(axis=1)\n",
    "                        df_xa_pi_all = df_xa_pi.mean(axis=1)\n",
    "                        \n",
    "                        #df_xb_pi_all = df_xb_pi.mask(df_xb_pi.eq(np.nan)).mean(axis=1)\n",
    "                        #df_xa_pi_all = df_xa_pi.mask(df_xa_pi.eq(np.nan)).mean(axis=1)\n",
    "                        if log_level > 3:\n",
    "                            print('df_ob_pi')\n",
    "                            print(df_ob_pi)\n",
    "                            print('df_xb_pi')\n",
    "                            print(df_xb_pi)\n",
    "                            print(df_xa_pi)\n",
    "                            print('df_xb_pi_all')\n",
    "                            print(df_xb_pi_all)\n",
    "\n",
    "                        if showplot:\n",
    "                            fig = plt.figure()\n",
    "                            plt.rcParams.update({'figure.figsize':(8,3), 'figure.dpi':150})\n",
    "\n",
    "                            plt.subplot(1,2,1)\n",
    "                            kwargs = dict(alpha=0.5, marker='o', markersize=8, linestyle='',label = 'xb')    \n",
    "                            plt.plot(df_ob_pi_all,df_xb_pi_all, **kwargs)    \n",
    "                            plt.gca().set(ylabel='xb', xlabel = 'obs', title = proxy_i, xlim = axis_lim[proxy_j,:], ylim = axis_lim[proxy_j,:])\n",
    "\n",
    "                            plt.subplot(1,2,2)\n",
    "                            kwargs = dict(alpha=0.5, marker='o', markersize=8, linestyle='',label = 'xa')    \n",
    "                            plt.plot(df_ob_pi_all,df_xa_pi_all, **kwargs)    \n",
    "                            plt.gca().set(ylabel='xa', xlabel = 'obs', title = proxy_i, xlim = axis_lim[proxy_j,:], ylim = axis_lim[proxy_j,:])\n",
    "\n",
    "                        #df_ob_pi_mean = df_ob_pi[data_period_id_i].mean()\n",
    "                        #df_ob_pi_std  = df_ob_pi[data_period_id_i].std()\n",
    "                        df_ob_pi_mean = pandas.Series.mean(df_ob_pi[data_period_id_i])\n",
    "                        df_ob_pi_std  = pandas.Series.std(df_ob_pi[data_period_id_i])\n",
    "                        if log_level > 3:\n",
    "                            print('df_ob_pi_mean')\n",
    "                            print(df_ob_pi_mean)\n",
    "                            print('df_ob_pi_std')\n",
    "                            print(df_ob_pi_std)\n",
    "\n",
    "                        df_ob_pi_zscore = (df_ob_pi[data_period_id_i] - df_ob_pi_mean) / df_ob_pi_std\n",
    "                        df_xb_pi_zscore = (df_xb_pi_all - df_ob_pi_mean) / df_ob_pi_std\n",
    "                        df_xa_pi_zscore = (df_xa_pi_all - df_ob_pi_mean) / df_ob_pi_std\n",
    "                        \n",
    "                        \n",
    "                        #df_zscore_j['proxy']  = proxy_i + '_'\n",
    "                        #df_zscore_j['reconi'] = data_period_id_i + '_'\n",
    "                        #df_zscore_j['loc']    = str(locRad)\n",
    "                        #df_zscore_j['proxy_frac'] = str(proxy_fraci)\n",
    "                        #df_zscore_j['Rscale'] = str(Rscalei)\n",
    "                        for MCii in range(MCn): df_zscore_j.loc[MCii, ['proxy']] = proxy_i\n",
    "                        for MCii in range(MCn): df_zscore_j.loc[MCii, ['reconi']] = data_period_id_i\n",
    "                        for MCii in range(MCn): df_zscore_j.loc[MCii, ['loc']] = locRadi\n",
    "                        for MCii in range(MCn): df_zscore_j.loc[MCii, ['proxy_frac']] = proxy_fraci\n",
    "                        for MCii in range(MCn): df_zscore_j.loc[MCii, ['Rscale']] = Rscale\n",
    "                        df_zscore_j.loc[proxy_j, ['xb']] = df_xb_pi_all\n",
    "                        df_zscore_j.loc[proxy_j, ['ob']] = df_ob_pi_all\n",
    "                        df_zscore_j.loc[proxy_j, ['xa']] = df_xa_pi_all\n",
    "                        df_zscore_j.loc[proxy_j, ['xb_zscore']] = df_xb_pi_zscore\n",
    "                        df_zscore_j.loc[proxy_j, ['ob_zscore']] = df_ob_pi_zscore\n",
    "                        df_zscore_j.loc[proxy_j, ['xa_zscore']] = df_xa_pi_zscore\n",
    "                        \n",
    "                        #df_zscore_j['proxy']  = proxy_j\n",
    "                        #df_zscore_j['reconi'] = reconi\n",
    "                        #df_zscore_j['loc']    = locRadi\n",
    "                        #df_zscore_j['proxy_frac'] = proxy_fraci\n",
    "                        #df_zscore_j['Rscale'] = Rscalei\n",
    "                        \n",
    "                        #df_zscore_j['xb'] = df_xb_pi_all\n",
    "                        #df_zscore_j['ob'] = df_ob_pi_all\n",
    "                        #df_zscore_j['xa'] = df_xa_pi_all\n",
    "\n",
    "                        #df_zscore_j['xb_zscore'] = df_xb_pi_zscore\n",
    "                        #df_zscore_j['ob_zscore'] = df_ob_pi_zscore\n",
    "                        #df_zscore_j['xa_zscore'] = df_xa_pi_zscore\n",
    "\n",
    "                        df_zscore = pandas.concat([df_zscore,df_zscore_j])\n",
    "\n",
    "                        if log_level > 2:\n",
    "                            print('df_ob_pi_mean {} {}'.format(proxy_i, df_ob_pi_mean))\n",
    "                            print('df_ob_pi_std  {} {}'.format(proxy_i, df_ob_pi_std))\n",
    "                            print('')\n",
    "                            if log_level > 3:\n",
    "                                print(df_eval_pi)\n",
    "                                print(df_ob_pi)\n",
    "                                print(df_xb_pi[:][0:6])\n",
    "                                print(df_xa_pi)\n",
    "                        if showplot:\n",
    "                            fig = plt.figure()\n",
    "                            plt.rcParams.update({'figure.figsize':(8,3), 'figure.dpi':150})\n",
    "\n",
    "                            plt.subplot(1,2,1)\n",
    "                            kwargs = dict(alpha=0.5, marker='o', markersize=8, linestyle='',label = 'xb')    \n",
    "                            plt.plot(df_ob_pi_zscore,df_xb_pi_zscore, **kwargs)    \n",
    "                            plt.gca().set(ylabel='xb zscore', xlabel = 'obs zscore', title = proxy_i, xlim = axis_limz, ylim = axis_limz)\n",
    "\n",
    "                            plt.subplot(1,2,2)\n",
    "                            kwargs = dict(alpha=0.5, marker='o', markersize=8, linestyle='',label = 'xa')\n",
    "                            plt.plot(df_ob_pi_zscore,df_xa_pi_zscore, **kwargs)    \n",
    "                            plt.gca().set(ylabel='xa zscore', xlabel = 'obs zscore', title = proxy_i, xlim = axis_limz, ylim = axis_limz)\n",
    "\n",
    "                    if log_level > 0:\n",
    "                        print('df_zscore:')\n",
    "                        print(df_zscore)\n",
    "\n",
    "\n",
    "                    if showplot:\n",
    "                        fig = plt.figure()\n",
    "                        plt.rcParams.update({'figure.figsize':(8,3), 'figure.dpi':150})\n",
    "\n",
    "                        plt.subplot(1,2,1)\n",
    "                        kwargs = dict(alpha=0.5, marker='o', markersize=8, linestyle='',label = 'xb_zscore')\n",
    "                        plt.plot(df_zscore['ob_zscore'],df_zscore['xb_zscore'], **kwargs)    \n",
    "                        plt.gca().set(ylabel='xb zscore', xlabel = 'obs zscore', title = proxy_i, xlim = axis_limz, ylim = axis_limz)\n",
    "\n",
    "                    rmse_xb = DeepDA_psm.rmse(df_zscore['ob_zscore'],df_zscore['xb_zscore'])\n",
    "                    \n",
    "                    if log_level > 1:\n",
    "                        print('RMSE of Ob vs. Xb {}'.format(rmse_xb))\n",
    "\n",
    "                    CE_xb = DeepDA_psm.CE_NS70(df_zscore['ob_zscore'],df_zscore['xb_zscore'],1)\n",
    "                    if log_level > 1:\n",
    "                        print('CE of Ob vs. Xb {}'.format(CE_xb))\n",
    "\n",
    "                    a=ma.masked_invalid(df_zscore['ob_zscore'])\n",
    "                    b=ma.masked_invalid(df_zscore['xb_zscore'])\n",
    "                    msk = (~a.mask & ~b.mask)\n",
    "                    cor_matrix = ma.corrcoef(a[msk],b[msk])\n",
    "                    r_2_xb = cor_matrix[0,1]**2\n",
    "\n",
    "                    if log_level > 1:\n",
    "                        print('r^2 of Ob vs. Xb {}'.format(r_2_xb))\n",
    "                        print('')\n",
    "\n",
    "                    if showplot:\n",
    "                        plt.subplot(1,2,2)\n",
    "                        kwargs = dict(alpha=0.5, marker='o', markersize=8, linestyle='',label = 'xa_zscore')\n",
    "                        plt.plot(df_zscore['ob_zscore'],df_zscore['xa_zscore'], **kwargs)\n",
    "                        plt.gca().set(ylabel='xa zscore', xlabel = 'obs zscore', title = proxy_i, xlim = axis_limz, ylim = axis_limz)\n",
    "\n",
    "                    rmse_xa = DeepDA_psm.rmse(df_zscore['ob_zscore'],df_zscore['xa_zscore'])\n",
    "                    \n",
    "                    if log_level > 1:\n",
    "                        print('RMSE of Ob vs. Xa {}'.format(rmse_xa))\n",
    "                    \n",
    "                    CE_xa = DeepDA_psm.CE_NS70(df_zscore['ob_zscore'],df_zscore['xa_zscore'],1)\n",
    "                    \n",
    "                    if log_level > 1:\n",
    "                        print('CE of Ob vs. Xb {}'.format(CE_xa))\n",
    "                    \n",
    "                    a=ma.masked_invalid(df_zscore['ob_zscore'])\n",
    "                    b=ma.masked_invalid(df_zscore['xa_zscore'])\n",
    "                    msk = (~a.mask & ~b.mask)\n",
    "                    cor_matrix = ma.corrcoef(a[msk],b[msk])\n",
    "                    r_2_xa = cor_matrix[0,1]**2\n",
    "                    \n",
    "                    if log_level > 1:\n",
    "                        print('r^2 of Ob vs. Xa {}'.format(r_2_xa))\n",
    "                        print(' --- ')\n",
    "                        print('')\n",
    "                    # delta RMSE, CE, and R^2\n",
    "                    drmse = 100 * (rmse_xb - rmse_xa)/rmse_xb\n",
    "                    dce   = 100 * (CE_xb - CE_xa)/CE_xb\n",
    "                    dr2   = 100 * (r_2_xb - r_2_xa)/r_2_xb\n",
    "                    \n",
    "                    df_reconi = pandas.DataFrame({'reconi':reconi,\n",
    "                                                  'data_period_id_i':data_period_id_i,\n",
    "                                                  'loc':locRadv,\n",
    "                                                  'proxy_frac':proxy_frac,\n",
    "                                                  'Rscale':Rscale,\n",
    "                                                  'RMSE Xb':rmse_xb,\n",
    "                                                  'RMSE Xa':rmse_xa,\n",
    "                                                  'dRMSE':drmse,\n",
    "                                                  'CE Xb':CE_xb,\n",
    "                                                  'CE Xa': CE_xa,\n",
    "                                                  'dCE':dce,\n",
    "                                                  'R^2 Xb':r_2_xb,\n",
    "                                                  'R^2 Xa': r_2_xa,\n",
    "                                                  'dR^2':dr2}, index=[df_ind_i])\n",
    "\n",
    "                    df_evaluation = pandas.concat([df_evaluation,df_reconi])\n",
    "\n",
    "                    df_ind_i += 1\n",
    "                    \n",
    "                    df_zscore_mc = pandas.concat([df_zscore_mc,df_zscore])\n",
    "                    \n",
    "                \n",
    "                # all df_sscore\n",
    "                #df_zscore_all = pandas.concat([df_zscore_all,df_zscore])\n",
    "                df_zscore_all = pandas.concat([df_zscore_all,df_zscore_mc])\n",
    "                print(' This loop done ')\n",
    "\n",
    "    if savesummary:\n",
    "        df_zscore_all.to_csv(yml_dict['core']['proj_dir']+'/wrk/'+en+savefilename_add+'_df_zscore_all'+'.csv')\n",
    "        df_evaluation.sort_index().to_csv(yml_dict['core']['proj_dir']+'/wrk/'+en+'_df_evaluation_log.csv')\n",
    "        \n",
    "    print('')\n",
    "    print('Step #4: evaluation - Done')\n",
    "    print('')\n",
    "    print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  proxy reconi   loc proxy_frac Rscale    xb    ob    xa xb_zscore ob_zscore  \\\n",
      "0  None   None  None       None   None  None  None  None      None      None   \n",
      "\n",
      "  xa_zscore  \n",
      "0      None  \n",
      "d18O\n",
      "  proxy reconi   loc proxy_frac Rscale    xb    ob    xa xb_zscore ob_zscore  \\\n",
      "0  d18O   None  None       None   None  None  None  None      None      None   \n",
      "\n",
      "  xa_zscore  \n",
      "0      None  \n"
     ]
    }
   ],
   "source": [
    "df_zscore_j = pandas.DataFrame({'proxy': [],\n",
    "                                                        'reconi': [],\n",
    "                                                        'loc': [],\n",
    "                                                        'proxy_frac': [],\n",
    "                                                        'Rscale': [],\n",
    "                                                        'xb': [],\n",
    "                                                        'ob': [],\n",
    "                                                        'xa': [],\n",
    "                                                        'xb_zscore': [],\n",
    "                                                        'ob_zscore': [],\n",
    "                                                        'xa_zscore': []})\n",
    "print(df_zscore_j)\n",
    "print(proxy_i)\n",
    "df_zscore_j.loc[0, ['proxy']] = [proxy_i]\n",
    "print(df_zscore_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "  proxy       reconi  loc  proxy_frac  Rscale        xb        ob        xa\n",
      "0  d18O  prePETMmean  0.0         0.0     2.0 -5.132015 -3.773568 -4.446489\n",
      "1  d18O  prePETMmean  0.0         0.0     2.0 -5.131957 -3.397277 -4.456344\n",
      "2  d18O  prePETMmean  0.0         0.0     2.0 -2.954112       NaN -2.249525\n",
      "3  d18O  prePETMmean  0.0         0.0     2.0 -3.609945 -2.345740 -2.901556\n",
      "4  d18O  prePETMmean  0.0         0.0     2.0 -3.803660       NaN -3.100056\n",
      "5  d18O  prePETMmean  0.0         0.0     2.0 -3.609365 -2.500314 -2.901647\n",
      "0   -5.132015\n",
      "1   -5.131957\n",
      "2   -2.954112\n",
      "3   -3.609945\n",
      "4   -3.803660\n",
      "5   -3.609365\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_zscore_j = pandas.DataFrame()\n",
    "                        \n",
    "print(MCn)\n",
    "for MCii in range(MCn): df_zscore_j.loc[MCii, ['proxy']] = proxy_i\n",
    "for MCii in range(MCn): df_zscore_j.loc[MCii, ['reconi']] = data_period_id_i\n",
    "for MCii in range(MCn): df_zscore_j.loc[MCii, ['loc']] = locRadi\n",
    "for MCii in range(MCn): df_zscore_j.loc[MCii, ['proxy_frac']] = proxy_fraci\n",
    "for MCii in range(MCn): df_zscore_j.loc[MCii, ['Rscale']] = Rscale\n",
    "\n",
    "df_zscore_j['xb'] = df_xb_pi_all\n",
    "df_zscore_j['ob'] = df_ob_pi_all\n",
    "df_zscore_j['xa'] = df_xa_pi_all\n",
    "\n",
    "print(df_zscore_j)\n",
    "print(df_xb_pi_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
