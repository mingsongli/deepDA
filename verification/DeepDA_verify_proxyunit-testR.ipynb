{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No module named 'bayspline'\n",
      ">>  Import package => OKAY\n",
      "\n",
      "petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_d18o_MC1_frac1_rscale\n",
      ">>  Loading configuration file => OKAY\n",
      "\n",
      "['sed_CaCO3', 'atm_pCO2']\n",
      ">>  nc_keyvalue {'biogem': 'fields_biogem_2d'}...\n",
      ">>  biogem: fields_biogem_2d\n",
      ">>  nc_keyvalue {'biogem': 'fields_biogem_3d'}...\n",
      ">>  biogem: fields_biogem_3d\n",
      ">>  Number of 2d prior variables is: 9. List:\n",
      "      ['ocn_sur_temp', 'atm_temp', 'atm_pCO2', 'ocn_sur_sal', 'misc_pH', 'carb_sur_ohm_cal', 'ocn_ben_temp', 'sed_CaCO3', 'ocn_sur_ALK']\n",
      ">>  Number of 3d prior variables is: 0. List:\n",
      "      []\n",
      ">>  Proxy: selected proxy dataset number 73: those in blacklist removed!\n",
      ">>  Proxy: selected proxy dataset number 53: those unknown/frosty removed!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DeepDA_verify is to verify DA output\n",
    "\n",
    "It read proxy, prior, and posterior from DA outputs files and configuration files.\n",
    "Then, it calculates the statistics (corrcoef and CE) of the DA results and save the outputs.\n",
    "\n",
    "By Mingsong Li\n",
    "    Penn State \n",
    "    Now at Peking University\n",
    "    2/17/2020\n",
    "    \n",
    "Updated Mar. 03, 2020\n",
    "Updated Oct. 11, 2020  # plot enhanced\n",
    "Updated Oct. 12, 2020  # multi jobs\n",
    "Updated June 30, 2021 \n",
    "Updated July 15, 2021  # ZSCORE\n",
    "\n",
    "#df_ob_pi   = df_ob[df_eval['proxy'] == proxy_i]   : only work for single proxy experiment\n",
    "Updated Aug. 5, 2021\n",
    "\n",
    "'''\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from DeepDA_lib import modules_nc\n",
    "from DeepDA_lib import DeepDA_psm\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "import h5py\n",
    "#import time\n",
    "import yaml\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "from sys import platform as sys_pf\n",
    "import matplotlib.pyplot as plt\n",
    "if sys_pf == 'darwin':\n",
    "    import matplotlib\n",
    "    matplotlib.use(\"TkAgg\")\n",
    "    import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "try:\n",
    "    import bayspline\n",
    "except ImportError as e1:\n",
    "    print('Warning:', e1)\n",
    "try:\n",
    "    import bayspar\n",
    "except ImportError as e2:\n",
    "    print('Warning:', e2)\n",
    "try:\n",
    "    import bayfox\n",
    "except ImportError as e3:\n",
    "    print('Warning:', e3)\n",
    "try:\n",
    "    import baymag\n",
    "except ImportError as e4:\n",
    "    print('Warning:', e4)\n",
    "\n",
    "print('>>  Import package => OKAY')\n",
    "print('')\n",
    "\n",
    "###################################################################\n",
    "#####################    User defined start   #####################\n",
    "###################################################################\n",
    "\n",
    "# DA output folders\n",
    "if sys_pf == 'darwin':\n",
    "    xlsxdir = '/volumes/DA/DeepDA/wrk/'\n",
    "    xlsxdir = '/volumes/Backup/DeepDA/'\n",
    "else:\n",
    "    xlsxdir = '/mnt/d/DeepDA/wrk/'\n",
    "\n",
    "# Experiment style: \n",
    "#    0 = given lsit\n",
    "#    1 = all folders\n",
    "#    \n",
    "expstyle = 0\n",
    "#expstyle = 1\n",
    "\n",
    "# needed when explist style is 0\n",
    "#explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210718_all_bays_MCsd100_pHcor_omega5_frac0.98']\n",
    "#Typelist = ['d18O','TEX86','MgCa','caco3']  # proxy type list\n",
    "#explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_d18o_bays_MCsd100_pHcor_omega5_frac0.95']  # 1 unselected proxy\n",
    "#Typelist = ['d18O']\n",
    "#explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_caco3_bays_MCsd100_pHcor_omega5_frac0.95'] #\n",
    "#Typelist = ['caco3']\n",
    "#explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_tex_bays_MCsd100_pHcor_omega5_frac0.95']\n",
    "#Typelist = ['TEX86'] \n",
    "#explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210715_mgca_bays_MCsd100_pHcor_omega5_frac0.95']\n",
    "#Typelist = ['MgCa']\n",
    "#explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_caco3_MC1_frac1_rscale']\n",
    "#explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_caco3_MC1_frac1_rscale10k2d1']\n",
    "#Typelist = ['caco3']\n",
    "#proxy_eval_list = ['d18O','TEX86','MgCa']  # use this list \n",
    "\n",
    "explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_d18o_MC1_frac1_rscale']\n",
    "Typelist = ['d18o']\n",
    "proxy_eval_list = ['caco3','TEX86','MgCa']  # use this list\n",
    "#proxy_eval_list = ['TEX86','MgCa']  # use this list\n",
    "\n",
    "#explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_mgca_MC1_frac1_rscale']\n",
    "#Typelist = ['mgca']\n",
    "#proxy_eval_list = ['caco3','TEX86','d18O']  # use this list\n",
    "\n",
    "\n",
    "#explist = ['petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_tex_MC1_frac1_rscale']\n",
    "#Typelist = ['TEX86']\n",
    "#proxy_eval_list = ['caco3','mgca','d18O']  # use this list\n",
    "#pn = len(Typelist)\n",
    "\n",
    "pn = len(proxy_eval_list)\n",
    "\n",
    "label_all = ('prePETM', 'peakPETM','postPETM', 'PETM_body')  # slice name\n",
    "warmcomp = [0,1]  # ID for petm warming \n",
    "\n",
    "log_level = 3\n",
    "\n",
    "\n",
    "dum_jmax = 36\n",
    "dum_imax = 36\n",
    "\n",
    "AnalysisStd = True   # True: standardize; False: use raw analysis data\n",
    "\n",
    "# output\n",
    "savesummary = True\n",
    "savesummary_slice=  True\n",
    "# for evaluation save and plot\n",
    "showplot = False\n",
    "\n",
    "#pn = 4  # use the first pn data\n",
    "\n",
    "axis_lim = np.array([[-6,1],[0,1],[0,7],[0,100]])   # axis limit for the plot\n",
    "axis_limz = np.array([-4,4])   # set axis limit for the zscore plot\n",
    "\n",
    "###################################################################\n",
    "#####################    User defined end     #####################\n",
    "###################################################################\n",
    "label_all_len = len(label_all)\n",
    "\n",
    "if expstyle == 0:\n",
    "    explist = explist\n",
    "    \n",
    "elif expstyle == 1:\n",
    "    # read content\n",
    "    dir1 = [o for o in os.listdir(xlsxdir) if os.path.isdir(os.path.join(xlsxdir,o))]\n",
    "    explist = dir1\n",
    "    #print(dir1[0])\n",
    "\n",
    "for diri in range(len(explist)):\n",
    "    \n",
    "    # run the first 5 folders\n",
    "    #if diri < 5:\n",
    "    #    continue\n",
    "    en = explist[diri]\n",
    "    print(en)\n",
    "\n",
    "    dum_ijmax = dum_imax * dum_jmax\n",
    "    config_name_f = \"../DeepDA_config.yml\"\n",
    "    f = open(config_name_f, 'r')\n",
    "    yml_dict_f = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    f.close()\n",
    "\n",
    "    dir_data_save = yml_dict_f['core']['wrkdir']\n",
    "\n",
    "    config_name = dir_data_save + '/' + en + '.yml'\n",
    "    f = open(config_name, 'r')\n",
    "    yml_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    f.close()\n",
    "    print('>>  Loading configuration file => OKAY')\n",
    "    print('')\n",
    "    # Read parameters from configurations\n",
    "    MCn = yml_dict['MonteCarlo']['number']\n",
    "    #debug\n",
    "    #MCn = 30\n",
    "    log_level = 2\n",
    "    nens = yml_dict['core']['nens']\n",
    "\n",
    "    nexp = yml_dict['core']['nexp']\n",
    "    dir_proxy = yml_dict['core']['proxy_dir']\n",
    "    dir_data_save = yml_dict['core']['wrkdir']\n",
    "    log_level = yml_dict['log_level']\n",
    "    recon_period = yml_dict['core']['recon_period']\n",
    "    recon_timescale = yml_dict['core']['recon_timescale_interval']\n",
    "    recon_period_full = np.arange(recon_period[0],recon_period[1]+1,recon_timescale)\n",
    "    recon_period_len = recon_period_full.shape[0]\n",
    "    recon_timescale = yml_dict['core']['recon_timescale_interval']\n",
    "    save_ens_full = yml_dict['core']['save_ens_full']\n",
    "    proxy_assim2 = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_assim2']\n",
    "    proxy_psm_type    = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_psm_type']\n",
    "    proxy_blacklist   = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_blacklist']\n",
    "    proxy_order       = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_order']\n",
    "    proxy_list = [item for item in proxy_order if item not in proxy_blacklist]\n",
    "    proxy_err_eval   = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_err_eval']\n",
    "    lon_label = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['lon_label']\n",
    "    lat_label = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['lat_label']\n",
    "\n",
    "    proxy_frac      = yml_dict['proxies']['proxy_frac']\n",
    "    prior_source = yml_dict['prior']['prior_source'] #\n",
    "    dum_lon_offset = yml_dict['prior'][prior_source]['dum_lon_offset'] # longitude offset\n",
    "    limit_hard_keys = list(yml_dict['prior'][prior_source]['limit_hard'].keys())\n",
    "    psm_baymag_ln =  yml_dict['psm']['bayesreg_mgca_pooled_red']['psm_baymag_ln']\n",
    "    print(limit_hard_keys)\n",
    "\n",
    "    data_period_id    = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['data_period_id']\n",
    "    data_period_idstd = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['data_period_idstd']\n",
    "    geologic_age = yml_dict['core']['geologic_age']\n",
    "\n",
    "    # read preprior HDF5 file\n",
    "    dir_proxy_data = dir_proxy +'/'+ yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['dbversion']\n",
    "    proxy_err_eval = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_err_eval']\n",
    "    proxy_d18o_glassy  = yml_dict['proxies']['proxy_d18o_glassy']\n",
    "    proxy_assim3 = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_assim3']\n",
    "    data_glassy_label_blacklist = proxy_assim3['Marine sediments_d18o_pooled_glassy']\n",
    "    # ========= dataset for plot =========\n",
    "    cGENIEGrid = yml_dict['core']['proj_dir'] + '/data_misc/cGENIEGrid.csv'\n",
    "    cGENIEGrid = pandas.read_csv(cGENIEGrid)\n",
    "    cGENIEGridB_lat36 = cGENIEGrid['lat']\n",
    "    cGENIEGridB_lon36 = cGENIEGrid['lon']\n",
    "    cGENIEGrid = cGENIEGrid.to_numpy()\n",
    "    #print('>>  OKAY.')\n",
    "\n",
    "    # Read global mean and plot to show results\n",
    "    ########## Prior #########\n",
    "    prior_state_variable = yml_dict['prior'][prior_source]['state_variable']  # note: ['2d': xxx; '3d': xxx]\n",
    "    dum_lon_offset = yml_dict['prior'][prior_source]['dum_lon_offset'] # longitude offset\n",
    "    \n",
    "    # ========= Monte Carlo =========\n",
    "    local_rad_list = yml_dict['core']['local_rad_list'] #\n",
    "    locRadn= len(local_rad_list)\n",
    "    local_rad_list = np.asarray(local_rad_list)\n",
    "    #print(local_rad_list)\n",
    "    #print(locRadn)\n",
    "    proxy_frac_list   = yml_dict['proxies']['proxy_frac']\n",
    "    proxy_fracn = len(proxy_frac_list)\n",
    "    proxy_frac_list = np.asarray(proxy_frac_list)\n",
    "    Rscale_style = yml_dict['core']['Rscale_style']\n",
    "    \n",
    "    if Rscale_style == 1:\n",
    "        Rscale_list = yml_dict['core']['Rscale']\n",
    "        Rscalen = len(Rscale_list)\n",
    "        Rscale_list = np.asarray(Rscale_list)\n",
    "        \n",
    "        # debug\n",
    "        #Rscale_list = np.array([100, 50.0, 20.0, 15.0, 10.0, 5.0, 2.0, 1.0, 0.5, 0.2, 0.1])\n",
    "        #Rscalen = len(Rscale_list)\n",
    "        \n",
    "    elif Rscale_style == 2:\n",
    "        Rscalen = 1\n",
    "        Rscale_list = [0]\n",
    "    # save prior variable list\n",
    "    prior_variable_dict = []  # variable list\n",
    "    prior_nc_file_list = []  # nc file list\n",
    "    prior_variable_dict_3d = []  # variable list\n",
    "    prior_nc_file_list_3d = []  # nc file list\n",
    "\n",
    "    for key, value in prior_state_variable.items():\n",
    "        nc_keyvalue = prior_state_variable[key]['ncname']  # note: 2d dict\n",
    "        print('>>  nc_keyvalue {}...'.format(nc_keyvalue))\n",
    "        for key1, value1 in nc_keyvalue.items():\n",
    "            print('>>  {}: {}'.format(key1,value1))\n",
    "            for i in range(len(prior_state_variable[key][value1])):\n",
    "                if key in ['2d']:\n",
    "                    prior_variable_dict.append(prior_state_variable[key][value1][i])\n",
    "                    prior_nc_file_list.append(key1+'/'+value1+'.nc')\n",
    "                elif key in ['3d']:\n",
    "                    prior_variable_dict_3d.append(prior_state_variable[key][value1][i])\n",
    "                    prior_nc_file_list_3d.append(key1+'/'+value1+'.nc')\n",
    "\n",
    "    # variable list\n",
    "    prior_variable_len = len(prior_variable_dict)\n",
    "    prior_variable3d_len = len(prior_variable_dict_3d)\n",
    "    print('>>  Number of 2d prior variables is: {}. List:'.format(prior_variable_len))\n",
    "    print('      {}'.format(prior_variable_dict))\n",
    "    print('>>  Number of 3d prior variables is: {}. List:'.format(prior_variable3d_len))\n",
    "    print('      {}'.format(prior_variable_dict_3d))\n",
    "\n",
    "    MC_dir =  dir_data_save + '/' + en + '/'\n",
    "\n",
    "    Xa2d_full_np   = np.full((locRadn,proxy_fracn,Rscalen,MCn*nens,prior_variable_len,recon_period_len),np.nan)  # save mean of each variable (column) of each MC run (row)\n",
    "    Xa2d_mean_np   = np.full((locRadn,proxy_fracn,Rscalen,MCn,prior_variable_len,recon_period_len),np.nan)  # save mean of each variable (column) of each MC run (row)\n",
    "    Xa2d_std_np    = np.full((locRadn,proxy_fracn,Rscalen,MCn,prior_variable_len,recon_period_len),np.nan)  # save mean of each variable (column) of each MC run (row)\n",
    "    Xa2d_all_np    = np.full((dum_jmax, dum_imax,locRadn,proxy_fracn,Rscalen,MCn, prior_variable_len, recon_period_len),np.nan)  # save mean of each variable (column) of each MC run (row)\n",
    "    Xa2d_allstd_np = np.full((dum_jmax, dum_imax, locRadn,proxy_fracn,Rscalen,MCn, prior_variable_len, recon_period_len),np.nan)  # save mean of each variable (column) of each MC run (row)\n",
    "    Xa2d_mean_np2  = np.full((locRadn,proxy_fracn,Rscalen,prior_variable_len,recon_period_len),np.nan)  # save mean of each variable (column) of each MC run (row)\n",
    "    Xa2d_std_np2   = np.full((locRadn,proxy_fracn,Rscalen,prior_variable_len,recon_period_len),np.nan)  # save mean of each variable (column) of each MC run (row)\n",
    "    df_evaluation  = pandas.DataFrame()\n",
    "    df_zscore_all  = pandas.DataFrame()\n",
    "    \n",
    "    \n",
    "proxies = pandas.read_csv(dir_proxy_data)\n",
    "proxies_len0 = len(proxies)\n",
    "if log_level > 3:\n",
    "    print('>>  All proxy: '.format(proxies))\n",
    "proxy_select_0 = 0\n",
    "\n",
    "### check proxy data in the blacklist or not ###\n",
    "for j in range(proxies_len0):\n",
    "    # Read proxy type from the database\n",
    "    data_psm_type = proxies['Proxy'][j]\n",
    "    # initial default 0 : this proxy is not included\n",
    "    data_assimilate_i = 0\n",
    "    for jlist in range(len(proxy_list)):\n",
    "        if data_psm_type in proxy_assim2[proxy_list[jlist]]:\n",
    "            # find and save this proxy\n",
    "            #data_assimilate_i = 1   # original option; select this data\n",
    "            data_assimilate_i = 0    # new option; deselect this proxy type\n",
    "        else:\n",
    "            data_assimilate_i = 1\n",
    "            \n",
    "    if data_assimilate_i == 1:\n",
    "        if log_level > 3:\n",
    "            print('>>    File {}, {} included'.format(proxies.loc[j,'File'], data_psm_type))\n",
    "        if proxy_select_0 == 0:\n",
    "            proxy_select0 = proxies.iloc[[j]]\n",
    "            proxy_select0 = proxy_select0.reset_index(drop=True) # reset_index, avoid index error\n",
    "            proxy_select_0 = 1\n",
    "        else:\n",
    "            proxy_select0 = proxy_select0.append(proxies.iloc[[j]], ignore_index=True)\n",
    "\n",
    "proxies_select_len0 = len(proxy_select0)\n",
    "\n",
    "if log_level > 1:\n",
    "    print('>>  Proxy: selected proxy dataset number {}: those in blacklist removed!'.format(proxies_select_len0))\n",
    "\n",
    "### check glassy only data or not\n",
    "proxy_select_0 = 0\n",
    "if proxy_d18o_glassy:\n",
    "    for jj in range(proxies_select_len0):\n",
    "        data_glassy_label = proxy_select0['Glassy'][jj]\n",
    "        if data_glassy_label not in data_glassy_label_blacklist:\n",
    "            if proxy_select_0 == 0:\n",
    "                proxy_select = proxy_select0.iloc[[jj]]\n",
    "                proxy_select = proxy_select.reset_index(drop=True) # reset_index, avoid index error\n",
    "                proxy_select_0 = 1\n",
    "            else:\n",
    "                proxy_select = proxy_select.append(proxy_select0.iloc[[jj]], ignore_index=True)\n",
    "\n",
    "    if log_level > 3:\n",
    "        print(proxy_select)\n",
    "    proxies_select_len0 = len(proxy_select)\n",
    "    if log_level > 1:\n",
    "        print('>>  Proxy: selected proxy dataset number {}: those unknown/frosty removed!'.format(proxies_select_len0))\n",
    "else:\n",
    "    proxy_select = proxy_select0.copy()\n",
    "if log_level > 4:\n",
    "    print(proxy_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  Read nc file: /volumes/DA/DeepDA/wrk/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_d18o_MC1_frac1_rscale/_loc_0_proxy_frac_1_Rscale_10000.0_MC_0.nc\n",
      "First variable: all MC mean\n",
      "[33.106449]\n",
      "All variable. Mean of variables x reconi\n",
      "[[  33.106448   33.13459 ]\n",
      " [  30.158416   30.191016]\n",
      " [1662.062622 1665.966797]\n",
      " [  33.627929   33.627574]\n",
      " [   7.543379    7.542236]\n",
      " [   5.557402    5.546009]\n",
      " [  17.310045   17.340623]\n",
      " [  38.34554    38.302009]\n",
      " [   0.002113    0.002113]]\n",
      "\n",
      "Step #1: read data - Done\n",
      "\n",
      "\n",
      "DA - Summary of global mean and standard deviation\n",
      "\n",
      "ocn_sur_temp\n",
      "atm_temp\n",
      "atm_pCO2\n",
      "ocn_sur_sal\n",
      "misc_pH\n",
      "carb_sur_ohm_cal\n",
      "ocn_ben_temp\n",
      "sed_CaCO3\n",
      "ocn_sur_ALK\n",
      "saved @\n",
      "/Users/mingsongli/Dropbox/git/deepDA/mlwrk/wrk/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_d18o_MC1_frac1_rscale_loc_0_proxy_frac_1_Rscale_10000.0.summary.csv\n",
      "\n",
      "Step #2: summary - Done\n",
      "\n",
      "DA - Read proxy, prior, and posterior, standardize\n",
      "\n",
      "Read first hdf5 file /volumes/DA/DeepDA/wrk/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_d18o_MC1_frac1_rscale/_loc_0_proxy_frac_1_Rscale_10000.0_MC_0.hdf5 to get the number of withold datasets.\n",
      " Site withhold length ： 53\n",
      "    /volumes/DA/DeepDA/wrk/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_d18o_MC1_frac1_rscale/_loc_0_proxy_frac_1_Rscale_10000.0_MC_0.nc\n",
      "Site withhold:       ['277' '277' '302' '401' '401' '401' '527' '527' '690' '690' '865' '865'\n",
      " '865' '959' '1172' '1209' '1209' 'U1443' 'BR' 'BR' 'BR' 'BR' 'BR' 'fur'\n",
      " 'fur' 'GreatBelt' 'harrell' 'ib10a' 'ib10b' 'lodo' 'lodo' 'M0077'\n",
      " 'Milville' 'Milville' 'sq' 'sq' 'sq' 'sq' 'sq' 'tanzania' 'tanzania'\n",
      " 'tumey' 'tumey' 'waipara' 'Siberia' 'WL' 'WL' 'WL' 'Ancora' 'Ancora'\n",
      " 'Ancora' 'Ancora' 'Ancora']\n",
      "Proxy        :       ['mgca_morozovella:barker' 'mgca_acarinina:barker' 'tex86' 'd18o_m.subb'\n",
      " 'mgca_m.subb:barker' 'd18o_a.soldadoensis' 'mgca_acarinina:barker'\n",
      " 'mgca_m.subb:barker' 'd18o_acarinina' 'mgca_acarinina:reductive'\n",
      " 'd18o_morozovella' 'mgca_morozovella:barker' 'mgca_acarinina:barker'\n",
      " 'tex86' 'tex86' 'mgca_morozovella:reductive' 'mgca_acarinina:reductive'\n",
      " 'mgca_morozovella:barker' 'tex86' 'mgca_acarinina:reductive'\n",
      " 'mgca_morozovella:reductive' 'd18o_acarinina' 'd18o_morozovella' 'tex86'\n",
      " 'tex86' 'tex86' 'tex86' 'tex86' 'tex86' 'd18o_acarinina'\n",
      " 'd18o_morozovella' 'tex86' 'd18o_acarinina' 'd18o_morozovella'\n",
      " 'd18o_morozovella' 'd18o_acarinina' 'mgca_morozovella:reductive'\n",
      " 'mgca_acarinina:reductive' 'tex86' 'd18o_morozovella'\n",
      " 'd18o_a.soldadoensis' 'd18o_acarinina' 'd18o_morozovella' 'tex86' 'tex86'\n",
      " 'd18o_morozovella' 'd18o_acarinina' 'tex86' 'tex86' 'd18o_morozovella'\n",
      " 'd18o_acarinina' 'mgca_morozovella:reductive' 'mgca_acarinina:reductive']\n",
      "\n",
      "Step #3: evaluation data preparation - Done\n",
      "\n",
      ">>>>>>>  \n",
      "\n",
      "reconi 0\n",
      "prePETMmean\n",
      "\n",
      "assimilated proxy i ['caco3', 'TEX86', 'MgCa']\n",
      ">>>>>>>  \n",
      "\n",
      "reconi 1\n",
      "peakPETM\n",
      "\n",
      "assimilated proxy i ['caco3', 'TEX86', 'MgCa']\n",
      "df_eval_pi\n",
      "         site  proxy  locRad  proxy_frac   Rscale  MC\n",
      "0         277   mgca       0           1  10000.0   0\n",
      "1         277   mgca       0           1  10000.0   0\n",
      "2         302  tex86       0           1  10000.0   0\n",
      "3         401   d18o       0           1  10000.0   0\n",
      "4         401   mgca       0           1  10000.0   0\n",
      "5         401   d18o       0           1  10000.0   0\n",
      "6         527   mgca       0           1  10000.0   0\n",
      "7         527   mgca       0           1  10000.0   0\n",
      "8         690   d18o       0           1  10000.0   0\n",
      "9         690   mgca       0           1  10000.0   0\n",
      "10        865   d18o       0           1  10000.0   0\n",
      "11        865   mgca       0           1  10000.0   0\n",
      "12        865   mgca       0           1  10000.0   0\n",
      "13        959  tex86       0           1  10000.0   0\n",
      "14       1172  tex86       0           1  10000.0   0\n",
      "15       1209   mgca       0           1  10000.0   0\n",
      "16       1209   mgca       0           1  10000.0   0\n",
      "17      U1443   mgca       0           1  10000.0   0\n",
      "18         BR  tex86       0           1  10000.0   0\n",
      "19         BR   mgca       0           1  10000.0   0\n",
      "20         BR   mgca       0           1  10000.0   0\n",
      "21         BR   d18o       0           1  10000.0   0\n",
      "22         BR   d18o       0           1  10000.0   0\n",
      "23        fur  tex86       0           1  10000.0   0\n",
      "24        fur  tex86       0           1  10000.0   0\n",
      "25  GreatBelt  tex86       0           1  10000.0   0\n",
      "26    harrell  tex86       0           1  10000.0   0\n",
      "27      ib10a  tex86       0           1  10000.0   0\n",
      "28      ib10b  tex86       0           1  10000.0   0\n",
      "29       lodo   d18o       0           1  10000.0   0\n",
      "30       lodo   d18o       0           1  10000.0   0\n",
      "31      M0077  tex86       0           1  10000.0   0\n",
      "32   Milville   d18o       0           1  10000.0   0\n",
      "33   Milville   d18o       0           1  10000.0   0\n",
      "34         sq   d18o       0           1  10000.0   0\n",
      "35         sq   d18o       0           1  10000.0   0\n",
      "36         sq   mgca       0           1  10000.0   0\n",
      "37         sq   mgca       0           1  10000.0   0\n",
      "38         sq  tex86       0           1  10000.0   0\n",
      "39   tanzania   d18o       0           1  10000.0   0\n",
      "40   tanzania   d18o       0           1  10000.0   0\n",
      "41      tumey   d18o       0           1  10000.0   0\n",
      "42      tumey   d18o       0           1  10000.0   0\n",
      "43    waipara  tex86       0           1  10000.0   0\n",
      "44    Siberia  tex86       0           1  10000.0   0\n",
      "45         WL   d18o       0           1  10000.0   0\n",
      "46         WL   d18o       0           1  10000.0   0\n",
      "47         WL  tex86       0           1  10000.0   0\n",
      "48     Ancora  tex86       0           1  10000.0   0\n",
      "49     Ancora   d18o       0           1  10000.0   0\n",
      "50     Ancora   d18o       0           1  10000.0   0\n",
      "51     Ancora   mgca       0           1  10000.0   0\n",
      "52     Ancora   mgca       0           1  10000.0   0\n",
      "df_ob_pi_all_col\n",
      "            0\n",
      "0         NaN\n",
      "1    3.789859\n",
      "2    0.608182\n",
      "3   -1.768513\n",
      "4    3.449635\n",
      "..        ...\n",
      "101  0.927895\n",
      "102 -3.857000\n",
      "103 -3.307778\n",
      "104  4.362609\n",
      "105  3.414800\n",
      "\n",
      "[106 rows x 1 columns]\n",
      "df_xb_pi_all_col\n",
      "           0         1         2         3         4         5         6   \\\n",
      "0    1.111002  1.157453  4.637259  2.114800  5.090611  2.401719  1.532503   \n",
      "1    1.117674  1.149699  4.585425  2.108281  5.101314  2.350121  1.547207   \n",
      "2    0.327476  0.328069  0.514216  0.381675  0.517488  0.397111  0.349512   \n",
      "3   -2.078694 -2.127759 -5.650001 -3.450293 -5.701553 -3.707247 -2.913210   \n",
      "4    1.304071  0.957116  3.365341  2.009995  4.592531  2.223063  0.894650   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "101  0.616062  0.619407  0.848101  0.706135  0.852392  0.722340  0.668911   \n",
      "102 -1.964573 -1.988015 -5.563418 -3.310695 -5.616186 -3.594878 -2.774131   \n",
      "103 -1.967430 -1.992013 -5.561485 -3.322947 -5.604410 -3.595474 -2.775255   \n",
      "104  1.169753  0.896168  3.438080  1.806481  4.145971  2.009257  0.973697   \n",
      "105  1.157285  0.890544  3.427339  1.804673  4.153811  1.996202  0.969830   \n",
      "\n",
      "           7         8         9   ...        90        91        92  \\\n",
      "0    0.628549  2.798235  1.360844  ...  3.103193  2.728358  1.457584   \n",
      "1    0.622527  2.787546  1.354910  ...  3.117675  2.723968  1.458201   \n",
      "2    0.380327  0.442964  0.415479  ...  0.461858  0.418533  0.337886   \n",
      "3   -3.416443 -4.469943 -4.010483  ... -4.779291 -4.057375 -2.617642   \n",
      "4    0.002260  1.777951  0.128189  ...  1.984546  2.599209  1.446060   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "101  0.702733  0.773002  0.742502  ...  0.793741  0.744360  0.651492   \n",
      "102 -3.293387 -4.370335 -3.885864  ... -4.674014 -3.930595 -2.501333   \n",
      "103 -3.294837 -4.368296 -3.890184  ... -4.674719 -3.932466 -2.488367   \n",
      "104  0.000073  1.871181  0.061527  ...  2.099250  2.283630  1.284882   \n",
      "105  0.000073  1.874299  0.061372  ...  2.074357  2.299212  1.283625   \n",
      "\n",
      "           93        94        95        96        97        98        99  \n",
      "0    2.417332  1.495726  6.318722  1.465419  5.691528  2.915743  3.963869  \n",
      "1    2.403735  1.491748  6.318990  1.460194  5.665010  2.866313  3.916208  \n",
      "2    0.399755  0.402669  0.569690  0.494730  0.540507  0.440995  0.486244  \n",
      "3   -3.748562 -3.797668 -6.533912 -5.322725 -6.056248 -4.425199 -5.198507  \n",
      "4    2.324261  0.229812  4.558701  0.074321  4.767923  2.064169  3.059424  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "101  0.726204  0.728820  0.899085  0.828092  0.873371  0.768756  0.819175  \n",
      "102 -3.638067 -3.676400 -6.456740 -5.236757 -5.980813 -4.324163 -5.098597  \n",
      "103 -3.636816 -3.674445 -6.455004 -5.227612 -5.965763 -4.322532 -5.095889  \n",
      "104  2.025691  0.160576  4.711224  0.014897  4.535202  2.145105  3.069746  \n",
      "105  2.033990  0.159891  4.780986  0.014659  4.514079  2.108041  3.025034  \n",
      "\n",
      "[106 rows x 100 columns]\n",
      "df_xa_pi_all_col\n",
      "           0         1         2         3         4         5         6   \\\n",
      "0    1.138498  1.247356  5.596232  2.240537  5.438786  2.549587  1.864880   \n",
      "1    1.132773  1.252517  5.633354  2.274469  5.479513  2.542712  1.889137   \n",
      "2    0.327687  0.327213  0.513237  0.382115  0.517123  0.397406  0.350648   \n",
      "3   -2.081361 -2.116226 -5.635698 -3.438375 -5.686220 -3.707606 -2.895337   \n",
      "4    1.375667  1.501651  5.827686  2.552581  5.524675  2.851415  2.202503   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "101  0.617291  0.619163  0.847561  0.705100  0.850946  0.722780  0.670025   \n",
      "102 -1.975995 -2.006630 -5.555829 -3.320410 -5.592757 -3.580164 -2.782947   \n",
      "103 -1.963687 -1.992199 -5.549678 -3.324220 -5.594392 -3.588539 -2.778664   \n",
      "104  1.358152  1.467681  5.813307  2.516918  5.561941  2.789511  2.149190   \n",
      "105  1.332836  1.473343  5.758184  2.520040  5.629854  2.833717  2.114621   \n",
      "\n",
      "           7         8         9   ...        90        91        92  \\\n",
      "0    2.468074  3.697121  3.153255  ...  4.168275  2.930113  1.545607   \n",
      "1    2.435351  3.670271  3.162853  ...  4.149037  2.935014  1.552682   \n",
      "2    0.379773  0.442664  0.414666  ...  0.460907  0.416636  0.336663   \n",
      "3   -3.418442 -4.459741 -3.993119  ... -4.762069 -4.037786 -2.631216   \n",
      "4    2.851545  4.096198  3.544858  ...  4.545524  3.217876  1.809801   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "101  0.703258  0.772489  0.741311  ...  0.792610  0.744273  0.651139   \n",
      "102 -3.290869 -4.361661 -3.874807  ... -4.676182 -3.931278 -2.505390   \n",
      "103 -3.290472 -4.359741 -3.891457  ... -4.663566 -3.912651 -2.501368   \n",
      "104  2.792820  4.061380  3.474620  ...  4.423407  3.215825  1.763348   \n",
      "105  2.792211  3.986962  3.515806  ...  4.433619  3.226918  1.784571   \n",
      "\n",
      "           93        94        95        96        97        98        99  \n",
      "0    2.604479  2.863527  7.477938  5.163789  6.311710  3.626437  4.763575  \n",
      "1    2.591585  2.894199  7.556033  5.127718  6.294883  3.599355  4.837521  \n",
      "2    0.399621  0.402086  0.568037  0.494223  0.539069  0.439766  0.485990  \n",
      "3   -3.745532 -3.791128 -6.520428 -5.324299 -6.042286 -4.420965 -5.178604  \n",
      "4    2.877938  3.254617  7.534499  5.450090  6.299078  3.972551  5.056610  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "101  0.725625  0.728020  0.900606  0.829188  0.873723  0.770569  0.818813  \n",
      "102 -3.632219 -3.664675 -6.445236 -5.222707 -5.958696 -4.313070 -5.088119  \n",
      "103 -3.625351 -3.679836 -6.444056 -5.210026 -5.963279 -4.306911 -5.080664  \n",
      "104  2.842051  3.178656  7.682437  5.330480  6.343365  3.901329  4.972744  \n",
      "105  2.846489  3.231948  7.568272  5.406454  6.383949  3.868135  5.014149  \n",
      "\n",
      "[106 rows x 100 columns]\n",
      "df_eval_pi_all_col\n",
      "       site  proxy  locRad  proxy_frac   Rscale  MC\n",
      "1       277   mgca       0           1  10000.0   0\n",
      "2       302  tex86       0           1  10000.0   0\n",
      "3       401   d18o       0           1  10000.0   0\n",
      "4       401   mgca       0           1  10000.0   0\n",
      "5       401   d18o       0           1  10000.0   0\n",
      "..      ...    ...     ...         ...      ...  ..\n",
      "101  Ancora  tex86       0           1  10000.0   0\n",
      "102  Ancora   d18o       0           1  10000.0   0\n",
      "103  Ancora   d18o       0           1  10000.0   0\n",
      "104  Ancora   mgca       0           1  10000.0   0\n",
      "105  Ancora   mgca       0           1  10000.0   0\n",
      "\n",
      "[87 rows x 6 columns]\n",
      "df_ob_pi_all_col\n",
      "            0\n",
      "1    3.789859\n",
      "2    0.608182\n",
      "3   -1.768513\n",
      "4    3.449635\n",
      "5   -1.734330\n",
      "..        ...\n",
      "101  0.927895\n",
      "102 -3.857000\n",
      "103 -3.307778\n",
      "104  4.362609\n",
      "105  3.414800\n",
      "\n",
      "[87 rows x 1 columns]\n",
      "df_xb_pi_all_col\n",
      "           0         1         2         3         4         5         6   \\\n",
      "1    1.117674  1.149699  4.585425  2.108281  5.101314  2.350121  1.547207   \n",
      "2    0.327476  0.328069  0.514216  0.381675  0.517488  0.397111  0.349512   \n",
      "3   -2.078694 -2.127759 -5.650001 -3.450293 -5.701553 -3.707247 -2.913210   \n",
      "4    1.304071  0.957116  3.365341  2.009995  4.592531  2.223063  0.894650   \n",
      "5   -2.088170 -2.117570 -5.660330 -3.452956 -5.698287 -3.720980 -2.899336   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "101  0.616062  0.619407  0.848101  0.706135  0.852392  0.722340  0.668911   \n",
      "102 -1.964573 -1.988015 -5.563418 -3.310695 -5.616186 -3.594878 -2.774131   \n",
      "103 -1.967430 -1.992013 -5.561485 -3.322947 -5.604410 -3.595474 -2.775255   \n",
      "104  1.169753  0.896168  3.438080  1.806481  4.145971  2.009257  0.973697   \n",
      "105  1.157285  0.890544  3.427339  1.804673  4.153811  1.996202  0.969830   \n",
      "\n",
      "           7         8         9   ...        90        91        92  \\\n",
      "1    0.622527  2.787546  1.354910  ...  3.117675  2.723968  1.458201   \n",
      "2    0.380327  0.442964  0.415479  ...  0.461858  0.418533  0.337886   \n",
      "3   -3.416443 -4.469943 -4.010483  ... -4.779291 -4.057375 -2.617642   \n",
      "4    0.002260  1.777951  0.128189  ...  1.984546  2.599209  1.446060   \n",
      "5   -3.418914 -4.475538 -4.007396  ... -4.777789 -4.046311 -2.617415   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "101  0.702733  0.773002  0.742502  ...  0.793741  0.744360  0.651492   \n",
      "102 -3.293387 -4.370335 -3.885864  ... -4.674014 -3.930595 -2.501333   \n",
      "103 -3.294837 -4.368296 -3.890184  ... -4.674719 -3.932466 -2.488367   \n",
      "104  0.000073  1.871181  0.061527  ...  2.099250  2.283630  1.284882   \n",
      "105  0.000073  1.874299  0.061372  ...  2.074357  2.299212  1.283625   \n",
      "\n",
      "           93        94        95        96        97        98        99  \n",
      "1    2.403735  1.491748  6.318990  1.460194  5.665010  2.866313  3.916208  \n",
      "2    0.399755  0.402669  0.569690  0.494730  0.540507  0.440995  0.486244  \n",
      "3   -3.748562 -3.797668 -6.533912 -5.322725 -6.056248 -4.425199 -5.198507  \n",
      "4    2.324261  0.229812  4.558701  0.074321  4.767923  2.064169  3.059424  \n",
      "5   -3.746783 -3.795996 -6.532993 -5.329564 -6.059408 -4.430681 -5.185864  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "101  0.726204  0.728820  0.899085  0.828092  0.873371  0.768756  0.819175  \n",
      "102 -3.638067 -3.676400 -6.456740 -5.236757 -5.980813 -4.324163 -5.098597  \n",
      "103 -3.636816 -3.674445 -6.455004 -5.227612 -5.965763 -4.322532 -5.095889  \n",
      "104  2.025691  0.160576  4.711224  0.014897  4.535202  2.145105  3.069746  \n",
      "105  2.033990  0.159891  4.780986  0.014659  4.514079  2.108041  3.025034  \n",
      "\n",
      "[87 rows x 100 columns]\n",
      "df_xa_pi_all_col\n",
      "           0         1         2         3         4         5         6   \\\n",
      "1    1.132773  1.252517  5.633354  2.274469  5.479513  2.542712  1.889137   \n",
      "2    0.327687  0.327213  0.513237  0.382115  0.517123  0.397406  0.350648   \n",
      "3   -2.081361 -2.116226 -5.635698 -3.438375 -5.686220 -3.707606 -2.895337   \n",
      "4    1.375667  1.501651  5.827686  2.552581  5.524675  2.851415  2.202503   \n",
      "5   -2.080406 -2.121212 -5.622741 -3.440772 -5.686234 -3.704964 -2.899721   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "101  0.617291  0.619163  0.847561  0.705100  0.850946  0.722780  0.670025   \n",
      "102 -1.975995 -2.006630 -5.555829 -3.320410 -5.592757 -3.580164 -2.782947   \n",
      "103 -1.963687 -1.992199 -5.549678 -3.324220 -5.594392 -3.588539 -2.778664   \n",
      "104  1.358152  1.467681  5.813307  2.516918  5.561941  2.789511  2.149190   \n",
      "105  1.332836  1.473343  5.758184  2.520040  5.629854  2.833717  2.114621   \n",
      "\n",
      "           7         8         9   ...        90        91        92  \\\n",
      "1    2.435351  3.670271  3.162853  ...  4.149037  2.935014  1.552682   \n",
      "2    0.379773  0.442664  0.414666  ...  0.460907  0.416636  0.336663   \n",
      "3   -3.418442 -4.459741 -3.993119  ... -4.762069 -4.037786 -2.631216   \n",
      "4    2.851545  4.096198  3.544858  ...  4.545524  3.217876  1.809801   \n",
      "5   -3.412066 -4.464374 -3.996683  ... -4.774403 -4.039193 -2.616417   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "101  0.703258  0.772489  0.741311  ...  0.792610  0.744273  0.651139   \n",
      "102 -3.290869 -4.361661 -3.874807  ... -4.676182 -3.931278 -2.505390   \n",
      "103 -3.290472 -4.359741 -3.891457  ... -4.663566 -3.912651 -2.501368   \n",
      "104  2.792820  4.061380  3.474620  ...  4.423407  3.215825  1.763348   \n",
      "105  2.792211  3.986962  3.515806  ...  4.433619  3.226918  1.784571   \n",
      "\n",
      "           93        94        95        96        97        98        99  \n",
      "1    2.591585  2.894199  7.556033  5.127718  6.294883  3.599355  4.837521  \n",
      "2    0.399621  0.402086  0.568037  0.494223  0.539069  0.439766  0.485990  \n",
      "3   -3.745532 -3.791128 -6.520428 -5.324299 -6.042286 -4.420965 -5.178604  \n",
      "4    2.877938  3.254617  7.534499  5.450090  6.299078  3.972551  5.056610  \n",
      "5   -3.732665 -3.797423 -6.527500 -5.316361 -6.045048 -4.414910 -5.184579  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "101  0.725625  0.728020  0.900606  0.829188  0.873723  0.770569  0.818813  \n",
      "102 -3.632219 -3.664675 -6.445236 -5.222707 -5.958696 -4.313070 -5.088119  \n",
      "103 -3.625351 -3.679836 -6.444056 -5.210026 -5.963279 -4.306911 -5.080664  \n",
      "104  2.842051  3.178656  7.682437  5.330480  6.343365  3.901329  4.972744  \n",
      "105  2.846489  3.231948  7.568272  5.406454  6.383949  3.868135  5.014149  \n",
      "\n",
      "[87 rows x 100 columns]\n",
      "assimilated proxy i caco3\n",
      "0\n",
      "assimilated proxy i tex86\n",
      "29\n",
      "assimilated proxy i mgca\n",
      "28\n",
      "RMSE of Ob vs. Xb 1.6921100939947613\n",
      "CE of Ob vs. Xb -1.9673542636607397\n",
      "r^2 of Ob vs. Xb 0.14225174273572777\n",
      "\n",
      "RMSE of Ob vs. Xa 1.3515482635190748\n",
      "CE of Ob vs. Xb -0.8931075343894779\n",
      "r^2 of Ob vs. Xa 0.14646304217145784\n",
      " --- \n",
      "\n",
      " This loop done \n",
      "save file @ /Users/mingsongli/Dropbox/git/deepDA/mlwrk/wrk/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_d18o_MC1_frac1_rscale_loc_0_proxy_frac_1_Rscale_10000.0_df_zscore_all.csv\n",
      ">>  Read nc file: /volumes/DA/DeepDA/wrk/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_d18o_MC1_frac1_rscale/_loc_0_proxy_frac_1_Rscale_5000.0_MC_0.nc\n",
      "First variable: all MC mean\n",
      "[33.066853]\n",
      "All variable. Mean of variables x reconi\n",
      "[[  33.066853   33.122475]\n",
      " [  30.112548   30.176982]\n",
      " [1656.571533 1664.287842]\n",
      " [  33.628428   33.627727]\n",
      " [   7.544986    7.542726]\n",
      " [   5.573421    5.55089 ]\n",
      " [  17.267021   17.327458]\n",
      " [  38.406881   38.32075 ]\n",
      " [   0.002114    0.002113]]\n",
      "\n",
      "Step #1: read data - Done\n",
      "\n",
      "\n",
      "DA - Summary of global mean and standard deviation\n",
      "\n",
      "ocn_sur_temp\n",
      "atm_temp\n",
      "atm_pCO2\n",
      "ocn_sur_sal\n",
      "misc_pH\n",
      "carb_sur_ohm_cal\n",
      "ocn_ben_temp\n",
      "sed_CaCO3\n",
      "ocn_sur_ALK\n",
      "saved @\n",
      "/Users/mingsongli/Dropbox/git/deepDA/mlwrk/wrk/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_d18o_MC1_frac1_rscale_loc_0_proxy_frac_1_Rscale_5000.0.summary.csv\n",
      "\n",
      "Step #2: summary - Done\n",
      "\n",
      "DA - Read proxy, prior, and posterior, standardize\n",
      "\n",
      "Read first hdf5 file /volumes/DA/DeepDA/wrk/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_d18o_MC1_frac1_rscale/_loc_0_proxy_frac_1_Rscale_5000.0_MC_0.hdf5 to get the number of withold datasets.\n",
      " Site withhold length ： 53\n",
      "    /volumes/DA/DeepDA/wrk/petmproxy3slices_v0.0.20_w_deepmip.csv_petm29_v20_20210805_d18o_MC1_frac1_rscale/_loc_0_proxy_frac_1_Rscale_5000.0_MC_0.nc\n",
      "Site withhold:       ['277' '277' '302' '401' '401' '401' '527' '527' '690' '690' '865' '865'\n",
      " '865' '959' '1172' '1209' '1209' 'U1443' 'BR' 'BR' 'BR' 'BR' 'BR' 'fur'\n",
      " 'fur' 'GreatBelt' 'harrell' 'ib10a' 'ib10b' 'lodo' 'lodo' 'M0077'\n",
      " 'Milville' 'Milville' 'sq' 'sq' 'sq' 'sq' 'sq' 'tanzania' 'tanzania'\n",
      " 'tumey' 'tumey' 'waipara' 'Siberia' 'WL' 'WL' 'WL' 'Ancora' 'Ancora'\n",
      " 'Ancora' 'Ancora' 'Ancora']\n",
      "Proxy        :       ['mgca_morozovella:barker' 'mgca_acarinina:barker' 'tex86' 'd18o_m.subb'\n",
      " 'mgca_m.subb:barker' 'd18o_a.soldadoensis' 'mgca_acarinina:barker'\n",
      " 'mgca_m.subb:barker' 'd18o_acarinina' 'mgca_acarinina:reductive'\n",
      " 'd18o_morozovella' 'mgca_morozovella:barker' 'mgca_acarinina:barker'\n",
      " 'tex86' 'tex86' 'mgca_morozovella:reductive' 'mgca_acarinina:reductive'\n",
      " 'mgca_morozovella:barker' 'tex86' 'mgca_acarinina:reductive'\n",
      " 'mgca_morozovella:reductive' 'd18o_acarinina' 'd18o_morozovella' 'tex86'\n",
      " 'tex86' 'tex86' 'tex86' 'tex86' 'tex86' 'd18o_acarinina'\n",
      " 'd18o_morozovella' 'tex86' 'd18o_acarinina' 'd18o_morozovella'\n",
      " 'd18o_morozovella' 'd18o_acarinina' 'mgca_morozovella:reductive'\n",
      " 'mgca_acarinina:reductive' 'tex86' 'd18o_morozovella'\n",
      " 'd18o_a.soldadoensis' 'd18o_acarinina' 'd18o_morozovella' 'tex86' 'tex86'\n",
      " 'd18o_morozovella' 'd18o_acarinina' 'tex86' 'tex86' 'd18o_morozovella'\n",
      " 'd18o_acarinina' 'mgca_morozovella:reductive' 'mgca_acarinina:reductive']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c467c794a8fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    439\u001b[0m                             \u001b[0mXa_ph_i\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXa_ph_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreconi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdum_imax\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdum_jmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                             \u001b[0mYe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepDA_psm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal_ye_cgenie_d18O\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myml_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msites_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXa_reconi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXa_sal_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXa_ph_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproxy_assim2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproxy_psm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdum_lon_offset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdum_imax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdum_jmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                             \u001b[0mxa_stat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocRadi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproxy_fraci\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRscalei\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMCi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreconi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/git/deepDA/DeepDA_lib/DeepDA_psm.py\u001b[0m in \u001b[0;36mcal_ye_cgenie_d18O\u001b[0;34m(yml_dict, proxies, j, Xb, Xb_sal, Xb_ph, proxy_assim2, proxy_psm_type, dum_lon_offset, dum_imax, dum_jmax)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mprediction_d18O_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayfox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_d18oc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior_1grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md18o_localsw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# pool model for bayfox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0mprediction_d18O\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mbayfox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpHCorrect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_d18O_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprior_1grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msalinity_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mph_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtype_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0mYe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_d18O\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/git/deepDA/src/bayfox/bayfox/predict.py\u001b[0m in \u001b[0;36mpHCorrect\u001b[0;34m(d18oc, seatemp, S, pH, cortype)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# Orbulina regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mpH_cor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.27\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpH\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mPIpH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0md18opH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md18oc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpH_cor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md18oc_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md18oc_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdcErr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md18oc_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md18oc_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# define the 1-sigma error. Best estimate based on culture studies is 0.27\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##\n",
    "# updated version, now pre-PETM and peak-PETM (and more) are forced to be 1 columns\n",
    "##\n",
    "\n",
    "# debug\n",
    "#Rscalen = 1\n",
    "# debug\n",
    "\n",
    "for locRadi in range(locRadn):\n",
    "    locRad = local_rad_list[locRadi]\n",
    "    if locRad is None:\n",
    "        locRadv = 0 # for filename only\n",
    "    else:\n",
    "        locRadv = locRad\n",
    "    for proxy_fraci in range(proxy_fracn):\n",
    "        proxy_frac = proxy_frac_list[proxy_fraci]\n",
    "\n",
    "        for Rscalei in range(Rscalen):\n",
    "            Rscale = Rscale_list[Rscalei]\n",
    "\n",
    "            savefilename_add = '_loc_'+ str(locRadv)+'_proxy_frac_'+ str(proxy_frac)+'_Rscale_'+str(Rscale)\n",
    "\n",
    "            for MCi in range(MCn):\n",
    "                # NetCDF file name\n",
    "                filename_short = '_loc_', str(locRadv),'_proxy_frac_', str(proxy_frac),'_Rscale_',str(Rscale),'_MC_',str(MCi) \n",
    "                nc_filename = MC_dir + ''.join(filename_short) + '.nc'\n",
    "                hdf5name    = MC_dir + ''.join(filename_short) + '.hdf5'\n",
    "\n",
    "                print('>>  Read nc file: {}'.format(nc_filename))\n",
    "\n",
    "                for Xa2d_vari in range(prior_variable_len):\n",
    "\n",
    "                    Xa_full_name_vari = prior_variable_dict[Xa2d_vari] +'_Xa_full'\n",
    "                    Xa_mean_name_vari = prior_variable_dict[Xa2d_vari] +'_Xa_mean'\n",
    "                    Xa_variance_name_vari = prior_variable_dict[Xa2d_vari] +'_Xa_variance'\n",
    "                    Xa_full_vari = Dataset(nc_filename).variables[Xa_full_name_vari][:]\n",
    "                    Xa_mean_vari = Dataset(nc_filename).variables[Xa_mean_name_vari][:]\n",
    "                    Xa_variance_vari = Dataset(nc_filename).variables[Xa_variance_name_vari][:]\n",
    "\n",
    "                    if prior_variable_dict[Xa2d_vari] in limit_hard_keys:\n",
    "                        # some variables have hard limitation: e.g., CaCO3 = [0, 100]                        \n",
    "                        lim_min = yml_dict['prior'][prior_source]['limit_hard'][prior_variable_dict[Xa2d_vari]]['lim_min']\n",
    "                        lim_max = yml_dict['prior'][prior_source]['limit_hard'][prior_variable_dict[Xa2d_vari]]['lim_max']\n",
    "                        #print('limit min {} and max {}'.format(lim_min, lim_max))\n",
    "                        if lim_min:\n",
    "                            if np.any(Xa_full_vari<lim_min):\n",
    "                                Xa_full_vari[Xa_full_vari<lim_min] = lim_min\n",
    "                                Xa_mean_vari = np.mean(Xa_full_vari,axis=2)\n",
    "                                Xa_variance_vari = np.var(Xa_full_vari,axis=2)\n",
    "                                print('>>    Force {} value to be >= {}'.format(prior_variable_dict[Xa2d_vari],lim_min))\n",
    "                        if lim_max:\n",
    "                            if np.any(Xa_full_vari>lim_max):\n",
    "                                Xa_full_vari[Xa_full_vari>lim_max] = lim_max\n",
    "                                Xa_mean_vari = np.mean(Xa_full_vari,axis=2)\n",
    "                                Xa_variance_vari = np.var(Xa_full_vari,axis=2)\n",
    "                                print('>>    Force {} value to be <= {}'.format(prior_variable_dict[Xa2d_vari], lim_max))\n",
    "\n",
    "                    for reconi in range(recon_period_len):\n",
    "\n",
    "                        Xa_full_reconi = Xa_full_vari[:,:,:,0,reconi].reshape((dum_ijmax,nens))\n",
    "                        Xa_full_reconi_mean = np.nanmean(Xa_full_reconi,axis=0)\n",
    "\n",
    "                        Xa_mean_reconi = Xa_mean_vari[:,:,0,reconi]\n",
    "                        Xa2d_all_np[:,:,locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = np.copy(Xa_mean_vari[:,:,0,reconi])\n",
    "                        Xa_mean_reconi_mean = np.nanmean(Xa_mean_reconi)\n",
    "\n",
    "                        Xa_variance_reconi = Xa_variance_vari[:,:,0,reconi]\n",
    "                        Xa2d_allstd_np[:,:,locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = Xa_variance_vari[:,:,0,reconi]\n",
    "                        Xa_std_reconi_mean = np.sqrt(np.nanmean(Xa_variance_reconi))\n",
    "\n",
    "                        #print('>>  reconi = {}, mean is {}, std is {}'.format(reconi, Xa_mean_reconi_mean, Xa_std_reconi_mean))\n",
    "                        Xa2d_full_np[locRadi,proxy_fraci,Rscalei,MCi*nens:(MCi+1)*nens,Xa2d_vari,reconi] = Xa_full_reconi_mean\n",
    "                        Xa2d_mean_np[locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = Xa_mean_reconi_mean\n",
    "                        Xa2d_std_np[locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = Xa_std_reconi_mean\n",
    "            print('First variable: all MC mean')\n",
    "            print(Xa2d_mean_np[locRadi,proxy_fraci,Rscalei,:,0,0])\n",
    "\n",
    "            Xa2d_all_np = np.ma.masked_where(Xa2d_all_np > 9.0e+36, Xa2d_all_np)\n",
    "            Xa2d_allstd_np = np.ma.masked_where(Xa2d_all_np > 9.0e+36, Xa2d_allstd_np)\n",
    "            for Xa2d_vari in range(prior_variable_len):\n",
    "                for reconi in range(recon_period_len):\n",
    "                    Xa2d_mean_np2[locRadi,proxy_fraci,Rscalei,Xa2d_vari,reconi] = np.nanmean(Xa2d_all_np[:,:,locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi])\n",
    "                    Xa2d_std_np2[locRadi,proxy_fraci,Rscalei,Xa2d_vari,reconi] = np.sqrt(np.nanmean(Xa2d_allstd_np[:,:,locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi]))\n",
    "\n",
    "            np.set_printoptions(precision=6, suppress=True)\n",
    "            if log_level > 1:\n",
    "                print('All variable. Mean of variables x reconi')\n",
    "                print('{}'.format(Xa2d_mean_np2[locRadi,proxy_fraci,Rscalei,:,:]))\n",
    "            #print('std  of variables x reconi')\n",
    "            #print('{}'.format(Xa2d_std_np2))\n",
    "\n",
    "            print('')\n",
    "            print('Step #1: read data - Done')\n",
    "            print('')\n",
    "\n",
    "            # Calculate mean and std of each variable for each time slice\n",
    "            # plot the ensemble values\n",
    "\n",
    "            df = pandas.DataFrame()\n",
    "            print('')\n",
    "            print('DA - Summary of global mean and standard deviation')\n",
    "            print('')\n",
    "\n",
    "            if showplot:\n",
    "                fig, (ax0, ax1, ax2, ax3) = plt.subplots(nrows=4, figsize=(3, 6))\n",
    "                if recon_period_len>1:\n",
    "                    fig2, (ax10, ax11, ax12, ax13) = plt.subplots(nrows=4, figsize=(3, 6))\n",
    "                params = {'mathtext.default': 'regular' }\n",
    "                plt.rcParams.update(params)\n",
    "                #plt.rcParams.update({'figure.figsize':(5,3), 'figure.dpi':110})\n",
    "                #fig.suptitle('DA')\n",
    "\n",
    "            # 2d variables\n",
    "            for Xa2d_vari in range(prior_variable_len):\n",
    "\n",
    "                print(prior_variable_dict[Xa2d_vari])\n",
    "                datadf = {'field':prior_variable_dict[Xa2d_vari],'mean':[np.nan],'std':[np.nan],\n",
    "                          '2.5%':[np.nan],'5%':[np.nan],'25%':[np.nan],'median':[np.nan],'75%':[np.nan],'95%':[np.nan],'97.5%':[np.nan],'label':''}\n",
    "                df2 = pandas.DataFrame(datadf, index=[Xa2d_vari])\n",
    "                df = pandas.concat([df,df2])\n",
    "\n",
    "                sst_std_mc = np.std(Xa2d_mean_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,:],axis=0)\n",
    "                if log_level > 2:\n",
    "                    print('  _locR '+str(locRadv)+' proxy_frac '+str(proxy_frac)+' scaled r '+str(Rscale))\n",
    "\n",
    "                for reconi in range(recon_period_len):\n",
    "\n",
    "                    meani = np.nanmean(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi])\n",
    "                    stdi = np.std(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi])\n",
    "                    perc = np.percentile(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi],np.array([2.5, 5, 25, 50, 75, 95, 97.5]))\n",
    "                    datadf = {'field':'','mean':[meani],'std':[stdi],\n",
    "                              '2.5%':[perc[0]],'5%':[perc[1]],'25%':[perc[2]],'median':[perc[3]],'75%':[perc[4]],'95%':[perc[5]],'97.5%':[perc[6]],'label':label_all[reconi]}\n",
    "                    df2 = pandas.DataFrame(data = datadf, index=[Xa2d_vari])\n",
    "                    df = pandas.concat([df,df2])\n",
    "                    if log_level > 2:\n",
    "                        print('    {:.3f} ± {:.3f}: {}'.format(meani, stdi, label_all[reconi]))\n",
    "\n",
    "                    if recon_period_len>2:\n",
    "                        warmpeak = Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,1]-Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,0]\n",
    "                        #warmbody = Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,2]-Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,0]\n",
    "                        coolpeak = Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,2]-Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,1]\n",
    "                        warmpeakmean = np.nanmean(warmpeak)\n",
    "                        warmpeakstd  = np.std(warmpeak)\n",
    "                        warmperc = np.percentile(warmpeak,np.array([2.5, 5, 25, 50, 75, 95, 97.5]))\n",
    "                        coolpeakmean = np.nanmean(coolpeak)\n",
    "                        coolpeakstd  = np.std(coolpeak)\n",
    "                        coolperc = np.percentile(coolpeak,np.array([2.5, 5, 25, 50, 75, 95, 97.5]))\n",
    "\n",
    "                if recon_period_len>2:\n",
    "                    df2 = pandas.DataFrame({'field':'','mean':[warmpeakmean],'std':[warmpeakstd],\n",
    "                                            '2.5%':[warmperc[0]],'5%':[warmperc[1]],'25%':[warmperc[2]],'median':[warmperc[3]],'75%':[warmperc[4]],'95%':[warmperc[5]],'97.5%':[warmperc[6]],'label':'Peak_warming'}, index=[Xa2d_vari])\n",
    "                    df3 = pandas.DataFrame({'field':'','mean':[coolpeakmean],'std':[coolpeakstd],\n",
    "                                            '2.5%':[coolperc[0]],'5%':[coolperc[1]],'25%':[coolperc[2]],'median':[coolperc[3]],'75%':[coolperc[4]],'95%':[coolperc[5]],'97.5%':[coolperc[6]],'label':'Peak_cooling'}, index=[Xa2d_vari])\n",
    "                    df = pandas.concat([df,df2,df3])\n",
    "                    if log_level > 2:\n",
    "                        print('    {:.6f} ± {:.6f}: peak warming'.format(warmpeakmean,warmpeakstd))\n",
    "                        print('    {:.6f} ± {:.6f}: peak cooling'.format(coolpeakmean,coolpeakstd))\n",
    "\n",
    "                if showplot:\n",
    "                    for reconi in range(recon_period_len):\n",
    "                        if reconi == 3:\n",
    "                            continue\n",
    "                        kwargs = dict(alpha=0.5, bins=50)\n",
    "\n",
    "                        if Xa2d_vari == 0:\n",
    "                            ax0.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                            ax0.set_ylabel('#')\n",
    "                            ax0.set_xlabel('SST (\\u00B0C)')\n",
    "                            ax0.tick_params(labelsize='small')\n",
    "                            ax0.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 1:\n",
    "                            ax1.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                            ax1.set_ylabel('#')\n",
    "                            ax1.set_xlabel('SAT (\\u00B0C)')\n",
    "                            ax1.tick_params(labelsize='small')\n",
    "                            ax1.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 2:\n",
    "                            ax2.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                            ax2.set_ylabel('#')\n",
    "                            ax2.set_xlabel('$\\it{p}$CO$_2$ (ppm)')\n",
    "                            ax2.set_xlim(0, 2800)\n",
    "                            ax2.legend(prop={'size': 6.5})  \n",
    "                            ax2.tick_params(labelsize='small')\n",
    "                            ax2.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        #if Xa2d_vari == 3:\n",
    "                        #    ax3.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                        #    ax3.set_ylabel('Number')\n",
    "                        #    ax3.set_xlabel('Salinity (PSU)')\n",
    "                        if Xa2d_vari == 4:\n",
    "                            ax3.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                            ax3.set_ylabel('#')\n",
    "                            ax3.set_xlabel('pH')     \n",
    "                            ax3.tick_params(labelsize='small')\n",
    "                            ax3.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        #if Xa2d_vari == 6:\n",
    "                        #    ax5.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                        #    ax5.set_ylabel('Number')\n",
    "                        #    ax5.set_xlabel('$CaCO_3$ (%)')\n",
    "                    fig.tight_layout()\n",
    "\n",
    "                    if recon_period_len>1:\n",
    "                        if Xa2d_vari == 0:                    \n",
    "                            ax10.hist(warmpeak, **kwargs, color = \"#ff7f0e\", label = 'warming')\n",
    "                            ax10.hist(coolpeak, **kwargs, color = \"#2ca02c\", label = 'cooling')\n",
    "                            ax10.set_ylabel('#')\n",
    "                            ax10.set_xlabel('\\u0394SST (\\u00B0C)')                        \n",
    "                            ax10.legend(prop={'size': 6.5});\n",
    "                            ax10.tick_params(labelsize='small')\n",
    "                            ax10.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 1:\n",
    "                            ax11.hist(warmpeak, **kwargs, color = \"#ff7f0e\")\n",
    "                            ax11.hist(coolpeak, **kwargs, color = \"#2ca02c\")\n",
    "                            ax11.set_ylabel('#')\n",
    "                            ax11.set_xlabel('\\u0394SAT (\\u00B0C)')\n",
    "                            ax11.tick_params(labelsize='small')\n",
    "                            ax11.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 2:\n",
    "                            ax12.hist(warmpeak, **kwargs, color = \"#ff7f0e\")\n",
    "                            ax12.hist(coolpeak, **kwargs, color = \"#2ca02c\")\n",
    "                            ax12.set_ylabel('#')\n",
    "                            ax12.set_xlabel('\\u0394$\\it{p}$CO$_2$ (ppm)')\n",
    "                            ax12.tick_params(labelsize='small')\n",
    "                            ax12.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 4:\n",
    "                            ax13.hist(warmpeak, **kwargs, color = \"#ff7f0e\")\n",
    "                            ax13.hist(coolpeak, **kwargs, color = \"#2ca02c\")\n",
    "                            ax13.set_ylabel('#')\n",
    "                            ax13.set_xlabel('\\u0394pH')\n",
    "                            ax13.tick_params(labelsize='small')\n",
    "                            ax13.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        fig2.tight_layout()\n",
    "\n",
    "            if showplot:\n",
    "                fig.savefig(yml_dict['core']['proj_dir']+'/wrk/'+en+'.summary.pdf')\n",
    "                if recon_period_len > 1:\n",
    "                    fig2.savefig(yml_dict['core']['proj_dir']+'/wrk/'+en+'.delta.pdf')\n",
    "\n",
    "            # print and save excel\n",
    "            if savesummary_slice:\n",
    "                print('saved @')\n",
    "                fullname = yml_dict['core']['proj_dir']+'/wrk/'+en+savefilename_add+'.summary.csv'\n",
    "                print(fullname)\n",
    "                df.to_csv(fullname)\n",
    "\n",
    "            print('')\n",
    "            print('Step #2: summary - Done')\n",
    "            print('')\n",
    "\n",
    "\n",
    "\n",
    "            ### Purpose of this block\n",
    "            # Prepare data for verification\n",
    "            #\n",
    "            ### Steps\n",
    "            # 1. Prepare matrix for data saving: proxy, prior, posterior; std or not\n",
    "            # 2. calculate and save each Monte Carlo runs\n",
    "\n",
    "            #####################    User defined start   #####################\n",
    "            if log_level > 1:\n",
    "                print('DA - Read proxy, prior, and posterior, standardize')\n",
    "                print('')\n",
    "            #####################    User defined end     #####################\n",
    "\n",
    "            df_eval = pandas.DataFrame()\n",
    "            df_ob   = pandas.DataFrame()\n",
    "            df_xb   = pandas.DataFrame()\n",
    "            df_xa   = pandas.DataFrame()\n",
    "\n",
    "            # Get the sites_withhold_len\n",
    "\n",
    "            #locRad = local_rad_list[0]\n",
    "            #if locRad is None:\n",
    "            #    locRadv = 0 # for filename only\n",
    "            #else:\n",
    "            #    locRadv = locRad\n",
    "\n",
    "            #proxy_frac = proxy_frac_list[0]\n",
    "            #Rscale = Rscale_list[0]\n",
    "            filename_short = '_loc_', str(locRadv),'_proxy_frac_', str(proxy_frac),'_Rscale_',str(Rscale),'_MC_0.hdf5'\n",
    "            hdf5name = MC_dir + ''.join(filename_short)\n",
    "            if log_level > 1:\n",
    "                print('Read first hdf5 file {} to get the number of withold datasets.'.format(hdf5name))\n",
    "            if proxy_eval_list:\n",
    "                sites_eval = proxy_select  # if use evaluate list, more than the leave-1-out model\n",
    "            else:\n",
    "                sites_eval = pandas.read_hdf(hdf5name, 'sites_eval')  # if use the default list, less than the leave-1-out model\n",
    "\n",
    "            sites_withhold_len  = len(sites_eval)\n",
    "            \n",
    "            if log_level > 1:\n",
    "                print(' Site withhold length ： {}'.format(sites_withhold_len))\n",
    "\n",
    "            data_psm_d18o_find = 0\n",
    "            data_psm_mgca_find = 0\n",
    "            if 'Marine sediments_mgca_pooled_bcp' in proxy_list or 'Marine sediments_mgca_pooled_red' in proxy_list:\n",
    "                data_psm_mgca_find = 1\n",
    "            \n",
    "            # debug:   force the DA to calculate Xb_sal, Xb_ph and Xb_sal, etc.\n",
    "            data_psm_mgca_find = 1\n",
    "            # debug:   end\n",
    "            \n",
    "            if 'Marine sediments_d18o_pooled' in proxy_list:\n",
    "                data_psm_d18o_find = 1\n",
    "\n",
    "            # Prepare empty matrix for saving the data of proxy, prior, and posterior\n",
    "            ob_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, recon_period_len*2, sites_withhold_len), np.nan)\n",
    "            xb_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, sites_withhold_len), np.nan)   # save full prior for withhold data\n",
    "            xa_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, recon_period_len, sites_withhold_len), np.nan)\n",
    "\n",
    "            df_ind = 0\n",
    "\n",
    "            # columns name for the observation\n",
    "            df_ind_recon = []\n",
    "\n",
    "            for reconi in range(recon_period_len):\n",
    "                df_ind_recon_i = [data_period_id[reconi]] + [data_period_idstd[reconi]]\n",
    "                df_ind_recon = df_ind_recon + df_ind_recon_i\n",
    "\n",
    "            if log_level > 2:\n",
    "                print(df_ind_recon)\n",
    "\n",
    "\n",
    "            for MCi in range(MCn):\n",
    "            #for MCi in range(1):\n",
    "                # NetCDF file name\n",
    "                filename_short = '_loc_', str(locRadv),'_proxy_frac_', str(proxy_frac),'_Rscale_',str(Rscale),'_MC_' + str(MCi)\n",
    "                nc_filename = MC_dir + ''.join(filename_short) + '.nc'\n",
    "                print('    {}'.format(nc_filename))\n",
    "                hdf5name    = MC_dir + ''.join(filename_short) + '.hdf5'\n",
    "\n",
    "                if data_psm_mgca_find == 1:\n",
    "                    with h5py.File(hdf5name, 'r') as f:\n",
    "                        Xb_sal = np.copy(f.get('Xb_sal'))\n",
    "                        if log_level > 3:\n",
    "                            print(Xb_sal.shape)\n",
    "                        Xb_omega = np.copy((f.get('Xb_omega')))\n",
    "                        Xb_ph = np.copy(f.get('Xb_ph'))\n",
    "                    Xa_sal_full = Dataset(nc_filename).variables['ocn_sur_sal_Xa_full']\n",
    "                    Xa_ph_full  = Dataset(nc_filename).variables['misc_pH_Xa_full']\n",
    "                    Xa_omega_full = Dataset(nc_filename).variables['carb_sur_ohm_cal_Xa_full']\n",
    "\n",
    "                elif data_psm_d18o_find == 1:\n",
    "                    with h5py.File(hdf5name, 'r') as f:\n",
    "                        Xb_sal = np.copy(f.get('Xb_sal'))\n",
    "                        if log_level > 3:\n",
    "                            print(Xb_sal.shape)\n",
    "                        Xb_ph = np.copy(f.get('Xb_ph'))\n",
    "                    Xa_sal_full = Dataset(nc_filename).variables['ocn_sur_sal_Xa_full']\n",
    "                    Xa_ph_full  = Dataset(nc_filename).variables['misc_pH_Xa_full']\n",
    "\n",
    "\n",
    "                ### Read Proxy ###\n",
    "                proxies = pandas.read_hdf(hdf5name, 'proxies')\n",
    "                #prior_variable_dict = pandas.read_hdf(hdf5name, 'prior_variable_dict')\n",
    "\n",
    "                if proxy_frac <= 1.0:\n",
    "                    if proxy_eval_list:\n",
    "                        sites_eval = proxy_select  # if use evaluate list, more than the leave-1-out model\n",
    "                    else:\n",
    "                        sites_eval = pandas.read_hdf(hdf5name, 'sites_eval')\n",
    "                    sites_withhold_len  = len(sites_eval)\n",
    "                    if log_level > 1:\n",
    "                        print('Site withhold:       {}'.format(sites_eval['Site'].values))\n",
    "                        print('Proxy        :       {}'.format(sites_eval['Proxy'].values))\n",
    "\n",
    "                proxy_psm_type_dict_df = pandas.read_hdf(hdf5name, 'proxy_psm_type_dict_df')\n",
    "                proxy_psm_type_dict_list = proxy_psm_type_dict_df[0].values.tolist()\n",
    "\n",
    "                for j in range(sites_withhold_len):\n",
    "                    data_psm_type = sites_eval['Proxy'][j]\n",
    "                    for key, value in proxy_assim2.items():\n",
    "                        if data_psm_type in value:\n",
    "                            #print(proxy_psm_type[key])\n",
    "                            key0 = key\n",
    "                            psm_required_variable_key = list(yml_dict['psm'][proxy_psm_type[key]]['psm_required_variables'].keys())[0]\n",
    "                            xb_key = psm_required_variable_key+'_Xb_full'\n",
    "                            xa_key = psm_required_variable_key+'_Xa_full'\n",
    "                            #print('xa_key is {}'.format(xa_key))\n",
    "                            Xb_full_field0 = Dataset(nc_filename).variables[xb_key] #\n",
    "                            Xb_full_field0 = Xb_full_field0[:,:,:,0].reshape(dum_imax*dum_jmax, nens)\n",
    "                            Xa_full_field0 = Dataset(nc_filename).variables[xa_key]\n",
    "\n",
    "                    if proxy_psm_type[key0] in ['bayesreg_tex86', 'cgenie_caco3']:\n",
    "                        if proxy_psm_type[key0] in ['bayesreg_tex86']:\n",
    "                            proxy_i = 'tex86'\n",
    "                        else:\n",
    "                            proxy_i = 'caco3'\n",
    "                        Ye = DeepDA_psm.cal_ye_cgenie(yml_dict,sites_eval,j,Xb_full_field0,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                        xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(Ye)\n",
    "\n",
    "                        #print('Prior Ye is {:.6f}'.format(np.mean(Ye)))\n",
    "\n",
    "                        for reconi in range(recon_period_len):\n",
    "\n",
    "                            Xa_reconi = np.copy(Xa_full_field0[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "\n",
    "                            Ye = DeepDA_psm.cal_ye_cgenie(yml_dict,sites_eval,j,Xa_reconi,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                            #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j]   = np.mean(Ye)\n",
    "                            #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi+1][j] = np.var(Ye)\n",
    "                            xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(Ye)\n",
    "                            #print('Analysis Ye is {:.6f}'.format(np.mean(Ye)))\n",
    "                            #ob_stat[j][reconi*2]   = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                            ob_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j] = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                            # error\n",
    "                            if ~np.isnan(sites_eval[data_period_id[reconi]][j]):\n",
    "\n",
    "                                if proxy_psm_type[key0] in ['bayesreg_tex86']:\n",
    "\n",
    "                                    if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_tex86(31) + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                    else:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_tex86(31)\n",
    "\n",
    "                                if proxy_psm_type[key0] in ['cgenie_caco3','cgenie_caco3_13c']:\n",
    "\n",
    "                                    psm_error = yml_dict['psm'][proxy_psm_type[key0]]['psm_error']\n",
    "\n",
    "                                    if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = psm_error + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                    else:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = psm_error\n",
    "\n",
    "                    elif proxy_psm_type[key0] in ['bayesreg_d18o_pooled']:\n",
    "\n",
    "                        proxy_i = 'd18o'\n",
    "\n",
    "                        Ye = DeepDA_psm.cal_ye_cgenie_d18O(yml_dict,sites_eval,j,Xb_full_field0,Xb_sal,Xb_ph,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                        xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(Ye)\n",
    "\n",
    "                        for reconi in range(recon_period_len):\n",
    "\n",
    "                            Xa_reconi = np.copy(Xa_full_field0[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                            Xa_sal_i  = np.copy(Xa_sal_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                            Xa_ph_i   = np.copy(Xa_ph_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "\n",
    "                            Ye = DeepDA_psm.cal_ye_cgenie_d18O(yml_dict,sites_eval,j,Xa_reconi,Xa_sal_i,Xa_ph_i,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                            xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(Ye)\n",
    "\n",
    "                            ob_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j] = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                            # error\n",
    "                            if ~np.isnan(sites_eval[data_period_id[reconi]][j]):\n",
    "\n",
    "                                if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                    ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_d18o(15) + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                else:\n",
    "                                    ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_d18o(15)\n",
    "\n",
    "                    elif proxy_psm_type[key0] in ['bayesreg_mgca_pooled_bcp', 'bayesreg_mgca_pooled_red']:\n",
    "                        proxy_i = 'mgca'\n",
    "                        spp = 'all'\n",
    "                        cleaningr = np.tile(np.array([1]),nens)\n",
    "                        cleaningb = np.tile(np.array([0]),nens)\n",
    "\n",
    "                        if proxy_psm_type[key0] in ['bayesreg_mgca_pooled_red']:\n",
    "                            clearning_one = cleaningr\n",
    "                            proxy_explain = 'reductive'\n",
    "\n",
    "                        elif proxy_psm_type[key0] in ['bayesreg_mgca_pooled_bcp']:\n",
    "                            clearning_one = cleaningb\n",
    "                            proxy_explain = 'barker'\n",
    "\n",
    "                        Ye = DeepDA_psm.cal_ye_cgenie_mgca(yml_dict,sites_eval,j,Xb_full_field0,proxy_psm_type[key0],dum_lon_offset,dum_imax,dum_jmax,Xb_sal,Xb_ph,Xb_omega,geologic_age)\n",
    "\n",
    "                        if psm_baymag_ln in ['yes']:\n",
    "                            xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(np.exp(Ye))\n",
    "                        else:\n",
    "                            xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(Ye)\n",
    "\n",
    "                        #Xa_sal_full = Dataset(nc_filename).variables['ocn_sur_sal_Xa_full']\n",
    "                        #Xa_ph_full  = Dataset(nc_filename).variables['misc_pH_Xa_full']\n",
    "                        #Xa_omega_full = Dataset(nc_filename).variables['carb_sur_ohm_cal_Xa_full']\n",
    "\n",
    "                        for reconi in range(recon_period_len):\n",
    "\n",
    "                            Xa_reconi  =   Xa_full_field0[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens))\n",
    "                            Xa_sal_i   =   np.copy(Xa_sal_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                            Xa_ph_i    =   np.copy(Xa_ph_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                            Xa_omega_i =   np.copy(Xa_omega_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "\n",
    "                            Ye = DeepDA_psm.cal_ye_cgenie_mgca(yml_dict,sites_eval,j,Xa_reconi,proxy_psm_type[key0],dum_lon_offset,dum_imax,dum_jmax,Xa_sal_i,Xa_ph_i,Xa_omega_i,geologic_age)\n",
    "\n",
    "                            if psm_baymag_ln in ['yes']:\n",
    "                                xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(np.exp(Ye))\n",
    "                            else:\n",
    "                                xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(Ye)\n",
    "\n",
    "                            #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j]   = np.mean(Ye)\n",
    "                            #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi+1][j] = np.var(Ye)\n",
    "\n",
    "                            ob_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j] = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                            if ~np.isnan(sites_eval[data_period_id[reconi]][j]):\n",
    "                                ob_err0 = DeepDA_psm.obs_estimate_r_fixed_mgca_pooled((15, 16), clearning_one[0], np.nanmean(Xb_sal), np.nanmean(Xb_ph), np.nanmean(Xb_omega), spp, geologic_age)\n",
    "                                if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                    ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = ob_err0 + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                else:\n",
    "                                    ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = ob_err0\n",
    "\n",
    "                    # save proxy, prior, and posterior data and then standardized\n",
    "\n",
    "                    # info\n",
    "                    df_i = pandas.DataFrame({'site':sites_eval['Site'][j],'proxy':proxy_i,'locRad':locRadv,'proxy_frac':proxy_frac,'Rscale':Rscale,'MC':MCi}, index=[df_ind])\n",
    "                    df_eval = pandas.concat([df_eval,df_i])\n",
    "\n",
    "                    df_ind += 1\n",
    "\n",
    "                # obs\n",
    "                ob_data = np.swapaxes(ob_stat[locRadi,proxy_fraci,Rscalei,MCi,:,:],0,1)\n",
    "                df_obi = pandas.DataFrame(data=ob_data,columns=df_ind_recon)\n",
    "                df_ob = pandas.concat([df_ob,df_obi])\n",
    "\n",
    "                #xb_std = np.copy(xb_stat[locRadi][proxy_fraci][Rscalei][MCi][:][:])\n",
    "                #ob_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, recon_period_len*2, sites_withhold_len), np.nan)\n",
    "                #xb_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, sites_withhold_len), np.nan)   # save full prior for withhold data\n",
    "                #xa_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, recon_period_len, sites_withhold_len), np.nan)\n",
    "\n",
    "                # xb\n",
    "                xb_data = np.swapaxes(xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,:],0,1)  # withhold x nens\n",
    "                df_xb_i  = pandas.DataFrame(data=xb_data)\n",
    "                df_xb = pandas.concat([df_xb,df_xb_i])\n",
    "\n",
    "                # xa\n",
    "                xa_data = np.swapaxes(xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,:,:],0,2)  # withhold x recon x nens\n",
    "                xa_data1 = xa_data.reshape((sites_withhold_len, recon_period_len*nens))\n",
    "                df_xa_i  = pandas.DataFrame(data=xa_data1)\n",
    "                df_xa = pandas.concat([df_xa,df_xa_i])\n",
    "\n",
    "            df_ob = df_ob.reset_index()\n",
    "            df_ob = df_ob.drop(columns='index')\n",
    "            df_xb = df_xb.reset_index()\n",
    "            df_xb = df_xb.drop(columns='index')\n",
    "            df_xa = df_xa.reset_index()\n",
    "            df_xa = df_xa.drop(columns='index')\n",
    "            print('')\n",
    "            print('Step #3: evaluation data preparation - Done')\n",
    "            print('')\n",
    "            if log_level > 3:\n",
    "                print('df_eval')\n",
    "                print(df_eval)\n",
    "                print('df_ob')\n",
    "                print(df_ob)\n",
    "                print('df_xb')\n",
    "                print(df_xb)\n",
    "\n",
    "        ###############################################################\n",
    "        # calculate RMSE, CE, R^2 for each time slice\n",
    "        ###############################################################\n",
    "        ###############################################################\n",
    "\n",
    "\n",
    "            df_reconi = pandas.DataFrame()\n",
    "\n",
    "            df_ind_i = 0\n",
    "            df_zscore_mc   = pandas.DataFrame()\n",
    "            df_zscore   = pandas.DataFrame()\n",
    "            df_ob_pi_all_col = pandas.DataFrame()\n",
    "            df_xb_pi_all_col = pandas.DataFrame()\n",
    "            df_xa_pi_all_col = pandas.DataFrame()\n",
    "            df_eval_pi_all_col = pandas.DataFrame()\n",
    "            \n",
    "            for reconi in range(recon_period_len):\n",
    "                \n",
    "                data_period_id_i = data_period_id[reconi]\n",
    "                \n",
    "                if log_level > 1:\n",
    "                    print('>>>>>>>  ')\n",
    "                    print('')\n",
    "                    print('reconi {}'.format(reconi))\n",
    "                    print(data_period_id_i)\n",
    "                    print('')\n",
    "                \n",
    "                # read ob, xb, and xa, in 1 column each\n",
    "                if proxy_eval_list:\n",
    "                    print('assimilated proxy i {}'.format(proxy_eval_list))\n",
    "                    \n",
    "                    df_ob_pi   = df_ob[data_period_id_i] \n",
    "                    df_xb_pi   = df_xb\n",
    "                    \n",
    "                    df_xa_pi   = df_xa[df_xa.columns[reconi*nens:(reconi+1)*nens]]\n",
    "                    df_xa_pi.columns = range(df_xa_pi.shape[1])\n",
    "                    \n",
    "                    if log_level > 4:\n",
    "                        print('df_xa_pi')\n",
    "                        print(df_xa_pi)\n",
    "                    df_eval_pi = df_eval\n",
    "                    \n",
    "                df_ob_pi_all_col = pandas.concat([df_ob_pi_all_col,df_ob_pi])\n",
    "                \n",
    "                # debug; only works for 1 single Xb\n",
    "                df_xb_pi_all_col = pandas.concat([df_xb_pi_all_col,df_xb_pi])\n",
    "                \n",
    "                df_xa_pi_all_col = pandas.concat([df_xa_pi_all_col,df_xa_pi])\n",
    "                df_eval_pi_all_col = pandas.concat([df_eval_pi_all_col,df_eval_pi])\n",
    "                \n",
    "            df_ob_pi_all_col = df_ob_pi_all_col.reset_index()\n",
    "            df_ob_pi_all_col = df_ob_pi_all_col.drop(columns='index')\n",
    "            df_xb_pi_all_col = df_xb_pi_all_col.reset_index()\n",
    "            df_xb_pi_all_col = df_xb_pi_all_col.drop(columns='index')\n",
    "            df_xa_pi_all_col = df_xa_pi_all_col.reset_index()\n",
    "            df_xa_pi_all_col = df_xa_pi_all_col.drop(columns='index')\n",
    "            df_eval_pi_all_col = df_eval_pi_all_col.reset_index()\n",
    "            df_eval_pi_all_col = df_eval_pi_all_col.drop(columns='index')\n",
    "            \n",
    "            if log_level > 1:\n",
    "                print('df_eval_pi')\n",
    "                print(df_eval_pi)\n",
    "                print('df_ob_pi_all_col')\n",
    "                print(df_ob_pi_all_col)\n",
    "                print('df_xb_pi_all_col')\n",
    "                print(df_xb_pi_all_col)\n",
    "                print('df_xa_pi_all_col')\n",
    "                print(df_xa_pi_all_col)\n",
    "                \n",
    "            # remove nan values in ob\n",
    "            df_xb_pi_all_col = df_xb_pi_all_col[df_ob_pi_all_col[0].notna()]\n",
    "            df_xa_pi_all_col = df_xa_pi_all_col[df_ob_pi_all_col[0].notna()]\n",
    "            df_eval_pi_all_col = df_eval_pi_all_col[df_ob_pi_all_col[0].notna()]\n",
    "            df_ob_pi_all_col = df_ob_pi_all_col.dropna()\n",
    "            \n",
    "            if log_level > 1:\n",
    "                print('df_eval_pi_all_col')\n",
    "                print(df_eval_pi_all_col)\n",
    "                print('df_ob_pi_all_col')\n",
    "                print(df_ob_pi_all_col)\n",
    "                print('df_xb_pi_all_col')\n",
    "                print(df_xb_pi_all_col)\n",
    "                print('df_xa_pi_all_col')\n",
    "                print(df_xa_pi_all_col)\n",
    "                \n",
    "                \n",
    "            # zscore by proxy type\n",
    "\n",
    "            for proxy_j in range(pn):\n",
    "\n",
    "                df_zscore_j = pandas.DataFrame()\n",
    "                \n",
    "                if proxy_eval_list:\n",
    "                    proxy_i = proxy_eval_list[proxy_j]\n",
    "                else:\n",
    "                    proxy_i = Typelist[proxy_j]\n",
    "                proxy_i = proxy_i.lower()\n",
    "                \n",
    "                print('assimilated proxy i {}'.format(proxy_i))\n",
    "\n",
    "                df_eval_pi = df_eval_pi_all_col[df_eval_pi_all_col['proxy'] == proxy_i]\n",
    "                if log_level > 4:\n",
    "                    print('df_eval_pi_all_col')\n",
    "                    print(df_eval_pi_all_col)\n",
    "                    print('df_eval_pi')\n",
    "                    print(df_eval_pi)\n",
    "                # debug\n",
    "                if pn > 1:\n",
    "                    df_ob_pi   = df_ob_pi_all_col[df_eval_pi_all_col['proxy'] == proxy_i]\n",
    "                    df_xb_pi   = df_xb_pi_all_col[df_eval_pi_all_col['proxy'] == proxy_i]\n",
    "                    df_xa_pi   = df_xa_pi_all_col[df_eval_pi_all_col['proxy'] == proxy_i]\n",
    "                else:\n",
    "                    df_ob_pi   = df_ob_pi_all_col\n",
    "                    df_xb_pi   = df_xb_pi_all_col\n",
    "                    df_xa_pi   = df_xa_pi_all_col\n",
    "                # debug end\n",
    "                df_ob_pi = df_ob_pi.reset_index()\n",
    "                df_ob_pi = df_ob_pi.drop(columns='index')\n",
    "                df_xb_pi = df_xb_pi.reset_index()\n",
    "                df_xb_pi = df_xb_pi.drop(columns='index')\n",
    "                df_xa_pi = df_xa_pi.reset_index()\n",
    "                df_xa_pi = df_xa_pi.drop(columns='index')\n",
    "                \n",
    "                if log_level > 4:\n",
    "                    print('df_ob_pi reset index')\n",
    "                    print(df_ob_pi)\n",
    "                    print('df_ob_pi drop index')\n",
    "                    print(df_ob_pi)\n",
    "                \n",
    "                df_ob_pi_mean = list(pandas.Series.mean(df_ob_pi))\n",
    "                df_ob_pi_std  = list(pandas.Series.std(df_ob_pi))\n",
    "                \n",
    "                if log_level > 2:\n",
    "                    print('df_ob_pi_mean {}'.format(df_ob_pi_mean))\n",
    "                    print('df_ob_pi_std  {}'.format(df_ob_pi_std))\n",
    "                \n",
    "                df_xb_pi_all = df_xb_pi.mean(axis=1)\n",
    "\n",
    "                df_xa_pi_all = df_xa_pi.mean(axis=1)\n",
    "                \n",
    "                if log_level > 4:\n",
    "                    print('df_xb_pi_all  mean')\n",
    "                    print(df_xb_pi_all)\n",
    "                    print('df_xa_pi_all  mean')\n",
    "                    print(df_xa_pi_all)\n",
    "                \n",
    "                df_ob_pi_zscore = (df_ob_pi - df_ob_pi_mean) / df_ob_pi_std\n",
    "                df_xb_pi_zscore = (df_xb_pi_all - df_ob_pi_mean) / df_ob_pi_std\n",
    "                df_xa_pi_zscore = (df_xa_pi_all - df_ob_pi_mean) / df_ob_pi_std\n",
    "                \n",
    "                if log_level > 4:\n",
    "                    print('df_ob_pi')\n",
    "                    print(df_ob_pi)\n",
    "                    print('df_ob_pi_zscore')\n",
    "                    print(df_ob_pi_zscore)\n",
    "                    #print('df_xb_pi')\n",
    "                    #print(df_xb_pi)\n",
    "                    print('df_xb_pi_zscore')\n",
    "                    print(df_xb_pi_zscore)\n",
    "                    #print('df_xa_pi')\n",
    "                    #print(df_xa_pi)\n",
    "                    print('df_xa_pi_zscore')\n",
    "                    print(df_xa_pi_zscore)\n",
    "                    \n",
    "                #for MCii in range(MCn): df_zscore_j.loc[MCii, ['proxy']] = proxy_i\n",
    "                #for MCii in range(MCn): df_zscore_j.loc[MCii, ['reconi']] = data_period_id_i\n",
    "                #for MCii in range(MCn): df_zscore_j.loc[MCii, ['loc']] = locRadi\n",
    "                #for MCii in range(MCn): df_zscore_j.loc[MCii, ['proxy_frac']] = proxy_fraci\n",
    "                #for MCii in range(MCn): df_zscore_j.loc[MCii, ['Rscale']] = Rscale\n",
    "                pnii = len(df_ob_pi)\n",
    "                print(pnii)\n",
    "                for MCii in range(pnii): df_zscore_j.loc[MCii, ['proxy']] = proxy_i\n",
    "                for MCii in range(pnii): df_zscore_j.loc[MCii, ['reconi']] = data_period_id_i\n",
    "                for MCii in range(pnii): df_zscore_j.loc[MCii, ['loc']] = locRadi\n",
    "                for MCii in range(pnii): df_zscore_j.loc[MCii, ['proxy_frac']] = proxy_fraci\n",
    "                for MCii in range(pnii): df_zscore_j.loc[MCii, ['Rscale']] = Rscale\n",
    "                \n",
    "                if log_level > 3:\n",
    "                    print('df_zscore_j')\n",
    "                    print(df_zscore_j)\n",
    "                df_zscore_j['ob'] = df_ob_pi\n",
    "                df_zscore_j['xb'] = df_xb_pi_all\n",
    "                df_zscore_j['xa'] = df_xa_pi_all\n",
    "                \n",
    "                df_zscore_j['ob_zscore'] = df_ob_pi_zscore\n",
    "                df_zscore_j['xb_zscore'] = df_xb_pi_zscore\n",
    "                df_zscore_j['xa_zscore'] = df_xa_pi_zscore\n",
    "                if log_level > 3:\n",
    "                    print('df_zscore_j')\n",
    "                    print(df_zscore_j)\n",
    "                df_zscore = pandas.concat([df_zscore,df_zscore_j])\n",
    "\n",
    "                if log_level > 4:\n",
    "                    print('df_eval_pi')\n",
    "                    print(df_eval_pi)\n",
    "                    print('df_ob_pi')\n",
    "                    print(df_ob_pi)\n",
    "                    print('df_xb_pi first 6 rows')\n",
    "                    print(df_xb_pi[:][0:6])\n",
    "                    print('df_xa_pi')\n",
    "                    print(df_xa_pi)\n",
    "                        \n",
    "            if log_level > 3:\n",
    "                print(' ')\n",
    "                print('df_zscore:')\n",
    "                print(df_zscore)\n",
    "\n",
    "            rmse_xb = DeepDA_psm.rmse(df_zscore['ob_zscore'],df_zscore['xb_zscore'])\n",
    "\n",
    "            CE_xb = DeepDA_psm.CE_NS70(df_zscore['ob_zscore'],df_zscore['xb_zscore'],1)\n",
    "            \n",
    "            if log_level > 1:\n",
    "                \n",
    "                print('RMSE of Ob vs. Xb {}'.format(rmse_xb))\n",
    "                print('CE of Ob vs. Xb {}'.format(CE_xb))\n",
    "\n",
    "            a=ma.masked_invalid(df_zscore['ob_zscore'])\n",
    "            b=ma.masked_invalid(df_zscore['xb_zscore'])\n",
    "            msk = (~a.mask & ~b.mask)\n",
    "            cor_matrix = ma.corrcoef(a[msk],b[msk])\n",
    "            r_2_xb = cor_matrix[0,1]**2\n",
    "\n",
    "            if log_level > 1:\n",
    "                print('r^2 of Ob vs. Xb {}'.format(r_2_xb))\n",
    "                print('')\n",
    "\n",
    "\n",
    "            rmse_xa = DeepDA_psm.rmse(df_zscore['ob_zscore'],df_zscore['xa_zscore'])\n",
    "\n",
    "            CE_xa = DeepDA_psm.CE_NS70(df_zscore['ob_zscore'],df_zscore['xa_zscore'],1)\n",
    "\n",
    "            if log_level > 1:\n",
    "                print('RMSE of Ob vs. Xa {}'.format(rmse_xa))\n",
    "                print('CE of Ob vs. Xb {}'.format(CE_xa))\n",
    "\n",
    "            b=ma.masked_invalid(df_zscore['xa_zscore'])\n",
    "            msk = (~a.mask & ~b.mask)\n",
    "            cor_matrix = ma.corrcoef(a[msk],b[msk])\n",
    "            r_2_xa = cor_matrix[0,1]**2\n",
    "\n",
    "            if log_level > 1:\n",
    "                print('r^2 of Ob vs. Xa {}'.format(r_2_xa))\n",
    "                print(' --- ')\n",
    "                print('')\n",
    "            # delta RMSE, CE, and R^2\n",
    "            drmse = 100 * (rmse_xb - rmse_xa)/rmse_xb\n",
    "            dce   = 100 * (CE_xb - CE_xa)/CE_xb\n",
    "            dr2   = 100 * (r_2_xb - r_2_xa)/r_2_xb\n",
    "\n",
    "            df_reconi = pandas.DataFrame({'reconi':reconi,\n",
    "                                          'data_period_id_i':data_period_id_i,\n",
    "                                          'loc':locRadv,\n",
    "                                          'proxy_frac':proxy_frac,\n",
    "                                          'Rscale':Rscale,\n",
    "                                          'RMSE Xb':rmse_xb,\n",
    "                                          'RMSE Xa':rmse_xa,\n",
    "                                          'dRMSE':drmse,\n",
    "                                          'CE Xb':CE_xb,\n",
    "                                          'CE Xa': CE_xa,\n",
    "                                          'dCE':dce,\n",
    "                                          'R^2 Xb':r_2_xb,\n",
    "                                          'R^2 Xa': r_2_xa,\n",
    "                                          'dR^2':dr2}, index=[df_ind_i])\n",
    "\n",
    "            df_evaluation = pandas.concat([df_evaluation,df_reconi])\n",
    "\n",
    "            df_ind_i += 1\n",
    "\n",
    "            df_zscore_mc = pandas.concat([df_zscore_mc,df_zscore])\n",
    "\n",
    "            df_evaluation = pandas.concat([df_evaluation,df_reconi])\n",
    "\n",
    "            df_zscore_all = pandas.concat([df_zscore_all,df_zscore_mc])\n",
    "            print(' This loop done ')\n",
    "            if savesummary:\n",
    "                df_zscore_name = yml_dict['core']['proj_dir']+'/wrk/'+en+savefilename_add+'_df_zscore_all'+'.csv'\n",
    "                print('save file @ {}'.format(df_zscore_name))\n",
    "                df_zscore_all.to_csv(df_zscore_name)        \n",
    "        \n",
    "if savesummary:\n",
    "    df_evaluation.sort_index().to_csv(yml_dict['core']['proj_dir']+'/wrk/'+en+'_df_evaluation_log.csv')\n",
    "\n",
    "print('')\n",
    "print('Step #4: evaluation - Done')\n",
    "print('')\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##\n",
    "# updated version, now pre-PETM and peak-PETM (and more) are forced to be 1 columns\n",
    "##\n",
    "# good, but not used. because has been merged with below codes\n",
    "\n",
    "# debug\n",
    "#Rscalen = 1\n",
    "# debug\n",
    "\n",
    "for locRadi in range(locRadn):\n",
    "    locRad = local_rad_list[locRadi]\n",
    "    if locRad is None:\n",
    "        locRadv = 0 # for filename only\n",
    "    else:\n",
    "        locRadv = locRad\n",
    "    for proxy_fraci in range(proxy_fracn):\n",
    "        proxy_frac = proxy_frac_list[proxy_fraci]\n",
    "\n",
    "        for Rscalei in range(Rscalen):\n",
    "            Rscale = Rscale_list[Rscalei]\n",
    "\n",
    "            savefilename_add = '_loc_'+ str(locRadv)+'_proxy_frac_'+ str(proxy_frac)+'_Rscale_'+str(Rscale)\n",
    "\n",
    "            for MCi in range(MCn):\n",
    "                # NetCDF file name\n",
    "                filename_short = '_loc_', str(locRadv),'_proxy_frac_', str(proxy_frac),'_Rscale_',str(Rscale),'_MC_',str(MCi) \n",
    "                nc_filename = MC_dir + ''.join(filename_short) + '.nc'\n",
    "                hdf5name    = MC_dir + ''.join(filename_short) + '.hdf5'\n",
    "\n",
    "                print('>>  Read nc file: {}'.format(nc_filename))\n",
    "\n",
    "                for Xa2d_vari in range(prior_variable_len):\n",
    "\n",
    "                    Xa_full_name_vari = prior_variable_dict[Xa2d_vari] +'_Xa_full'\n",
    "                    Xa_mean_name_vari = prior_variable_dict[Xa2d_vari] +'_Xa_mean'\n",
    "                    Xa_variance_name_vari = prior_variable_dict[Xa2d_vari] +'_Xa_variance'\n",
    "                    Xa_full_vari = Dataset(nc_filename).variables[Xa_full_name_vari][:]\n",
    "                    Xa_mean_vari = Dataset(nc_filename).variables[Xa_mean_name_vari][:]\n",
    "                    Xa_variance_vari = Dataset(nc_filename).variables[Xa_variance_name_vari][:]\n",
    "\n",
    "                    if prior_variable_dict[Xa2d_vari] in limit_hard_keys:\n",
    "                        # some variables have hard limitation: e.g., CaCO3 = [0, 100]                        \n",
    "                        lim_min = yml_dict['prior'][prior_source]['limit_hard'][prior_variable_dict[Xa2d_vari]]['lim_min']\n",
    "                        lim_max = yml_dict['prior'][prior_source]['limit_hard'][prior_variable_dict[Xa2d_vari]]['lim_max']\n",
    "                        #print('limit min {} and max {}'.format(lim_min, lim_max))\n",
    "                        if lim_min:\n",
    "                            if np.any(Xa_full_vari<lim_min):\n",
    "                                Xa_full_vari[Xa_full_vari<lim_min] = lim_min\n",
    "                                Xa_mean_vari = np.mean(Xa_full_vari,axis=2)\n",
    "                                Xa_variance_vari = np.var(Xa_full_vari,axis=2)\n",
    "                                print('>>    Force {} value to be >= {}'.format(prior_variable_dict[Xa2d_vari],lim_min))\n",
    "                        if lim_max:\n",
    "                            if np.any(Xa_full_vari>lim_max):\n",
    "                                Xa_full_vari[Xa_full_vari>lim_max] = lim_max\n",
    "                                Xa_mean_vari = np.mean(Xa_full_vari,axis=2)\n",
    "                                Xa_variance_vari = np.var(Xa_full_vari,axis=2)\n",
    "                                print('>>    Force {} value to be <= {}'.format(prior_variable_dict[Xa2d_vari], lim_max))\n",
    "\n",
    "                    for reconi in range(recon_period_len):\n",
    "\n",
    "                        Xa_full_reconi = Xa_full_vari[:,:,:,0,reconi].reshape((dum_ijmax,nens))\n",
    "                        Xa_full_reconi_mean = np.nanmean(Xa_full_reconi,axis=0)\n",
    "\n",
    "                        Xa_mean_reconi = Xa_mean_vari[:,:,0,reconi]\n",
    "                        Xa2d_all_np[:,:,locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = np.copy(Xa_mean_vari[:,:,0,reconi])\n",
    "                        Xa_mean_reconi_mean = np.nanmean(Xa_mean_reconi)\n",
    "\n",
    "                        Xa_variance_reconi = Xa_variance_vari[:,:,0,reconi]\n",
    "                        Xa2d_allstd_np[:,:,locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = Xa_variance_vari[:,:,0,reconi]\n",
    "                        Xa_std_reconi_mean = np.sqrt(np.nanmean(Xa_variance_reconi))\n",
    "\n",
    "                        #print('>>  reconi = {}, mean is {}, std is {}'.format(reconi, Xa_mean_reconi_mean, Xa_std_reconi_mean))\n",
    "                        Xa2d_full_np[locRadi,proxy_fraci,Rscalei,MCi*nens:(MCi+1)*nens,Xa2d_vari,reconi] = Xa_full_reconi_mean\n",
    "                        Xa2d_mean_np[locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = Xa_mean_reconi_mean\n",
    "                        Xa2d_std_np[locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = Xa_std_reconi_mean\n",
    "            print('First variable: all MC mean')\n",
    "            print(Xa2d_mean_np[locRadi,proxy_fraci,Rscalei,:,0,0])\n",
    "\n",
    "            Xa2d_all_np = np.ma.masked_where(Xa2d_all_np > 9.0e+36, Xa2d_all_np)\n",
    "            Xa2d_allstd_np = np.ma.masked_where(Xa2d_all_np > 9.0e+36, Xa2d_allstd_np)\n",
    "            for Xa2d_vari in range(prior_variable_len):\n",
    "                for reconi in range(recon_period_len):\n",
    "                    Xa2d_mean_np2[locRadi,proxy_fraci,Rscalei,Xa2d_vari,reconi] = np.nanmean(Xa2d_all_np[:,:,locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi])\n",
    "                    Xa2d_std_np2[locRadi,proxy_fraci,Rscalei,Xa2d_vari,reconi] = np.sqrt(np.nanmean(Xa2d_allstd_np[:,:,locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi]))\n",
    "\n",
    "            np.set_printoptions(precision=6, suppress=True)\n",
    "            if log_level > 1:\n",
    "                print('All variable. Mean of variables x reconi')\n",
    "                print('{}'.format(Xa2d_mean_np2[locRadi,proxy_fraci,Rscalei,:,:]))\n",
    "            #print('std  of variables x reconi')\n",
    "            #print('{}'.format(Xa2d_std_np2))\n",
    "\n",
    "            print('')\n",
    "            print('Step #1: read data - Done')\n",
    "            print('')\n",
    "\n",
    "            # Calculate mean and std of each variable for each time slice\n",
    "            # plot the ensemble values\n",
    "\n",
    "            df = pandas.DataFrame()\n",
    "            print('')\n",
    "            print('DA - Summary of global mean and standard deviation')\n",
    "            print('')\n",
    "\n",
    "            if showplot:\n",
    "                fig, (ax0, ax1, ax2, ax3) = plt.subplots(nrows=4, figsize=(3, 6))\n",
    "                if recon_period_len>1:\n",
    "                    fig2, (ax10, ax11, ax12, ax13) = plt.subplots(nrows=4, figsize=(3, 6))\n",
    "                params = {'mathtext.default': 'regular' }\n",
    "                plt.rcParams.update(params)\n",
    "                #plt.rcParams.update({'figure.figsize':(5,3), 'figure.dpi':110})\n",
    "                #fig.suptitle('DA')\n",
    "\n",
    "            # 2d variables\n",
    "            for Xa2d_vari in range(prior_variable_len):\n",
    "\n",
    "                print(prior_variable_dict[Xa2d_vari])\n",
    "                datadf = {'field':prior_variable_dict[Xa2d_vari],'mean':[np.nan],'std':[np.nan],\n",
    "                          '2.5%':[np.nan],'5%':[np.nan],'25%':[np.nan],'median':[np.nan],'75%':[np.nan],'95%':[np.nan],'97.5%':[np.nan],'label':''}\n",
    "                df2 = pandas.DataFrame(datadf, index=[Xa2d_vari])\n",
    "                df = pandas.concat([df,df2])\n",
    "\n",
    "                sst_std_mc = np.std(Xa2d_mean_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,:],axis=0)\n",
    "                if log_level > 2:\n",
    "                    print('  _locR '+str(locRadv)+' proxy_frac '+str(proxy_frac)+' scaled r '+str(Rscale))\n",
    "\n",
    "                for reconi in range(recon_period_len):\n",
    "\n",
    "                    meani = np.nanmean(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi])\n",
    "                    stdi = np.std(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi])\n",
    "                    perc = np.percentile(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi],np.array([2.5, 5, 25, 50, 75, 95, 97.5]))\n",
    "                    datadf = {'field':'','mean':[meani],'std':[stdi],\n",
    "                              '2.5%':[perc[0]],'5%':[perc[1]],'25%':[perc[2]],'median':[perc[3]],'75%':[perc[4]],'95%':[perc[5]],'97.5%':[perc[6]],'label':label_all[reconi]}\n",
    "                    df2 = pandas.DataFrame(data = datadf, index=[Xa2d_vari])\n",
    "                    df = pandas.concat([df,df2])\n",
    "                    if log_level > 2:\n",
    "                        print('    {:.3f} ± {:.3f}: {}'.format(meani, stdi, label_all[reconi]))\n",
    "\n",
    "                    if recon_period_len>2:\n",
    "                        warmpeak = Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,1]-Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,0]\n",
    "                        #warmbody = Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,2]-Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,0]\n",
    "                        coolpeak = Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,2]-Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,1]\n",
    "                        warmpeakmean = np.nanmean(warmpeak)\n",
    "                        warmpeakstd  = np.std(warmpeak)\n",
    "                        warmperc = np.percentile(warmpeak,np.array([2.5, 5, 25, 50, 75, 95, 97.5]))\n",
    "                        coolpeakmean = np.nanmean(coolpeak)\n",
    "                        coolpeakstd  = np.std(coolpeak)\n",
    "                        coolperc = np.percentile(coolpeak,np.array([2.5, 5, 25, 50, 75, 95, 97.5]))\n",
    "\n",
    "                if recon_period_len>2:\n",
    "                    df2 = pandas.DataFrame({'field':'','mean':[warmpeakmean],'std':[warmpeakstd],\n",
    "                                            '2.5%':[warmperc[0]],'5%':[warmperc[1]],'25%':[warmperc[2]],'median':[warmperc[3]],'75%':[warmperc[4]],'95%':[warmperc[5]],'97.5%':[warmperc[6]],'label':'Peak_warming'}, index=[Xa2d_vari])\n",
    "                    df3 = pandas.DataFrame({'field':'','mean':[coolpeakmean],'std':[coolpeakstd],\n",
    "                                            '2.5%':[coolperc[0]],'5%':[coolperc[1]],'25%':[coolperc[2]],'median':[coolperc[3]],'75%':[coolperc[4]],'95%':[coolperc[5]],'97.5%':[coolperc[6]],'label':'Peak_cooling'}, index=[Xa2d_vari])\n",
    "                    df = pandas.concat([df,df2,df3])\n",
    "                    if log_level > 2:\n",
    "                        print('    {:.6f} ± {:.6f}: peak warming'.format(warmpeakmean,warmpeakstd))\n",
    "                        print('    {:.6f} ± {:.6f}: peak cooling'.format(coolpeakmean,coolpeakstd))\n",
    "\n",
    "                if showplot:\n",
    "                    for reconi in range(recon_period_len):\n",
    "                        if reconi == 3:\n",
    "                            continue\n",
    "                        kwargs = dict(alpha=0.5, bins=50)\n",
    "\n",
    "                        if Xa2d_vari == 0:\n",
    "                            ax0.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                            ax0.set_ylabel('#')\n",
    "                            ax0.set_xlabel('SST (\\u00B0C)')\n",
    "                            ax0.tick_params(labelsize='small')\n",
    "                            ax0.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 1:\n",
    "                            ax1.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                            ax1.set_ylabel('#')\n",
    "                            ax1.set_xlabel('SAT (\\u00B0C)')\n",
    "                            ax1.tick_params(labelsize='small')\n",
    "                            ax1.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 2:\n",
    "                            ax2.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                            ax2.set_ylabel('#')\n",
    "                            ax2.set_xlabel('$\\it{p}$CO$_2$ (ppm)')\n",
    "                            ax2.set_xlim(0, 2800)\n",
    "                            ax2.legend(prop={'size': 6.5})  \n",
    "                            ax2.tick_params(labelsize='small')\n",
    "                            ax2.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        #if Xa2d_vari == 3:\n",
    "                        #    ax3.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                        #    ax3.set_ylabel('Number')\n",
    "                        #    ax3.set_xlabel('Salinity (PSU)')\n",
    "                        if Xa2d_vari == 4:\n",
    "                            ax3.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                            ax3.set_ylabel('#')\n",
    "                            ax3.set_xlabel('pH')     \n",
    "                            ax3.tick_params(labelsize='small')\n",
    "                            ax3.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        #if Xa2d_vari == 6:\n",
    "                        #    ax5.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                        #    ax5.set_ylabel('Number')\n",
    "                        #    ax5.set_xlabel('$CaCO_3$ (%)')\n",
    "                    fig.tight_layout()\n",
    "\n",
    "                    if recon_period_len>1:\n",
    "                        if Xa2d_vari == 0:                    \n",
    "                            ax10.hist(warmpeak, **kwargs, color = \"#ff7f0e\", label = 'warming')\n",
    "                            ax10.hist(coolpeak, **kwargs, color = \"#2ca02c\", label = 'cooling')\n",
    "                            ax10.set_ylabel('#')\n",
    "                            ax10.set_xlabel('\\u0394SST (\\u00B0C)')                        \n",
    "                            ax10.legend(prop={'size': 6.5});\n",
    "                            ax10.tick_params(labelsize='small')\n",
    "                            ax10.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 1:\n",
    "                            ax11.hist(warmpeak, **kwargs, color = \"#ff7f0e\")\n",
    "                            ax11.hist(coolpeak, **kwargs, color = \"#2ca02c\")\n",
    "                            ax11.set_ylabel('#')\n",
    "                            ax11.set_xlabel('\\u0394SAT (\\u00B0C)')\n",
    "                            ax11.tick_params(labelsize='small')\n",
    "                            ax11.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 2:\n",
    "                            ax12.hist(warmpeak, **kwargs, color = \"#ff7f0e\")\n",
    "                            ax12.hist(coolpeak, **kwargs, color = \"#2ca02c\")\n",
    "                            ax12.set_ylabel('#')\n",
    "                            ax12.set_xlabel('\\u0394$\\it{p}$CO$_2$ (ppm)')\n",
    "                            ax12.tick_params(labelsize='small')\n",
    "                            ax12.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 4:\n",
    "                            ax13.hist(warmpeak, **kwargs, color = \"#ff7f0e\")\n",
    "                            ax13.hist(coolpeak, **kwargs, color = \"#2ca02c\")\n",
    "                            ax13.set_ylabel('#')\n",
    "                            ax13.set_xlabel('\\u0394pH')\n",
    "                            ax13.tick_params(labelsize='small')\n",
    "                            ax13.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        fig2.tight_layout()\n",
    "\n",
    "            if showplot:\n",
    "                fig.savefig(yml_dict['core']['proj_dir']+'/wrk/'+en+'.summary.pdf')\n",
    "                if recon_period_len > 1:\n",
    "                    fig2.savefig(yml_dict['core']['proj_dir']+'/wrk/'+en+'.delta.pdf')\n",
    "\n",
    "            # print and save excel\n",
    "            if savesummary_slice:\n",
    "                print('saved @')\n",
    "                fullname = yml_dict['core']['proj_dir']+'/wrk/'+en+savefilename_add+'.summary.csv'\n",
    "                print(fullname)\n",
    "                df.to_csv(fullname)\n",
    "\n",
    "            print('')\n",
    "            print('Step #2: summary - Done')\n",
    "            print('')\n",
    "\n",
    "\n",
    "\n",
    "            ### Purpose of this block\n",
    "            # Prepare data for verification\n",
    "            #\n",
    "            ### Steps\n",
    "            # 1. Prepare matrix for data saving: proxy, prior, posterior; std or not\n",
    "            # 2. calculate and save each Monte Carlo runs\n",
    "\n",
    "            #####################    User defined start   #####################\n",
    "            if log_level > 1:\n",
    "                print('DA - Read proxy, prior, and posterior, standardize')\n",
    "                print('')\n",
    "            #####################    User defined end     #####################\n",
    "\n",
    "            df_eval = pandas.DataFrame()\n",
    "            df_ob   = pandas.DataFrame()\n",
    "            df_xb   = pandas.DataFrame()\n",
    "            df_xa   = pandas.DataFrame()\n",
    "\n",
    "            # Get the sites_withhold_len\n",
    "\n",
    "            #locRad = local_rad_list[0]\n",
    "            #if locRad is None:\n",
    "            #    locRadv = 0 # for filename only\n",
    "            #else:\n",
    "            #    locRadv = locRad\n",
    "\n",
    "            #proxy_frac = proxy_frac_list[0]\n",
    "            #Rscale = Rscale_list[0]\n",
    "            filename_short = '_loc_', str(locRadv),'_proxy_frac_', str(proxy_frac),'_Rscale_',str(Rscale),'_MC_0.hdf5'\n",
    "            hdf5name = MC_dir + ''.join(filename_short)\n",
    "            if log_level > 1:\n",
    "                print('Read first hdf5 file {} to get the number of withold datasets.'.format(hdf5name))\n",
    "            if proxy_eval_list:\n",
    "                sites_eval = proxy_select  # if use evaluate list, more than the leave-1-out model\n",
    "            else:\n",
    "                sites_eval = pandas.read_hdf(hdf5name, 'sites_eval')  # if use the default list, less than the leave-1-out model\n",
    "\n",
    "            sites_withhold_len  = len(sites_eval)\n",
    "            \n",
    "            if log_level > 1:\n",
    "                print(' Site withhold length ： {}'.format(sites_withhold_len))\n",
    "\n",
    "            data_psm_d18o_find = 0\n",
    "            data_psm_mgca_find = 0\n",
    "            if 'Marine sediments_mgca_pooled_bcp' in proxy_list or 'Marine sediments_mgca_pooled_red' in proxy_list:\n",
    "                data_psm_mgca_find = 1\n",
    "            \n",
    "            # debug:   force the DA to calculate Xb_sal, Xb_ph and Xb_sal, etc.\n",
    "            data_psm_mgca_find = 1\n",
    "            # debug:   end\n",
    "            \n",
    "            if 'Marine sediments_d18o_pooled' in proxy_list:\n",
    "                data_psm_d18o_find = 1\n",
    "\n",
    "            # Prepare empty matrix for saving the data of proxy, prior, and posterior\n",
    "            ob_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, recon_period_len*2, sites_withhold_len), np.nan)\n",
    "            xb_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, sites_withhold_len), np.nan)   # save full prior for withhold data\n",
    "            xa_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, recon_period_len, sites_withhold_len), np.nan)\n",
    "\n",
    "            df_ind = 0\n",
    "\n",
    "            # columns name for the observation\n",
    "            df_ind_recon = []\n",
    "\n",
    "            for reconi in range(recon_period_len):\n",
    "                df_ind_recon_i = [data_period_id[reconi]] + [data_period_idstd[reconi]]\n",
    "                df_ind_recon = df_ind_recon + df_ind_recon_i\n",
    "\n",
    "            if log_level > 2:\n",
    "                print(df_ind_recon)\n",
    "\n",
    "\n",
    "            for MCi in range(MCn):\n",
    "            #for MCi in range(1):\n",
    "                # NetCDF file name\n",
    "                filename_short = '_loc_', str(locRadv),'_proxy_frac_', str(proxy_frac),'_Rscale_',str(Rscale),'_MC_' + str(MCi)\n",
    "                nc_filename = MC_dir + ''.join(filename_short) + '.nc'\n",
    "                print('    {}'.format(nc_filename))\n",
    "                hdf5name    = MC_dir + ''.join(filename_short) + '.hdf5'\n",
    "\n",
    "                if data_psm_mgca_find == 1:\n",
    "                    with h5py.File(hdf5name, 'r') as f:\n",
    "                        Xb_sal = np.copy(f.get('Xb_sal'))\n",
    "                        if log_level > 3:\n",
    "                            print(Xb_sal.shape)\n",
    "                        Xb_omega = np.copy((f.get('Xb_omega')))\n",
    "                        Xb_ph = np.copy(f.get('Xb_ph'))\n",
    "                    Xa_sal_full = Dataset(nc_filename).variables['ocn_sur_sal_Xa_full']\n",
    "                    Xa_ph_full  = Dataset(nc_filename).variables['misc_pH_Xa_full']\n",
    "                    Xa_omega_full = Dataset(nc_filename).variables['carb_sur_ohm_cal_Xa_full']\n",
    "\n",
    "                elif data_psm_d18o_find == 1:\n",
    "                    with h5py.File(hdf5name, 'r') as f:\n",
    "                        Xb_sal = np.copy(f.get('Xb_sal'))\n",
    "                        if log_level > 3:\n",
    "                            print(Xb_sal.shape)\n",
    "                        Xb_ph = np.copy(f.get('Xb_ph'))\n",
    "                    Xa_sal_full = Dataset(nc_filename).variables['ocn_sur_sal_Xa_full']\n",
    "                    Xa_ph_full  = Dataset(nc_filename).variables['misc_pH_Xa_full']\n",
    "\n",
    "\n",
    "                ### Read Proxy ###\n",
    "                proxies = pandas.read_hdf(hdf5name, 'proxies')\n",
    "                #prior_variable_dict = pandas.read_hdf(hdf5name, 'prior_variable_dict')\n",
    "\n",
    "                if proxy_frac <= 1.0:\n",
    "                    if proxy_eval_list:\n",
    "                        sites_eval = proxy_select  # if use evaluate list, more than the leave-1-out model\n",
    "                    else:\n",
    "                        sites_eval = pandas.read_hdf(hdf5name, 'sites_eval')\n",
    "                    sites_withhold_len  = len(sites_eval)\n",
    "                    if log_level > 1:\n",
    "                        print('Site withhold:       {}'.format(sites_eval['Site'].values))\n",
    "                        print('Proxy        :       {}'.format(sites_eval['Proxy'].values))\n",
    "\n",
    "                proxy_psm_type_dict_df = pandas.read_hdf(hdf5name, 'proxy_psm_type_dict_df')\n",
    "                proxy_psm_type_dict_list = proxy_psm_type_dict_df[0].values.tolist()\n",
    "\n",
    "                for j in range(sites_withhold_len):\n",
    "                    data_psm_type = sites_eval['Proxy'][j]\n",
    "                    for key, value in proxy_assim2.items():\n",
    "                        if data_psm_type in value:\n",
    "                            #print(proxy_psm_type[key])\n",
    "                            key0 = key\n",
    "                            psm_required_variable_key = list(yml_dict['psm'][proxy_psm_type[key]]['psm_required_variables'].keys())[0]\n",
    "                            xb_key = psm_required_variable_key+'_Xb_full'\n",
    "                            xa_key = psm_required_variable_key+'_Xa_full'\n",
    "                            #print('xa_key is {}'.format(xa_key))\n",
    "                            Xb_full_field0 = Dataset(nc_filename).variables[xb_key] #\n",
    "                            Xb_full_field0 = Xb_full_field0[:,:,:,0].reshape(dum_imax*dum_jmax, nens)\n",
    "                            Xa_full_field0 = Dataset(nc_filename).variables[xa_key]\n",
    "\n",
    "                    if proxy_psm_type[key0] in ['bayesreg_tex86', 'cgenie_caco3']:\n",
    "                        if proxy_psm_type[key0] in ['bayesreg_tex86']:\n",
    "                            proxy_i = 'tex86'\n",
    "                        else:\n",
    "                            proxy_i = 'caco3'\n",
    "                        Ye = DeepDA_psm.cal_ye_cgenie(yml_dict,sites_eval,j,Xb_full_field0,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                        xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(Ye)\n",
    "\n",
    "                        #print('Prior Ye is {:.6f}'.format(np.mean(Ye)))\n",
    "\n",
    "                        for reconi in range(recon_period_len):\n",
    "\n",
    "                            Xa_reconi = np.copy(Xa_full_field0[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "\n",
    "                            Ye = DeepDA_psm.cal_ye_cgenie(yml_dict,sites_eval,j,Xa_reconi,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                            #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j]   = np.mean(Ye)\n",
    "                            #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi+1][j] = np.var(Ye)\n",
    "                            xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(Ye)\n",
    "                            #print('Analysis Ye is {:.6f}'.format(np.mean(Ye)))\n",
    "                            #ob_stat[j][reconi*2]   = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                            ob_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j] = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                            # error\n",
    "                            if ~np.isnan(sites_eval[data_period_id[reconi]][j]):\n",
    "\n",
    "                                if proxy_psm_type[key0] in ['bayesreg_tex86']:\n",
    "\n",
    "                                    if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_tex86(31) + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                    else:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_tex86(31)\n",
    "\n",
    "                                if proxy_psm_type[key0] in ['cgenie_caco3','cgenie_caco3_13c']:\n",
    "\n",
    "                                    psm_error = yml_dict['psm'][proxy_psm_type[key0]]['psm_error']\n",
    "\n",
    "                                    if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = psm_error + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                    else:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = psm_error\n",
    "\n",
    "                    elif proxy_psm_type[key0] in ['bayesreg_d18o_pooled']:\n",
    "\n",
    "                        proxy_i = 'd18o'\n",
    "\n",
    "                        Ye = DeepDA_psm.cal_ye_cgenie_d18O(yml_dict,sites_eval,j,Xb_full_field0,Xb_sal,Xb_ph,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                        xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(Ye)\n",
    "\n",
    "                        for reconi in range(recon_period_len):\n",
    "\n",
    "                            Xa_reconi = np.copy(Xa_full_field0[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                            Xa_sal_i  = np.copy(Xa_sal_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                            Xa_ph_i   = np.copy(Xa_ph_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "\n",
    "                            Ye = DeepDA_psm.cal_ye_cgenie_d18O(yml_dict,sites_eval,j,Xa_reconi,Xa_sal_i,Xa_ph_i,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                            xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(Ye)\n",
    "\n",
    "                            ob_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j] = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                            # error\n",
    "                            if ~np.isnan(sites_eval[data_period_id[reconi]][j]):\n",
    "\n",
    "                                if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                    ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_d18o(15) + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                else:\n",
    "                                    ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_d18o(15)\n",
    "\n",
    "                    elif proxy_psm_type[key0] in ['bayesreg_mgca_pooled_bcp', 'bayesreg_mgca_pooled_red']:\n",
    "                        proxy_i = 'mgca'\n",
    "                        spp = 'all'\n",
    "                        cleaningr = np.tile(np.array([1]),nens)\n",
    "                        cleaningb = np.tile(np.array([0]),nens)\n",
    "\n",
    "                        if proxy_psm_type[key0] in ['bayesreg_mgca_pooled_red']:\n",
    "                            clearning_one = cleaningr\n",
    "                            proxy_explain = 'reductive'\n",
    "\n",
    "                        elif proxy_psm_type[key0] in ['bayesreg_mgca_pooled_bcp']:\n",
    "                            clearning_one = cleaningb\n",
    "                            proxy_explain = 'barker'\n",
    "\n",
    "                        Ye = DeepDA_psm.cal_ye_cgenie_mgca(yml_dict,sites_eval,j,Xb_full_field0,proxy_psm_type[key0],dum_lon_offset,dum_imax,dum_jmax,Xb_sal,Xb_ph,Xb_omega,geologic_age)\n",
    "\n",
    "                        if psm_baymag_ln in ['yes']:\n",
    "                            xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(np.exp(Ye))\n",
    "                        else:\n",
    "                            xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(Ye)\n",
    "\n",
    "                        #Xa_sal_full = Dataset(nc_filename).variables['ocn_sur_sal_Xa_full']\n",
    "                        #Xa_ph_full  = Dataset(nc_filename).variables['misc_pH_Xa_full']\n",
    "                        #Xa_omega_full = Dataset(nc_filename).variables['carb_sur_ohm_cal_Xa_full']\n",
    "\n",
    "                        for reconi in range(recon_period_len):\n",
    "\n",
    "                            Xa_reconi  =   Xa_full_field0[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens))\n",
    "                            Xa_sal_i   =   np.copy(Xa_sal_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                            Xa_ph_i    =   np.copy(Xa_ph_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                            Xa_omega_i =   np.copy(Xa_omega_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "\n",
    "                            Ye = DeepDA_psm.cal_ye_cgenie_mgca(yml_dict,sites_eval,j,Xa_reconi,proxy_psm_type[key0],dum_lon_offset,dum_imax,dum_jmax,Xa_sal_i,Xa_ph_i,Xa_omega_i,geologic_age)\n",
    "\n",
    "                            if psm_baymag_ln in ['yes']:\n",
    "                                xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(np.exp(Ye))\n",
    "                            else:\n",
    "                                xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(Ye)\n",
    "\n",
    "                            #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j]   = np.mean(Ye)\n",
    "                            #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi+1][j] = np.var(Ye)\n",
    "\n",
    "                            ob_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j] = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                            if ~np.isnan(sites_eval[data_period_id[reconi]][j]):\n",
    "                                ob_err0 = DeepDA_psm.obs_estimate_r_fixed_mgca_pooled((15, 16), clearning_one[0], np.nanmean(Xb_sal), np.nanmean(Xb_ph), np.nanmean(Xb_omega), spp, geologic_age)\n",
    "                                if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                    ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = ob_err0 + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                else:\n",
    "                                    ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = ob_err0\n",
    "\n",
    "                    # save proxy, prior, and posterior data and then standardized\n",
    "\n",
    "                    # info\n",
    "                    df_i = pandas.DataFrame({'site':sites_eval['Site'][j],'proxy':proxy_i,'locRad':locRadv,'proxy_frac':proxy_frac,'Rscale':Rscale,'MC':MCi}, index=[df_ind])\n",
    "                    df_eval = pandas.concat([df_eval,df_i])\n",
    "\n",
    "                    df_ind += 1\n",
    "\n",
    "                # obs\n",
    "                ob_data = np.swapaxes(ob_stat[locRadi,proxy_fraci,Rscalei,MCi,:,:],0,1)\n",
    "                df_obi = pandas.DataFrame(data=ob_data,columns=df_ind_recon)\n",
    "                df_ob = pandas.concat([df_ob,df_obi])\n",
    "\n",
    "                #xb_std = np.copy(xb_stat[locRadi][proxy_fraci][Rscalei][MCi][:][:])\n",
    "                #ob_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, recon_period_len*2, sites_withhold_len), np.nan)\n",
    "                #xb_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, sites_withhold_len), np.nan)   # save full prior for withhold data\n",
    "                #xa_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, recon_period_len, sites_withhold_len), np.nan)\n",
    "\n",
    "                # xb\n",
    "                xb_data = np.swapaxes(xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,:],0,1)  # withhold x nens\n",
    "                df_xb_i  = pandas.DataFrame(data=xb_data)\n",
    "                df_xb = pandas.concat([df_xb,df_xb_i])\n",
    "\n",
    "                # xa\n",
    "                xa_data = np.swapaxes(xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,:,:],0,2)  # withhold x recon x nens\n",
    "                xa_data1 = xa_data.reshape((sites_withhold_len, recon_period_len*nens))\n",
    "                df_xa_i  = pandas.DataFrame(data=xa_data1)\n",
    "                df_xa = pandas.concat([df_xa,df_xa_i])\n",
    "\n",
    "            df_ob = df_ob.reset_index()\n",
    "            df_ob = df_ob.drop(columns='index')\n",
    "            df_xb = df_xb.reset_index()\n",
    "            df_xb = df_xb.drop(columns='index')\n",
    "            df_xa = df_xa.reset_index()\n",
    "            df_xa = df_xa.drop(columns='index')\n",
    "            print('')\n",
    "            print('Step #3: evaluation data preparation - Done')\n",
    "            print('')\n",
    "            if log_level > 3:\n",
    "                print('df_eval')\n",
    "                print(df_eval)\n",
    "                print('df_ob')\n",
    "                print(df_ob)\n",
    "                print('df_xb')\n",
    "                print(df_xb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for locRadi in range(locRadn):\n",
    "    locRad = local_rad_list[locRadi]\n",
    "    if locRad is None:\n",
    "        locRadv = 0 # for filename only\n",
    "    else:\n",
    "        locRadv = locRad\n",
    "    for proxy_fraci in range(proxy_fracn):\n",
    "        proxy_frac = proxy_frac_list[proxy_fraci]\n",
    "\n",
    "        for Rscalei in range(Rscalen):\n",
    "            \n",
    "        # debug ; remove the above codes and merge with the above codes\n",
    "        ###############################################################\n",
    "        # calculate RMSE, CE, R^2 for each time slice\n",
    "        ###############################################################\n",
    "        ###############################################################\n",
    "\n",
    "\n",
    "            df_reconi = pandas.DataFrame()\n",
    "\n",
    "            df_ind_i = 0\n",
    "            df_zscore_mc   = pandas.DataFrame()\n",
    "            df_zscore   = pandas.DataFrame()\n",
    "            df_ob_pi_all_col = pandas.DataFrame()\n",
    "            df_xb_pi_all_col = pandas.DataFrame()\n",
    "            df_xa_pi_all_col = pandas.DataFrame()\n",
    "            df_eval_pi_all_col = pandas.DataFrame()\n",
    "            \n",
    "            for reconi in range(recon_period_len):\n",
    "                \n",
    "                data_period_id_i = data_period_id[reconi]\n",
    "                \n",
    "                if log_level > 1:\n",
    "                    print('>>>>>>>  ')\n",
    "                    print('')\n",
    "                    print('reconi {}'.format(reconi))\n",
    "                    print(data_period_id_i)\n",
    "                    print('')\n",
    "                \n",
    "                # read ob, xb, and xa, in 1 column each\n",
    "                if proxy_eval_list:\n",
    "                    print('assimilated proxy i {}'.format(proxy_eval_list))\n",
    "                    \n",
    "                    df_ob_pi   = df_ob[data_period_id_i] \n",
    "                    df_xb_pi   = df_xb\n",
    "                    \n",
    "                    df_xa_pi   = df_xa[df_xa.columns[reconi*nens:(reconi+1)*nens]]\n",
    "                    df_xa_pi.columns = range(df_xa_pi.shape[1])\n",
    "                    \n",
    "                    if log_level > 4:\n",
    "                        print('df_xa_pi')\n",
    "                        print(df_xa_pi)\n",
    "                    df_eval_pi = df_eval\n",
    "                    \n",
    "                df_ob_pi_all_col = pandas.concat([df_ob_pi_all_col,df_ob_pi])\n",
    "                \n",
    "                # debug; only works for 1 single Xb\n",
    "                df_xb_pi_all_col = pandas.concat([df_xb_pi_all_col,df_xb_pi])\n",
    "                \n",
    "                df_xa_pi_all_col = pandas.concat([df_xa_pi_all_col,df_xa_pi])\n",
    "                df_eval_pi_all_col = pandas.concat([df_eval_pi_all_col,df_eval_pi])\n",
    "                \n",
    "            df_ob_pi_all_col = df_ob_pi_all_col.reset_index()\n",
    "            df_ob_pi_all_col = df_ob_pi_all_col.drop(columns='index')\n",
    "            df_xb_pi_all_col = df_xb_pi_all_col.reset_index()\n",
    "            df_xb_pi_all_col = df_xb_pi_all_col.drop(columns='index')\n",
    "            df_xa_pi_all_col = df_xa_pi_all_col.reset_index()\n",
    "            df_xa_pi_all_col = df_xa_pi_all_col.drop(columns='index')\n",
    "            df_eval_pi_all_col = df_eval_pi_all_col.reset_index()\n",
    "            df_eval_pi_all_col = df_eval_pi_all_col.drop(columns='index')\n",
    "            \n",
    "            if log_level > 4:\n",
    "                print('df_eval_pi')\n",
    "                print(df_eval_pi)\n",
    "                print('df_ob_pi_all_col')\n",
    "                print(df_ob_pi_all_col)\n",
    "                print('df_xb_pi_all_col')\n",
    "                print(df_xb_pi_all_col)\n",
    "                print('df_xa_pi_all_col')\n",
    "                print(df_xa_pi_all_col)\n",
    "                \n",
    "            # remove nan values in ob\n",
    "            df_xb_pi_all_col = df_xb_pi_all_col[df_ob_pi_all_col[0].notna()]\n",
    "            df_xa_pi_all_col = df_xa_pi_all_col[df_ob_pi_all_col[0].notna()]\n",
    "            df_eval_pi_all_col = df_eval_pi_all_col[df_ob_pi_all_col[0].notna()]\n",
    "            df_ob_pi_all_col = df_ob_pi_all_col.dropna()\n",
    "            \n",
    "            if log_level > 4:\n",
    "                print('df_eval_pi_all_col')\n",
    "                print(df_eval_pi_all_col)\n",
    "                print('df_ob_pi_all_col')\n",
    "                print(df_ob_pi_all_col)\n",
    "                print('df_xb_pi_all_col')\n",
    "                print(df_xb_pi_all_col)\n",
    "                print('df_xa_pi_all_col')\n",
    "                print(df_xa_pi_all_col)\n",
    "                \n",
    "                \n",
    "            # zscore by proxy type\n",
    "\n",
    "            for proxy_j in range(pn):\n",
    "\n",
    "                df_zscore_j = pandas.DataFrame()\n",
    "                \n",
    "                if proxy_eval_list:\n",
    "                    proxy_i = proxy_eval_list[proxy_j]\n",
    "                else:\n",
    "                    proxy_i = Typelist[proxy_j]\n",
    "                proxy_i = proxy_i.lower()\n",
    "                \n",
    "                print('assimilated proxy i {}'.format(proxy_i))\n",
    "\n",
    "                df_eval_pi = df_eval_pi_all_col[df_eval_pi_all_col['proxy'] == proxy_i]\n",
    "                if log_level > 4:\n",
    "                    print('df_eval_pi_all_col')\n",
    "                    print(df_eval_pi_all_col)\n",
    "                    print('df_eval_pi')\n",
    "                    print(df_eval_pi)\n",
    "                # debug\n",
    "                if pn > 1:\n",
    "                    df_ob_pi   = df_ob_pi_all_col[df_eval_pi_all_col['proxy'] == proxy_i]\n",
    "                    df_xb_pi   = df_xb_pi_all_col[df_eval_pi_all_col['proxy'] == proxy_i]\n",
    "                    df_xa_pi   = df_xa_pi_all_col[df_eval_pi_all_col['proxy'] == proxy_i]\n",
    "                else:\n",
    "                    df_ob_pi   = df_ob_pi_all_col\n",
    "                    df_xb_pi   = df_xb_pi_all_col\n",
    "                    df_xa_pi   = df_xa_pi_all_col\n",
    "                # debug end\n",
    "                df_ob_pi = df_ob_pi.reset_index()\n",
    "                df_ob_pi = df_ob_pi.drop(columns='index')\n",
    "                df_xb_pi = df_xb_pi.reset_index()\n",
    "                df_xb_pi = df_xb_pi.drop(columns='index')\n",
    "                df_xa_pi = df_xa_pi.reset_index()\n",
    "                df_xa_pi = df_xa_pi.drop(columns='index')\n",
    "                \n",
    "                if log_level > 4:\n",
    "                    print('df_ob_pi reset index')\n",
    "                    print(df_ob_pi)\n",
    "                    print('df_ob_pi drop index')\n",
    "                    print(df_ob_pi)\n",
    "                \n",
    "                df_ob_pi_mean = list(pandas.Series.mean(df_ob_pi))\n",
    "                df_ob_pi_std  = list(pandas.Series.std(df_ob_pi))\n",
    "                \n",
    "                if log_level > 2:\n",
    "                    print('df_ob_pi_mean {}'.format(df_ob_pi_mean))\n",
    "                    print('df_ob_pi_std  {}'.format(df_ob_pi_std))\n",
    "                \n",
    "                df_xb_pi_all = df_xb_pi.mean(axis=1)\n",
    "\n",
    "                df_xa_pi_all = df_xa_pi.mean(axis=1)\n",
    "                \n",
    "                if log_level > 4:\n",
    "                    print('df_xb_pi_all  mean')\n",
    "                    print(df_xb_pi_all)\n",
    "                    print('df_xa_pi_all  mean')\n",
    "                    print(df_xa_pi_all)\n",
    "                \n",
    "                df_ob_pi_zscore = (df_ob_pi - df_ob_pi_mean) / df_ob_pi_std\n",
    "                df_xb_pi_zscore = (df_xb_pi_all - df_ob_pi_mean) / df_ob_pi_std\n",
    "                df_xa_pi_zscore = (df_xa_pi_all - df_ob_pi_mean) / df_ob_pi_std\n",
    "                \n",
    "                if log_level > 4:\n",
    "                    print('df_ob_pi')\n",
    "                    print(df_ob_pi)\n",
    "                    print('df_ob_pi_zscore')\n",
    "                    print(df_ob_pi_zscore)\n",
    "                    #print('df_xb_pi')\n",
    "                    #print(df_xb_pi)\n",
    "                    print('df_xb_pi_zscore')\n",
    "                    print(df_xb_pi_zscore)\n",
    "                    #print('df_xa_pi')\n",
    "                    #print(df_xa_pi)\n",
    "                    print('df_xa_pi_zscore')\n",
    "                    print(df_xa_pi_zscore)\n",
    "                    \n",
    "                #for MCii in range(MCn): df_zscore_j.loc[MCii, ['proxy']] = proxy_i\n",
    "                #for MCii in range(MCn): df_zscore_j.loc[MCii, ['reconi']] = data_period_id_i\n",
    "                #for MCii in range(MCn): df_zscore_j.loc[MCii, ['loc']] = locRadi\n",
    "                #for MCii in range(MCn): df_zscore_j.loc[MCii, ['proxy_frac']] = proxy_fraci\n",
    "                #for MCii in range(MCn): df_zscore_j.loc[MCii, ['Rscale']] = Rscale\n",
    "                pnii = len(df_ob_pi)\n",
    "                print(pnii)\n",
    "                for MCii in range(pnii): df_zscore_j.loc[MCii, ['proxy']] = proxy_i\n",
    "                for MCii in range(pnii): df_zscore_j.loc[MCii, ['reconi']] = data_period_id_i\n",
    "                for MCii in range(pnii): df_zscore_j.loc[MCii, ['loc']] = locRadi\n",
    "                for MCii in range(pnii): df_zscore_j.loc[MCii, ['proxy_frac']] = proxy_fraci\n",
    "                for MCii in range(pnii): df_zscore_j.loc[MCii, ['Rscale']] = Rscale\n",
    "                \n",
    "                if log_level > 3:\n",
    "                    print('df_zscore_j')\n",
    "                    print(df_zscore_j)\n",
    "                df_zscore_j['ob'] = df_ob_pi\n",
    "                df_zscore_j['xb'] = df_xb_pi_all\n",
    "                df_zscore_j['xa'] = df_xa_pi_all\n",
    "                \n",
    "                df_zscore_j['ob_zscore'] = df_ob_pi_zscore\n",
    "                df_zscore_j['xb_zscore'] = df_xb_pi_zscore\n",
    "                df_zscore_j['xa_zscore'] = df_xa_pi_zscore\n",
    "                if log_level > 3:\n",
    "                    print('df_zscore_j')\n",
    "                    print(df_zscore_j)\n",
    "                df_zscore = pandas.concat([df_zscore,df_zscore_j])\n",
    "\n",
    "                if log_level > 4:\n",
    "                    print('df_eval_pi')\n",
    "                    print(df_eval_pi)\n",
    "                    print('df_ob_pi')\n",
    "                    print(df_ob_pi)\n",
    "                    print('df_xb_pi first 6 rows')\n",
    "                    print(df_xb_pi[:][0:6])\n",
    "                    print('df_xa_pi')\n",
    "                    print(df_xa_pi)\n",
    "                        \n",
    "            if log_level > 3:\n",
    "                print(' ')\n",
    "                print('df_zscore:')\n",
    "                print(df_zscore)\n",
    "\n",
    "            rmse_xb = DeepDA_psm.rmse(df_zscore['ob_zscore'],df_zscore['xb_zscore'])\n",
    "\n",
    "            CE_xb = DeepDA_psm.CE_NS70(df_zscore['ob_zscore'],df_zscore['xb_zscore'],1)\n",
    "            \n",
    "            if log_level > 1:\n",
    "                \n",
    "                print('RMSE of Ob vs. Xb {}'.format(rmse_xb))\n",
    "                print('CE of Ob vs. Xb {}'.format(CE_xb))\n",
    "\n",
    "            a=ma.masked_invalid(df_zscore['ob_zscore'])\n",
    "            b=ma.masked_invalid(df_zscore['xb_zscore'])\n",
    "            msk = (~a.mask & ~b.mask)\n",
    "            cor_matrix = ma.corrcoef(a[msk],b[msk])\n",
    "            r_2_xb = cor_matrix[0,1]**2\n",
    "\n",
    "            if log_level > 1:\n",
    "                print('r^2 of Ob vs. Xb {}'.format(r_2_xb))\n",
    "                print('')\n",
    "\n",
    "\n",
    "            rmse_xa = DeepDA_psm.rmse(df_zscore['ob_zscore'],df_zscore['xa_zscore'])\n",
    "\n",
    "            CE_xa = DeepDA_psm.CE_NS70(df_zscore['ob_zscore'],df_zscore['xa_zscore'],1)\n",
    "\n",
    "            if log_level > 1:\n",
    "                print('RMSE of Ob vs. Xa {}'.format(rmse_xa))\n",
    "                print('CE of Ob vs. Xb {}'.format(CE_xa))\n",
    "\n",
    "            b=ma.masked_invalid(df_zscore['xa_zscore'])\n",
    "            msk = (~a.mask & ~b.mask)\n",
    "            cor_matrix = ma.corrcoef(a[msk],b[msk])\n",
    "            r_2_xa = cor_matrix[0,1]**2\n",
    "\n",
    "            if log_level > 1:\n",
    "                print('r^2 of Ob vs. Xa {}'.format(r_2_xa))\n",
    "                print(' --- ')\n",
    "                print('')\n",
    "            # delta RMSE, CE, and R^2\n",
    "            drmse = 100 * (rmse_xb - rmse_xa)/rmse_xb\n",
    "            dce   = 100 * (CE_xb - CE_xa)/CE_xb\n",
    "            dr2   = 100 * (r_2_xb - r_2_xa)/r_2_xb\n",
    "\n",
    "            df_reconi = pandas.DataFrame({'reconi':reconi,\n",
    "                                          'data_period_id_i':data_period_id_i,\n",
    "                                          'loc':locRadv,\n",
    "                                          'proxy_frac':proxy_frac,\n",
    "                                          'Rscale':Rscale,\n",
    "                                          'RMSE Xb':rmse_xb,\n",
    "                                          'RMSE Xa':rmse_xa,\n",
    "                                          'dRMSE':drmse,\n",
    "                                          'CE Xb':CE_xb,\n",
    "                                          'CE Xa': CE_xa,\n",
    "                                          'dCE':dce,\n",
    "                                          'R^2 Xb':r_2_xb,\n",
    "                                          'R^2 Xa': r_2_xa,\n",
    "                                          'dR^2':dr2}, index=[df_ind_i])\n",
    "\n",
    "            df_evaluation = pandas.concat([df_evaluation,df_reconi])\n",
    "\n",
    "            df_ind_i += 1\n",
    "\n",
    "            df_zscore_mc = pandas.concat([df_zscore_mc,df_zscore])\n",
    "\n",
    "        df_evaluation = pandas.concat([df_evaluation,df_reconi])\n",
    "\n",
    "        df_zscore_all = pandas.concat([df_zscore_all,df_zscore_mc])\n",
    "        print(' This loop done ')\n",
    "                \n",
    "        \n",
    "if savesummary:\n",
    "    df_zscore_all.to_csv(yml_dict['core']['proj_dir']+'/wrk/'+en+savefilename_add+'_df_zscore_all'+'.csv')\n",
    "    df_evaluation.sort_index().to_csv(yml_dict['core']['proj_dir']+'/wrk/'+en+'_df_evaluation_log.csv')\n",
    "\n",
    "print('')\n",
    "print('Step #4: evaluation - Done')\n",
    "print('')\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -3.250338\n",
      "dtype: float64\n",
      "0    0.705239\n",
      "dtype: float64\n",
      "3     -3.986148\n",
      "5     -3.985556\n",
      "8     -1.542667\n",
      "10    -5.120917\n",
      "21    -3.645565\n",
      "22    -3.644957\n",
      "32    -3.644814\n",
      "33    -3.646079\n",
      "34    -5.184041\n",
      "35    -5.183511\n",
      "39    -5.606343\n",
      "40    -5.606529\n",
      "56    -3.986148\n",
      "58    -3.985556\n",
      "61    -1.542667\n",
      "63    -5.120917\n",
      "74    -3.645565\n",
      "75    -3.644957\n",
      "82    -2.983595\n",
      "83    -2.983297\n",
      "85    -3.644814\n",
      "86    -3.646079\n",
      "92    -5.606343\n",
      "93    -5.606529\n",
      "94    -2.904650\n",
      "95    -2.904417\n",
      "98    -3.839952\n",
      "99    -3.841066\n",
      "102   -3.871986\n",
      "103   -3.872500\n",
      "dtype: float64\n",
      "3     -0.735811\n",
      "5     -0.735218\n",
      "8      1.707671\n",
      "10    -1.870579\n",
      "21    -0.395227\n",
      "22    -0.394620\n",
      "32    -0.394476\n",
      "33    -0.395741\n",
      "34    -1.933703\n",
      "35    -1.933174\n",
      "39    -2.356006\n",
      "40    -2.356191\n",
      "56    -0.735811\n",
      "58    -0.735218\n",
      "61     1.707671\n",
      "63    -1.870579\n",
      "74    -0.395227\n",
      "75    -0.394620\n",
      "82     0.266742\n",
      "83     0.267041\n",
      "85    -0.394476\n",
      "86    -0.395741\n",
      "92    -2.356006\n",
      "93    -2.356191\n",
      "94     0.345688\n",
      "95     0.345921\n",
      "98    -0.589614\n",
      "99    -0.590729\n",
      "102   -0.621648\n",
      "103   -0.622162\n",
      "dtype: float64\n",
      "3     -1.043349\n",
      "5     -1.042509\n",
      "8      2.421407\n",
      "10    -2.652405\n",
      "21    -0.560416\n",
      "22    -0.559555\n",
      "32    -0.559351\n",
      "33    -0.561145\n",
      "34    -2.741912\n",
      "35    -2.741161\n",
      "39    -3.340720\n",
      "40    -3.340983\n",
      "56    -1.043349\n",
      "58    -1.042509\n",
      "61     2.421407\n",
      "63    -2.652405\n",
      "74    -0.560416\n",
      "75    -0.559555\n",
      "82     0.378230\n",
      "83     0.378653\n",
      "85    -0.559351\n",
      "86    -0.561145\n",
      "92    -3.340720\n",
      "93    -3.340983\n",
      "94     0.490172\n",
      "95     0.490502\n",
      "98    -0.836049\n",
      "99    -0.837629\n",
      "102   -0.881471\n",
      "103   -0.882201\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     3.789859\n",
      "2     0.608182\n",
      "3    -1.768513\n",
      "4     3.449635\n",
      "5    -1.734330\n",
      "        ...   \n",
      "48    0.927895\n",
      "49   -3.857000\n",
      "50   -3.307778\n",
      "51    4.362609\n",
      "52    3.414800\n",
      "Name: 0, Length: 140, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_ob_pi_all_col[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unused code; \n",
    "# because pre and peak have to be 1 coulumn\n",
    "#\n",
    "for locRadi in range(locRadn):\n",
    "    locRad = local_rad_list[locRadi]\n",
    "    if locRad is None:\n",
    "        locRadv = 0 # for filename only\n",
    "    else:\n",
    "        locRadv = locRad\n",
    "    for proxy_fraci in range(proxy_fracn):\n",
    "        proxy_frac = proxy_frac_list[proxy_fraci]\n",
    "\n",
    "        for Rscalei in range(Rscalen):\n",
    "            Rscale = Rscale_list[Rscalei]\n",
    "\n",
    "            savefilename_add = '_loc_'+ str(locRadv)+'_proxy_frac_'+ str(proxy_frac)+'_Rscale_'+str(Rscale)\n",
    "\n",
    "            for MCi in range(MCn):\n",
    "                # NetCDF file name\n",
    "                filename_short = '_loc_', str(locRadv),'_proxy_frac_', str(proxy_frac),'_Rscale_',str(Rscale),'_MC_',str(MCi) \n",
    "                nc_filename = MC_dir + ''.join(filename_short) + '.nc'\n",
    "                hdf5name    = MC_dir + ''.join(filename_short) + '.hdf5'\n",
    "\n",
    "                print('>>  Read nc file: {}'.format(nc_filename))\n",
    "\n",
    "                for Xa2d_vari in range(prior_variable_len):\n",
    "\n",
    "                    Xa_full_name_vari = prior_variable_dict[Xa2d_vari] +'_Xa_full'\n",
    "                    Xa_mean_name_vari = prior_variable_dict[Xa2d_vari] +'_Xa_mean'\n",
    "                    Xa_variance_name_vari = prior_variable_dict[Xa2d_vari] +'_Xa_variance'\n",
    "                    Xa_full_vari = Dataset(nc_filename).variables[Xa_full_name_vari][:]\n",
    "                    Xa_mean_vari = Dataset(nc_filename).variables[Xa_mean_name_vari][:]\n",
    "                    Xa_variance_vari = Dataset(nc_filename).variables[Xa_variance_name_vari][:]\n",
    "\n",
    "                    if prior_variable_dict[Xa2d_vari] in limit_hard_keys:\n",
    "                        # some variables have hard limitation: e.g., CaCO3 = [0, 100]                        \n",
    "                        lim_min = yml_dict['prior'][prior_source]['limit_hard'][prior_variable_dict[Xa2d_vari]]['lim_min']\n",
    "                        lim_max = yml_dict['prior'][prior_source]['limit_hard'][prior_variable_dict[Xa2d_vari]]['lim_max']\n",
    "                        #print('limit min {} and max {}'.format(lim_min, lim_max))\n",
    "                        if lim_min:\n",
    "                            if np.any(Xa_full_vari<lim_min):\n",
    "                                Xa_full_vari[Xa_full_vari<lim_min] = lim_min\n",
    "                                Xa_mean_vari = np.mean(Xa_full_vari,axis=2)\n",
    "                                Xa_variance_vari = np.var(Xa_full_vari,axis=2)\n",
    "                                print('>>    Force {} value to be >= {}'.format(prior_variable_dict[Xa2d_vari],lim_min))\n",
    "                        if lim_max:\n",
    "                            if np.any(Xa_full_vari>lim_max):\n",
    "                                Xa_full_vari[Xa_full_vari>lim_max] = lim_max\n",
    "                                Xa_mean_vari = np.mean(Xa_full_vari,axis=2)\n",
    "                                Xa_variance_vari = np.var(Xa_full_vari,axis=2)\n",
    "                                print('>>    Force {} value to be <= {}'.format(prior_variable_dict[Xa2d_vari], lim_max))\n",
    "\n",
    "                    for reconi in range(recon_period_len):\n",
    "\n",
    "                        Xa_full_reconi = Xa_full_vari[:,:,:,0,reconi].reshape((dum_ijmax,nens))\n",
    "                        Xa_full_reconi_mean = np.nanmean(Xa_full_reconi,axis=0)\n",
    "\n",
    "                        Xa_mean_reconi = Xa_mean_vari[:,:,0,reconi]\n",
    "                        Xa2d_all_np[:,:,locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = np.copy(Xa_mean_vari[:,:,0,reconi])\n",
    "                        Xa_mean_reconi_mean = np.nanmean(Xa_mean_reconi)\n",
    "\n",
    "                        Xa_variance_reconi = Xa_variance_vari[:,:,0,reconi]\n",
    "                        Xa2d_allstd_np[:,:,locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = Xa_variance_vari[:,:,0,reconi]\n",
    "                        Xa_std_reconi_mean = np.sqrt(np.nanmean(Xa_variance_reconi))\n",
    "\n",
    "                        #print('>>  reconi = {}, mean is {}, std is {}'.format(reconi, Xa_mean_reconi_mean, Xa_std_reconi_mean))\n",
    "                        Xa2d_full_np[locRadi,proxy_fraci,Rscalei,MCi*nens:(MCi+1)*nens,Xa2d_vari,reconi] = Xa_full_reconi_mean\n",
    "                        Xa2d_mean_np[locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = Xa_mean_reconi_mean\n",
    "                        Xa2d_std_np[locRadi,proxy_fraci,Rscalei,MCi,Xa2d_vari,reconi] = Xa_std_reconi_mean\n",
    "            print('First variable: all MC mean')\n",
    "            print(Xa2d_mean_np[locRadi,proxy_fraci,Rscalei,:,0,0])\n",
    "\n",
    "            Xa2d_all_np = np.ma.masked_where(Xa2d_all_np > 9.0e+36, Xa2d_all_np)\n",
    "            Xa2d_allstd_np = np.ma.masked_where(Xa2d_all_np > 9.0e+36, Xa2d_allstd_np)\n",
    "            for Xa2d_vari in range(prior_variable_len):\n",
    "                for reconi in range(recon_period_len):\n",
    "                    Xa2d_mean_np2[locRadi,proxy_fraci,Rscalei,Xa2d_vari,reconi] = np.nanmean(Xa2d_all_np[:,:,locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi])\n",
    "                    Xa2d_std_np2[locRadi,proxy_fraci,Rscalei,Xa2d_vari,reconi] = np.sqrt(np.nanmean(Xa2d_allstd_np[:,:,locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi]))\n",
    "\n",
    "            np.set_printoptions(precision=6, suppress=True)\n",
    "            if log_level > 1:\n",
    "                print('All variable. Mean of variables x reconi')\n",
    "                print('{}'.format(Xa2d_mean_np2[locRadi,proxy_fraci,Rscalei,:,:]))\n",
    "            #print('std  of variables x reconi')\n",
    "            #print('{}'.format(Xa2d_std_np2))\n",
    "\n",
    "            print('')\n",
    "            print('Step #1: read data - Done')\n",
    "            print('')\n",
    "\n",
    "            # Calculate mean and std of each variable for each time slice\n",
    "            # plot the ensemble values\n",
    "\n",
    "            df = pandas.DataFrame()\n",
    "            print('')\n",
    "            print('DA - Summary of global mean and standard deviation')\n",
    "            print('')\n",
    "\n",
    "            if showplot:\n",
    "                fig, (ax0, ax1, ax2, ax3) = plt.subplots(nrows=4, figsize=(3, 6))\n",
    "                if recon_period_len>1:\n",
    "                    fig2, (ax10, ax11, ax12, ax13) = plt.subplots(nrows=4, figsize=(3, 6))\n",
    "                params = {'mathtext.default': 'regular' }\n",
    "                plt.rcParams.update(params)\n",
    "                #plt.rcParams.update({'figure.figsize':(5,3), 'figure.dpi':110})\n",
    "                #fig.suptitle('DA')\n",
    "\n",
    "            # 2d variables\n",
    "            for Xa2d_vari in range(prior_variable_len):\n",
    "\n",
    "                print(prior_variable_dict[Xa2d_vari])\n",
    "                datadf = {'field':prior_variable_dict[Xa2d_vari],'mean':[np.nan],'std':[np.nan],\n",
    "                          '2.5%':[np.nan],'5%':[np.nan],'25%':[np.nan],'median':[np.nan],'75%':[np.nan],'95%':[np.nan],'97.5%':[np.nan],'label':''}\n",
    "                df2 = pandas.DataFrame(datadf, index=[Xa2d_vari])\n",
    "                df = pandas.concat([df,df2])\n",
    "\n",
    "                sst_std_mc = np.std(Xa2d_mean_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,:],axis=0)\n",
    "                if log_level > 2:\n",
    "                    print('  _locR '+str(locRadv)+' proxy_frac '+str(proxy_frac)+' scaled r '+str(Rscale))\n",
    "\n",
    "                for reconi in range(recon_period_len):\n",
    "\n",
    "                    meani = np.nanmean(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi])\n",
    "                    stdi = np.std(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi])\n",
    "                    perc = np.percentile(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi],np.array([2.5, 5, 25, 50, 75, 95, 97.5]))\n",
    "                    datadf = {'field':'','mean':[meani],'std':[stdi],\n",
    "                              '2.5%':[perc[0]],'5%':[perc[1]],'25%':[perc[2]],'median':[perc[3]],'75%':[perc[4]],'95%':[perc[5]],'97.5%':[perc[6]],'label':label_all[reconi]}\n",
    "                    df2 = pandas.DataFrame(data = datadf, index=[Xa2d_vari])\n",
    "                    df = pandas.concat([df,df2])\n",
    "                    if log_level > 2:\n",
    "                        print('    {:.3f} ± {:.3f}: {}'.format(meani, stdi, label_all[reconi]))\n",
    "\n",
    "                    if recon_period_len>2:\n",
    "                        warmpeak = Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,1]-Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,0]\n",
    "                        #warmbody = Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,2]-Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,0]\n",
    "                        coolpeak = Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,2]-Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,1]\n",
    "                        warmpeakmean = np.nanmean(warmpeak)\n",
    "                        warmpeakstd  = np.std(warmpeak)\n",
    "                        warmperc = np.percentile(warmpeak,np.array([2.5, 5, 25, 50, 75, 95, 97.5]))\n",
    "                        coolpeakmean = np.nanmean(coolpeak)\n",
    "                        coolpeakstd  = np.std(coolpeak)\n",
    "                        coolperc = np.percentile(coolpeak,np.array([2.5, 5, 25, 50, 75, 95, 97.5]))\n",
    "\n",
    "                if recon_period_len>2:\n",
    "                    df2 = pandas.DataFrame({'field':'','mean':[warmpeakmean],'std':[warmpeakstd],\n",
    "                                            '2.5%':[warmperc[0]],'5%':[warmperc[1]],'25%':[warmperc[2]],'median':[warmperc[3]],'75%':[warmperc[4]],'95%':[warmperc[5]],'97.5%':[warmperc[6]],'label':'Peak_warming'}, index=[Xa2d_vari])\n",
    "                    df3 = pandas.DataFrame({'field':'','mean':[coolpeakmean],'std':[coolpeakstd],\n",
    "                                            '2.5%':[coolperc[0]],'5%':[coolperc[1]],'25%':[coolperc[2]],'median':[coolperc[3]],'75%':[coolperc[4]],'95%':[coolperc[5]],'97.5%':[coolperc[6]],'label':'Peak_cooling'}, index=[Xa2d_vari])\n",
    "                    df = pandas.concat([df,df2,df3])\n",
    "                    if log_level > 2:\n",
    "                        print('    {:.6f} ± {:.6f}: peak warming'.format(warmpeakmean,warmpeakstd))\n",
    "                        print('    {:.6f} ± {:.6f}: peak cooling'.format(coolpeakmean,coolpeakstd))\n",
    "\n",
    "                if showplot:\n",
    "                    for reconi in range(recon_period_len):\n",
    "                        if reconi == 3:\n",
    "                            continue\n",
    "                        kwargs = dict(alpha=0.5, bins=50)\n",
    "\n",
    "                        if Xa2d_vari == 0:\n",
    "                            ax0.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                            ax0.set_ylabel('#')\n",
    "                            ax0.set_xlabel('SST (\\u00B0C)')\n",
    "                            ax0.tick_params(labelsize='small')\n",
    "                            ax0.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 1:\n",
    "                            ax1.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                            ax1.set_ylabel('#')\n",
    "                            ax1.set_xlabel('SAT (\\u00B0C)')\n",
    "                            ax1.tick_params(labelsize='small')\n",
    "                            ax1.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 2:\n",
    "                            ax2.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                            ax2.set_ylabel('#')\n",
    "                            ax2.set_xlabel('$\\it{p}$CO$_2$ (ppm)')\n",
    "                            ax2.set_xlim(0, 2800)\n",
    "                            ax2.legend(prop={'size': 6.5})  \n",
    "                            ax2.tick_params(labelsize='small')\n",
    "                            ax2.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        #if Xa2d_vari == 3:\n",
    "                        #    ax3.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                        #    ax3.set_ylabel('Number')\n",
    "                        #    ax3.set_xlabel('Salinity (PSU)')\n",
    "                        if Xa2d_vari == 4:\n",
    "                            ax3.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                            ax3.set_ylabel('#')\n",
    "                            ax3.set_xlabel('pH')     \n",
    "                            ax3.tick_params(labelsize='small')\n",
    "                            ax3.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        #if Xa2d_vari == 6:\n",
    "                        #    ax5.hist(Xa2d_full_np[locRadi,proxy_fraci,Rscalei,:,Xa2d_vari,reconi], **kwargs, label = label_all[reconi])\n",
    "                        #    ax5.set_ylabel('Number')\n",
    "                        #    ax5.set_xlabel('$CaCO_3$ (%)')\n",
    "                    fig.tight_layout()\n",
    "\n",
    "                    if recon_period_len>1:\n",
    "                        if Xa2d_vari == 0:                    \n",
    "                            ax10.hist(warmpeak, **kwargs, color = \"#ff7f0e\", label = 'warming')\n",
    "                            ax10.hist(coolpeak, **kwargs, color = \"#2ca02c\", label = 'cooling')\n",
    "                            ax10.set_ylabel('#')\n",
    "                            ax10.set_xlabel('\\u0394SST (\\u00B0C)')                        \n",
    "                            ax10.legend(prop={'size': 6.5});\n",
    "                            ax10.tick_params(labelsize='small')\n",
    "                            ax10.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 1:\n",
    "                            ax11.hist(warmpeak, **kwargs, color = \"#ff7f0e\")\n",
    "                            ax11.hist(coolpeak, **kwargs, color = \"#2ca02c\")\n",
    "                            ax11.set_ylabel('#')\n",
    "                            ax11.set_xlabel('\\u0394SAT (\\u00B0C)')\n",
    "                            ax11.tick_params(labelsize='small')\n",
    "                            ax11.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 2:\n",
    "                            ax12.hist(warmpeak, **kwargs, color = \"#ff7f0e\")\n",
    "                            ax12.hist(coolpeak, **kwargs, color = \"#2ca02c\")\n",
    "                            ax12.set_ylabel('#')\n",
    "                            ax12.set_xlabel('\\u0394$\\it{p}$CO$_2$ (ppm)')\n",
    "                            ax12.tick_params(labelsize='small')\n",
    "                            ax12.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        if Xa2d_vari == 4:\n",
    "                            ax13.hist(warmpeak, **kwargs, color = \"#ff7f0e\")\n",
    "                            ax13.hist(coolpeak, **kwargs, color = \"#2ca02c\")\n",
    "                            ax13.set_ylabel('#')\n",
    "                            ax13.set_xlabel('\\u0394pH')\n",
    "                            ax13.tick_params(labelsize='small')\n",
    "                            ax13.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "                        fig2.tight_layout()\n",
    "\n",
    "            if showplot:\n",
    "                fig.savefig(yml_dict['core']['proj_dir']+'/wrk/'+en+'.summary.pdf')\n",
    "                if recon_period_len > 1:\n",
    "                    fig2.savefig(yml_dict['core']['proj_dir']+'/wrk/'+en+'.delta.pdf')\n",
    "\n",
    "            # print and save excel\n",
    "            if savesummary_slice:\n",
    "                print('saved @')\n",
    "                fullname = yml_dict['core']['proj_dir']+'/wrk/'+en+savefilename_add+'.summary.csv'\n",
    "                print(fullname)\n",
    "                df.to_csv(fullname)\n",
    "\n",
    "            print('')\n",
    "            print('Step #2: summary - Done')\n",
    "            print('')\n",
    "\n",
    "\n",
    "\n",
    "            ### Purpose of this block\n",
    "            # Prepare data for verification\n",
    "            #\n",
    "            ### Steps\n",
    "            # 1. Prepare matrix for data saving: proxy, prior, posterior; std or not\n",
    "            # 2. calculate and save each Monte Carlo runs\n",
    "\n",
    "            #####################    User defined start   #####################\n",
    "            if log_level > 1:\n",
    "                print('DA - Read proxy, prior, and posterior, standardize')\n",
    "                print('')\n",
    "            #####################    User defined end     #####################\n",
    "\n",
    "            df_eval = pandas.DataFrame()\n",
    "            df_ob   = pandas.DataFrame()\n",
    "            df_xb   = pandas.DataFrame()\n",
    "            df_xa   = pandas.DataFrame()\n",
    "\n",
    "            # Get the sites_withhold_len\n",
    "\n",
    "            #locRad = local_rad_list[0]\n",
    "            #if locRad is None:\n",
    "            #    locRadv = 0 # for filename only\n",
    "            #else:\n",
    "            #    locRadv = locRad\n",
    "\n",
    "            #proxy_frac = proxy_frac_list[0]\n",
    "            #Rscale = Rscale_list[0]\n",
    "            filename_short = '_loc_', str(locRadv),'_proxy_frac_', str(proxy_frac),'_Rscale_',str(Rscale),'_MC_0.hdf5'\n",
    "            hdf5name = MC_dir + ''.join(filename_short)\n",
    "            if log_level > 1:\n",
    "                print('Read first hdf5 file {} to get the number of withold datasets.'.format(hdf5name))\n",
    "            if proxy_eval_list:\n",
    "                sites_eval = proxy_select  # if use evaluate list, more than the leave-1-out model\n",
    "            else:\n",
    "                sites_eval = pandas.read_hdf(hdf5name, 'sites_eval')  # if use the default list, less than the leave-1-out model\n",
    "\n",
    "            sites_withhold_len  = len(sites_eval)\n",
    "            \n",
    "            if log_level > 1:\n",
    "                print(' Site withhold length ： {}'.format(sites_withhold_len))\n",
    "\n",
    "            data_psm_d18o_find = 0\n",
    "            data_psm_mgca_find = 0\n",
    "            if 'Marine sediments_mgca_pooled_bcp' in proxy_list or 'Marine sediments_mgca_pooled_red' in proxy_list:\n",
    "                data_psm_mgca_find = 1\n",
    "            \n",
    "            # debug:   force the DA to calculate Xb_sal, Xb_ph and Xb_sal, etc.\n",
    "            data_psm_mgca_find = 1\n",
    "            # debug:   end\n",
    "            \n",
    "            if 'Marine sediments_d18o_pooled' in proxy_list:\n",
    "                data_psm_d18o_find = 1\n",
    "\n",
    "            # Prepare empty matrix for saving the data of proxy, prior, and posterior\n",
    "            ob_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, recon_period_len*2, sites_withhold_len), np.nan)\n",
    "            xb_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, sites_withhold_len), np.nan)   # save full prior for withhold data\n",
    "            xa_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, recon_period_len, sites_withhold_len), np.nan)\n",
    "\n",
    "            df_ind = 0\n",
    "\n",
    "            # columns name for the observation\n",
    "            df_ind_recon = []\n",
    "\n",
    "            for reconi in range(recon_period_len):\n",
    "                df_ind_recon_i = [data_period_id[reconi]] + [data_period_idstd[reconi]]\n",
    "                df_ind_recon = df_ind_recon + df_ind_recon_i\n",
    "\n",
    "            if log_level > 2:\n",
    "                print(df_ind_recon)\n",
    "\n",
    "\n",
    "            for MCi in range(MCn):\n",
    "            #for MCi in range(1):\n",
    "                # NetCDF file name\n",
    "                filename_short = '_loc_', str(locRadv),'_proxy_frac_', str(proxy_frac),'_Rscale_',str(Rscale),'_MC_' + str(MCi)\n",
    "                nc_filename = MC_dir + ''.join(filename_short) + '.nc'\n",
    "                print('    {}'.format(nc_filename))\n",
    "                hdf5name    = MC_dir + ''.join(filename_short) + '.hdf5'\n",
    "\n",
    "                if data_psm_mgca_find == 1:\n",
    "                    with h5py.File(hdf5name, 'r') as f:\n",
    "                        Xb_sal = np.copy(f.get('Xb_sal'))\n",
    "                        if log_level > 3:\n",
    "                            print(Xb_sal.shape)\n",
    "                        Xb_omega = np.copy((f.get('Xb_omega')))\n",
    "                        Xb_ph = np.copy(f.get('Xb_ph'))\n",
    "                    Xa_sal_full = Dataset(nc_filename).variables['ocn_sur_sal_Xa_full']\n",
    "                    Xa_ph_full  = Dataset(nc_filename).variables['misc_pH_Xa_full']\n",
    "                    Xa_omega_full = Dataset(nc_filename).variables['carb_sur_ohm_cal_Xa_full']\n",
    "\n",
    "                elif data_psm_d18o_find == 1:\n",
    "                    with h5py.File(hdf5name, 'r') as f:\n",
    "                        Xb_sal = np.copy(f.get('Xb_sal'))\n",
    "                        if log_level > 3:\n",
    "                            print(Xb_sal.shape)\n",
    "                        Xb_ph = np.copy(f.get('Xb_ph'))\n",
    "                    Xa_sal_full = Dataset(nc_filename).variables['ocn_sur_sal_Xa_full']\n",
    "                    Xa_ph_full  = Dataset(nc_filename).variables['misc_pH_Xa_full']\n",
    "\n",
    "\n",
    "                ### Read Proxy ###\n",
    "                proxies = pandas.read_hdf(hdf5name, 'proxies')\n",
    "                #prior_variable_dict = pandas.read_hdf(hdf5name, 'prior_variable_dict')\n",
    "\n",
    "                if proxy_frac <= 1.0:\n",
    "                    if proxy_eval_list:\n",
    "                        sites_eval = proxy_select  # if use evaluate list, more than the leave-1-out model\n",
    "                    else:\n",
    "                        sites_eval = pandas.read_hdf(hdf5name, 'sites_eval')\n",
    "                    sites_withhold_len  = len(sites_eval)\n",
    "                    if log_level > 1:\n",
    "                        print('Site withhold:       {}'.format(sites_eval['Site'].values))\n",
    "                        print('Proxy        :       {}'.format(sites_eval['Proxy'].values))\n",
    "\n",
    "                proxy_psm_type_dict_df = pandas.read_hdf(hdf5name, 'proxy_psm_type_dict_df')\n",
    "                proxy_psm_type_dict_list = proxy_psm_type_dict_df[0].values.tolist()\n",
    "\n",
    "                for j in range(sites_withhold_len):\n",
    "                    data_psm_type = sites_eval['Proxy'][j]\n",
    "                    for key, value in proxy_assim2.items():\n",
    "                        if data_psm_type in value:\n",
    "                            #print(proxy_psm_type[key])\n",
    "                            key0 = key\n",
    "                            psm_required_variable_key = list(yml_dict['psm'][proxy_psm_type[key]]['psm_required_variables'].keys())[0]\n",
    "                            xb_key = psm_required_variable_key+'_Xb_full'\n",
    "                            xa_key = psm_required_variable_key+'_Xa_full'\n",
    "                            #print('xa_key is {}'.format(xa_key))\n",
    "                            Xb_full_field0 = Dataset(nc_filename).variables[xb_key] #\n",
    "                            Xb_full_field0 = Xb_full_field0[:,:,:,0].reshape(dum_imax*dum_jmax, nens)\n",
    "                            Xa_full_field0 = Dataset(nc_filename).variables[xa_key]\n",
    "\n",
    "                    if proxy_psm_type[key0] in ['bayesreg_tex86', 'cgenie_caco3']:\n",
    "                        if proxy_psm_type[key0] in ['bayesreg_tex86']:\n",
    "                            proxy_i = 'tex86'\n",
    "                        else:\n",
    "                            proxy_i = 'caco3'\n",
    "                        Ye = DeepDA_psm.cal_ye_cgenie(yml_dict,sites_eval,j,Xb_full_field0,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                        xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(Ye)\n",
    "\n",
    "                        #print('Prior Ye is {:.6f}'.format(np.mean(Ye)))\n",
    "\n",
    "                        for reconi in range(recon_period_len):\n",
    "\n",
    "                            Xa_reconi = np.copy(Xa_full_field0[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "\n",
    "                            Ye = DeepDA_psm.cal_ye_cgenie(yml_dict,sites_eval,j,Xa_reconi,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                            #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j]   = np.mean(Ye)\n",
    "                            #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi+1][j] = np.var(Ye)\n",
    "                            xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(Ye)\n",
    "                            #print('Analysis Ye is {:.6f}'.format(np.mean(Ye)))\n",
    "                            #ob_stat[j][reconi*2]   = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                            ob_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j] = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                            # error\n",
    "                            if ~np.isnan(sites_eval[data_period_id[reconi]][j]):\n",
    "\n",
    "                                if proxy_psm_type[key0] in ['bayesreg_tex86']:\n",
    "\n",
    "                                    if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_tex86(31) + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                    else:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_tex86(31)\n",
    "\n",
    "                                if proxy_psm_type[key0] in ['cgenie_caco3','cgenie_caco3_13c']:\n",
    "\n",
    "                                    psm_error = yml_dict['psm'][proxy_psm_type[key0]]['psm_error']\n",
    "\n",
    "                                    if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = psm_error + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                    else:\n",
    "                                        ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = psm_error\n",
    "\n",
    "                    elif proxy_psm_type[key0] in ['bayesreg_d18o_pooled']:\n",
    "\n",
    "                        proxy_i = 'd18o'\n",
    "\n",
    "                        Ye = DeepDA_psm.cal_ye_cgenie_d18O(yml_dict,sites_eval,j,Xb_full_field0,Xb_sal,Xb_ph,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                        xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(Ye)\n",
    "\n",
    "                        for reconi in range(recon_period_len):\n",
    "\n",
    "                            Xa_reconi = np.copy(Xa_full_field0[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                            Xa_sal_i  = np.copy(Xa_sal_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                            Xa_ph_i   = np.copy(Xa_ph_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "\n",
    "                            Ye = DeepDA_psm.cal_ye_cgenie_d18O(yml_dict,sites_eval,j,Xa_reconi,Xa_sal_i,Xa_ph_i,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "\n",
    "                            xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(Ye)\n",
    "\n",
    "                            ob_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j] = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                            # error\n",
    "                            if ~np.isnan(sites_eval[data_period_id[reconi]][j]):\n",
    "\n",
    "                                if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                    ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_d18o(15) + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                else:\n",
    "                                    ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = DeepDA_psm.obs_estimate_r_fixed_d18o(15)\n",
    "\n",
    "                    elif proxy_psm_type[key0] in ['bayesreg_mgca_pooled_bcp', 'bayesreg_mgca_pooled_red']:\n",
    "                        proxy_i = 'mgca'\n",
    "                        spp = 'all'\n",
    "                        cleaningr = np.tile(np.array([1]),nens)\n",
    "                        cleaningb = np.tile(np.array([0]),nens)\n",
    "\n",
    "                        if proxy_psm_type[key0] in ['bayesreg_mgca_pooled_red']:\n",
    "                            clearning_one = cleaningr\n",
    "                            proxy_explain = 'reductive'\n",
    "\n",
    "                        elif proxy_psm_type[key0] in ['bayesreg_mgca_pooled_bcp']:\n",
    "                            clearning_one = cleaningb\n",
    "                            proxy_explain = 'barker'\n",
    "\n",
    "                        Ye = DeepDA_psm.cal_ye_cgenie_mgca(yml_dict,sites_eval,j,Xb_full_field0,proxy_psm_type[key0],dum_lon_offset,dum_imax,dum_jmax,Xb_sal,Xb_ph,Xb_omega,geologic_age)\n",
    "\n",
    "                        if psm_baymag_ln in ['yes']:\n",
    "                            xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(np.exp(Ye))\n",
    "                        else:\n",
    "                            xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,j] = np.copy(Ye)\n",
    "\n",
    "                        #Xa_sal_full = Dataset(nc_filename).variables['ocn_sur_sal_Xa_full']\n",
    "                        #Xa_ph_full  = Dataset(nc_filename).variables['misc_pH_Xa_full']\n",
    "                        #Xa_omega_full = Dataset(nc_filename).variables['carb_sur_ohm_cal_Xa_full']\n",
    "\n",
    "                        for reconi in range(recon_period_len):\n",
    "\n",
    "                            Xa_reconi  =   Xa_full_field0[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens))\n",
    "                            Xa_sal_i   =   np.copy(Xa_sal_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                            Xa_ph_i    =   np.copy(Xa_ph_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "                            Xa_omega_i =   np.copy(Xa_omega_full[:,:,:,0,reconi].reshape((dum_imax*dum_jmax,nens)))\n",
    "\n",
    "                            Ye = DeepDA_psm.cal_ye_cgenie_mgca(yml_dict,sites_eval,j,Xa_reconi,proxy_psm_type[key0],dum_lon_offset,dum_imax,dum_jmax,Xa_sal_i,Xa_ph_i,Xa_omega_i,geologic_age)\n",
    "\n",
    "                            if psm_baymag_ln in ['yes']:\n",
    "                                xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(np.exp(Ye))\n",
    "                            else:\n",
    "                                xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,reconi,j]   = np.copy(Ye)\n",
    "\n",
    "                            #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j]   = np.mean(Ye)\n",
    "                            #xa_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi+1][j] = np.var(Ye)\n",
    "\n",
    "                            ob_stat[locRadi][proxy_fraci][Rscalei][MCi][2*reconi][j] = sites_eval[data_period_id[reconi]][j]\n",
    "\n",
    "                            if ~np.isnan(sites_eval[data_period_id[reconi]][j]):\n",
    "                                ob_err0 = DeepDA_psm.obs_estimate_r_fixed_mgca_pooled((15, 16), clearning_one[0], np.nanmean(Xb_sal), np.nanmean(Xb_ph), np.nanmean(Xb_omega), spp, geologic_age)\n",
    "                                if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                    ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = ob_err0 + sites_eval[data_period_idstd[reconi]][j] ** 2\n",
    "                                else:\n",
    "                                    ob_stat[locRadi][proxy_fraci][Rscalei][MCi][reconi*2+1][j] = ob_err0\n",
    "\n",
    "                    # save proxy, prior, and posterior data and then standardized\n",
    "\n",
    "                    # info\n",
    "                    df_i = pandas.DataFrame({'site':sites_eval['Site'][j],'proxy':proxy_i,'locRad':locRadv,'proxy_frac':proxy_frac,'Rscale':Rscale,'MC':MCi}, index=[df_ind])\n",
    "                    df_eval = pandas.concat([df_eval,df_i])\n",
    "\n",
    "                    df_ind += 1\n",
    "\n",
    "                # obs\n",
    "                ob_data = np.swapaxes(ob_stat[locRadi,proxy_fraci,Rscalei,MCi,:,:],0,1)\n",
    "                df_obi = pandas.DataFrame(data=ob_data,columns=df_ind_recon)\n",
    "                df_ob = pandas.concat([df_ob,df_obi])\n",
    "\n",
    "                #xb_std = np.copy(xb_stat[locRadi][proxy_fraci][Rscalei][MCi][:][:])\n",
    "                #ob_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, recon_period_len*2, sites_withhold_len), np.nan)\n",
    "                #xb_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, sites_withhold_len), np.nan)   # save full prior for withhold data\n",
    "                #xa_stat = np.full((locRadn,proxy_fracn,Rscalen,MCn, nens, recon_period_len, sites_withhold_len), np.nan)\n",
    "\n",
    "                # xb\n",
    "                xb_data = np.swapaxes(xb_stat[locRadi,proxy_fraci,Rscalei,MCi,:,:],0,1)  # withhold x nens\n",
    "                df_xb_i  = pandas.DataFrame(data=xb_data)\n",
    "                df_xb = pandas.concat([df_xb,df_xb_i])\n",
    "\n",
    "                # xa\n",
    "                xa_data = np.swapaxes(xa_stat[locRadi,proxy_fraci,Rscalei,MCi,:,:,:],0,2)  # withhold x recon x nens\n",
    "                xa_data1 = xa_data.reshape((sites_withhold_len, recon_period_len*nens))\n",
    "                df_xa_i  = pandas.DataFrame(data=xa_data1)\n",
    "                df_xa = pandas.concat([df_xa,df_xa_i])\n",
    "\n",
    "            df_ob = df_ob.reset_index()\n",
    "            df_ob = df_ob.drop(columns='index')\n",
    "            df_xb = df_xb.reset_index()\n",
    "            df_xb = df_xb.drop(columns='index')\n",
    "            df_xa = df_xa.reset_index()\n",
    "            df_xa = df_xa.drop(columns='index')\n",
    "            print('')\n",
    "            print('Step #3: evaluation data preparation - Done')\n",
    "            print('')\n",
    "            if log_level > 3:\n",
    "                print('df_eval')\n",
    "                print(df_eval)\n",
    "                print('df_ob')\n",
    "                print(df_ob)\n",
    "                print('df_xb')\n",
    "                print(df_xb)\n",
    "\n",
    "        ###############################################################\n",
    "        # calculate RMSE, CE, R^2 for each time slice\n",
    "        ###############################################################\n",
    "        ###############################################################\n",
    "\n",
    "\n",
    "            df_reconi = pandas.DataFrame()\n",
    "\n",
    "            df_ind_i = 0\n",
    "            df_zscore_mc   = pandas.DataFrame()\n",
    "\n",
    "            for reconi in range(recon_period_len):\n",
    "                df_zscore   = pandas.DataFrame()\n",
    "                data_period_id_i = data_period_id[reconi]\n",
    "                if log_level > 1:\n",
    "                    print('>>>>>>>  ')\n",
    "                    print('')\n",
    "                    print(data_period_id_i)\n",
    "                    print('')\n",
    "\n",
    "                for proxy_j in range(pn):\n",
    "                    df_zscore_j = pandas.DataFrame()\n",
    "\n",
    "                    proxy_i = Typelist[proxy_j]\n",
    "                    print('proxy i {}'.format(proxy_i))\n",
    "\n",
    "                    df_eval_pi = df_eval[df_eval['proxy'] == proxy_i]\n",
    "                    \n",
    "                    # debug\n",
    "                    if pn > 1:\n",
    "                        df_ob_pi   = df_ob[df_eval['proxy'] == proxy_i]\n",
    "                        df_xb_pi   = df_xb[df_eval['proxy'] == proxy_i]\n",
    "                        df_xa_pi   = df_xa[df_eval['proxy'] == proxy_i]\n",
    "                    else:\n",
    "                        df_ob_pi   = df_ob \n",
    "                        df_xb_pi   = df_xb\n",
    "                        df_xa_pi   = df_xa\n",
    "                    # debug end\n",
    "                    \n",
    "                    # show 1 data\n",
    "                    df_ob_pi_all = df_ob_pi[data_period_id_i]\n",
    "\n",
    "                    df_xb_pi_all = df_xb_pi.mean(axis=1)\n",
    "                    \n",
    "                    df_xa_pi_all = df_xa_pi.mean(axis=1)\n",
    "\n",
    "                    #df_xb_pi_all = df_xb_pi.mask(df_xb_pi.eq(np.nan)).mean(axis=1)\n",
    "                    #df_xa_pi_all = df_xa_pi.mask(df_xa_pi.eq(np.nan)).mean(axis=1)\n",
    "                    \n",
    "                    if log_level > 3:\n",
    "                        print('df_eval_pi')\n",
    "                        print(df_eval_pi)\n",
    "                        print('df_ob_pi')\n",
    "                        print(df_ob_pi)\n",
    "                        print('df_xb_pi')\n",
    "                        print(df_xb_pi)\n",
    "                        print('df_xa_pi')\n",
    "                        print(df_xa_pi)\n",
    "                        print('df_xb_pi_all')\n",
    "                        print(df_xb_pi_all)\n",
    "                        print('df_xa_pi_all')\n",
    "                        print(df_xa_pi_all)\n",
    "\n",
    "                    if showplot:\n",
    "                        fig = plt.figure()\n",
    "                        plt.rcParams.update({'figure.figsize':(8,3), 'figure.dpi':150})\n",
    "\n",
    "                        plt.subplot(1,2,1)\n",
    "                        kwargs = dict(alpha=0.5, marker='o', markersize=8, linestyle='',label = 'xb')    \n",
    "                        plt.plot(df_ob_pi_all,df_xb_pi_all, **kwargs)    \n",
    "                        plt.gca().set(ylabel='xb', xlabel = 'obs', title = proxy_i, xlim = axis_lim[proxy_j,:], ylim = axis_lim[proxy_j,:])\n",
    "\n",
    "                        plt.subplot(1,2,2)\n",
    "                        kwargs = dict(alpha=0.5, marker='o', markersize=8, linestyle='',label = 'xa')    \n",
    "                        plt.plot(df_ob_pi_all,df_xa_pi_all, **kwargs)    \n",
    "                        plt.gca().set(ylabel='xa', xlabel = 'obs', title = proxy_i, xlim = axis_lim[proxy_j,:], ylim = axis_lim[proxy_j,:])\n",
    "\n",
    "                    #df_ob_pi_mean = df_ob_pi[data_period_id_i].mean()\n",
    "                    #df_ob_pi_std  = df_ob_pi[data_period_id_i].std()\n",
    "                    df_ob_pi_mean = pandas.Series.mean(df_ob_pi[data_period_id_i])\n",
    "                    df_ob_pi_std  = pandas.Series.std(df_ob_pi[data_period_id_i])\n",
    "                    \n",
    "                    if log_level > 3:\n",
    "                        print('df_ob_pi_mean')\n",
    "                        print(df_ob_pi_mean)\n",
    "                        print('df_ob_pi_std')\n",
    "                        print(df_ob_pi_std)\n",
    "\n",
    "                    df_ob_pi_zscore = (df_ob_pi[data_period_id_i] - df_ob_pi_mean) / df_ob_pi_std\n",
    "                    df_xb_pi_zscore = (df_xb_pi_all - df_ob_pi_mean) / df_ob_pi_std\n",
    "                    df_xa_pi_zscore = (df_xa_pi_all - df_ob_pi_mean) / df_ob_pi_std\n",
    "                    \n",
    "                    if log_level > 3:\n",
    "                        print('df_ob_pi_zscore')\n",
    "                        print(df_ob_pi_zscore)\n",
    "                        print('df_xb_pi_zscore')\n",
    "                        print(df_xb_pi_zscore)\n",
    "                        print('df_xa_pi_zscore')\n",
    "                        print(df_xa_pi_zscore)\n",
    "\n",
    "\n",
    "                    for MCii in range(MCn): df_zscore_j.loc[MCii, ['proxy']] = proxy_i\n",
    "                    for MCii in range(MCn): df_zscore_j.loc[MCii, ['reconi']] = data_period_id_i\n",
    "                    for MCii in range(MCn): df_zscore_j.loc[MCii, ['loc']] = locRadi\n",
    "                    for MCii in range(MCn): df_zscore_j.loc[MCii, ['proxy_frac']] = proxy_fraci\n",
    "                    for MCii in range(MCn): df_zscore_j.loc[MCii, ['Rscale']] = Rscale\n",
    "\n",
    "                    df_zscore_j['xb'] = df_xb_pi_all\n",
    "                    df_zscore_j['ob'] = df_ob_pi_all\n",
    "                    df_zscore_j['xa'] = df_xa_pi_all\n",
    "\n",
    "                    df_zscore_j['xb_zscore'] = df_xb_pi_zscore\n",
    "                    df_zscore_j['ob_zscore'] = df_ob_pi_zscore\n",
    "                    df_zscore_j['xa_zscore'] = df_xa_pi_zscore\n",
    "\n",
    "                    df_zscore = pandas.concat([df_zscore,df_zscore_j])\n",
    "\n",
    "                    if log_level > 2:\n",
    "                        print('df_ob_pi_mean {} {}'.format(proxy_i, df_ob_pi_mean))\n",
    "                        print('df_ob_pi_std  {} {}'.format(proxy_i, df_ob_pi_std))\n",
    "                        print('')\n",
    "                        if log_level > 3:\n",
    "                            print(df_eval_pi)\n",
    "                            print(df_ob_pi)\n",
    "                            print(df_xb_pi[:][0:6])\n",
    "                            print(df_xa_pi)\n",
    "\n",
    "                    if showplot:\n",
    "                        fig = plt.figure()\n",
    "                        plt.rcParams.update({'figure.figsize':(8,3), 'figure.dpi':150})\n",
    "\n",
    "                        plt.subplot(1,2,1)\n",
    "                        kwargs = dict(alpha=0.5, marker='o', markersize=8, linestyle='',label = 'xb')    \n",
    "                        plt.plot(df_ob_pi_zscore,df_xb_pi_zscore, **kwargs)    \n",
    "                        plt.gca().set(ylabel='xb zscore', xlabel = 'obs zscore', title = proxy_i, xlim = axis_limz, ylim = axis_limz)\n",
    "\n",
    "                        plt.subplot(1,2,2)\n",
    "                        kwargs = dict(alpha=0.5, marker='o', markersize=8, linestyle='',label = 'xa')\n",
    "                        plt.plot(df_ob_pi_zscore,df_xa_pi_zscore, **kwargs)    \n",
    "                        plt.gca().set(ylabel='xa zscore', xlabel = 'obs zscore', title = proxy_i, xlim = axis_limz, ylim = axis_limz)\n",
    "\n",
    "                if log_level > 3:\n",
    "                    print(' ')\n",
    "                    print('df_zscore:')\n",
    "                    print(df_zscore)\n",
    "\n",
    "\n",
    "                if showplot:\n",
    "                    fig = plt.figure()\n",
    "                    plt.rcParams.update({'figure.figsize':(8,3), 'figure.dpi':150})\n",
    "\n",
    "                    plt.subplot(1,2,1)\n",
    "                    kwargs = dict(alpha=0.5, marker='o', markersize=8, linestyle='',label = 'xb_zscore')\n",
    "                    plt.plot(df_zscore['ob_zscore'],df_zscore['xb_zscore'], **kwargs)    \n",
    "                    plt.gca().set(ylabel='xb zscore', xlabel = 'obs zscore', title = proxy_i, xlim = axis_limz, ylim = axis_limz)\n",
    "\n",
    "                rmse_xb = DeepDA_psm.rmse(df_zscore['ob_zscore'],df_zscore['xb_zscore'])\n",
    "\n",
    "                if log_level > 1:\n",
    "                    print('RMSE of Ob vs. Xb {}'.format(rmse_xb))\n",
    "\n",
    "                CE_xb = DeepDA_psm.CE_NS70(df_zscore['ob_zscore'],df_zscore['xb_zscore'],1)\n",
    "                if log_level > 1:\n",
    "                    print('CE of Ob vs. Xb {}'.format(CE_xb))\n",
    "\n",
    "                a=ma.masked_invalid(df_zscore['ob_zscore'])\n",
    "                b=ma.masked_invalid(df_zscore['xb_zscore'])\n",
    "                msk = (~a.mask & ~b.mask)\n",
    "                cor_matrix = ma.corrcoef(a[msk],b[msk])\n",
    "                r_2_xb = cor_matrix[0,1]**2\n",
    "\n",
    "                if log_level > 1:\n",
    "                    print('r^2 of Ob vs. Xb {}'.format(r_2_xb))\n",
    "                    print('')\n",
    "\n",
    "                if showplot:\n",
    "                    plt.subplot(1,2,2)\n",
    "                    kwargs = dict(alpha=0.5, marker='o', markersize=8, linestyle='',label = 'xa_zscore')\n",
    "                    plt.plot(df_zscore['ob_zscore'],df_zscore['xa_zscore'], **kwargs)\n",
    "                    plt.gca().set(ylabel='xa zscore', xlabel = 'obs zscore', title = proxy_i, xlim = axis_limz, ylim = axis_limz)\n",
    "\n",
    "                rmse_xa = DeepDA_psm.rmse(df_zscore['ob_zscore'],df_zscore['xa_zscore'])\n",
    "\n",
    "                if log_level > 1:\n",
    "                    print('RMSE of Ob vs. Xa {}'.format(rmse_xa))\n",
    "\n",
    "                CE_xa = DeepDA_psm.CE_NS70(df_zscore['ob_zscore'],df_zscore['xa_zscore'],1)\n",
    "\n",
    "                if log_level > 1:\n",
    "                    print('CE of Ob vs. Xb {}'.format(CE_xa))\n",
    "\n",
    "                a=ma.masked_invalid(df_zscore['ob_zscore'])\n",
    "                b=ma.masked_invalid(df_zscore['xa_zscore'])\n",
    "                msk = (~a.mask & ~b.mask)\n",
    "                cor_matrix = ma.corrcoef(a[msk],b[msk])\n",
    "                r_2_xa = cor_matrix[0,1]**2\n",
    "\n",
    "                if log_level > 1:\n",
    "                    print('r^2 of Ob vs. Xa {}'.format(r_2_xa))\n",
    "                    print(' --- ')\n",
    "                    print('')\n",
    "                # delta RMSE, CE, and R^2\n",
    "                drmse = 100 * (rmse_xb - rmse_xa)/rmse_xb\n",
    "                dce   = 100 * (CE_xb - CE_xa)/CE_xb\n",
    "                dr2   = 100 * (r_2_xb - r_2_xa)/r_2_xb\n",
    "\n",
    "                df_reconi = pandas.DataFrame({'reconi':reconi,\n",
    "                                              'data_period_id_i':data_period_id_i,\n",
    "                                              'loc':locRadv,\n",
    "                                              'proxy_frac':proxy_frac,\n",
    "                                              'Rscale':Rscale,\n",
    "                                              'RMSE Xb':rmse_xb,\n",
    "                                              'RMSE Xa':rmse_xa,\n",
    "                                              'dRMSE':drmse,\n",
    "                                              'CE Xb':CE_xb,\n",
    "                                              'CE Xa': CE_xa,\n",
    "                                              'dCE':dce,\n",
    "                                              'R^2 Xb':r_2_xb,\n",
    "                                              'R^2 Xa': r_2_xa,\n",
    "                                              'dR^2':dr2}, index=[df_ind_i])\n",
    "\n",
    "                df_evaluation = pandas.concat([df_evaluation,df_reconi])\n",
    "\n",
    "                df_ind_i += 1\n",
    "\n",
    "                df_zscore_mc = pandas.concat([df_zscore_mc,df_zscore])\n",
    "\n",
    "            # all slice zscore\n",
    "\n",
    "            df_ob_slice_mean   = pandas.Series.mean(df_zscore_mc['ob'])\n",
    "            df_ob_slice_std    = pandas.Series.std(df_zscore_mc['ob'])\n",
    "            df_ob_slice_zscore = (df_zscore_mc['ob'] - df_ob_slice_mean) / df_ob_slice_std\n",
    "            df_xb_slice_zscore = (df_zscore_mc['xb'] - df_ob_slice_mean) / df_ob_slice_std\n",
    "            df_xa_slice_zscore = (df_zscore_mc['xa'] - df_ob_slice_mean) / df_ob_slice_std\n",
    "\n",
    "            rmse_slice_xb = DeepDA_psm.rmse(df_ob_slice_zscore,df_xb_slice_zscore)\n",
    "            CE_slice_xb = DeepDA_psm.CE_NS70(df_ob_slice_zscore,df_xb_slice_zscore,1)\n",
    "            rmse_slice_xa = DeepDA_psm.rmse(df_ob_slice_zscore,df_xa_slice_zscore)\n",
    "            CE_slice_xa = DeepDA_psm.CE_NS70(df_ob_slice_zscore,df_xa_slice_zscore,1)\n",
    "\n",
    "            drmse_slice = 100 * (rmse_slice_xb - rmse_slice_xa)/rmse_slice_xb\n",
    "            dce_slice   = 100 * (CE_slice_xb - CE_slice_xa)/CE_slice_xb\n",
    "\n",
    "            df_reconi = pandas.DataFrame({'reconi':reconi,\n",
    "                                          'data_period_id_i':'all',\n",
    "                                          'loc':locRadv,\n",
    "                                          'proxy_frac':proxy_frac,\n",
    "                                          'Rscale':Rscale,\n",
    "                                          'RMSE Xb':rmse_slice_xb,\n",
    "                                          'RMSE Xa':rmse_slice_xa,\n",
    "                                          'dRMSE':drmse_slice,\n",
    "                                          'CE Xb':CE_slice_xb,\n",
    "                                          'CE Xa': CE_slice_xa,\n",
    "                                          'dCE':dce_slice,\n",
    "                                          'R^2 Xb':'',\n",
    "                                          'R^2 Xa': '',\n",
    "                                          'dR^2':''}, index=[df_ind_i])\n",
    "\n",
    "            df_evaluation = pandas.concat([df_evaluation,df_reconi])\n",
    "\n",
    "\n",
    "            # all df_sscore\n",
    "            #df_zscore_all = pandas.concat([df_zscore_all,df_zscore])\n",
    "            df_zscore_all = pandas.concat([df_zscore_all,df_zscore_mc])\n",
    "            print(' This loop done ')\n",
    "\n",
    "if savesummary:\n",
    "    df_zscore_all.to_csv(yml_dict['core']['proj_dir']+'/wrk/'+en+savefilename_add+'_df_zscore_all'+'.csv')\n",
    "    df_evaluation.sort_index().to_csv(yml_dict['core']['proj_dir']+'/wrk/'+en+'_df_evaluation_log.csv')\n",
    "\n",
    "print('')\n",
    "print('Step #4: evaluation - Done')\n",
    "print('')\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.631964 0.632928 0.634026 0.632632]\n"
     ]
    }
   ],
   "source": [
    "prediction = bayspar.predict_tex_analog(np.array([25,25,25,25]), temptype = 'sst', search_tol = 20, nens=1000)\n",
    "Ye = np.mean(prediction.ensemble, axis = 1)\n",
    "print(Ye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.255616631875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(pandas.Series.mean(df_zscore_mc['ob']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "  proxy       reconi  loc  proxy_frac  Rscale        xb        ob        xa\n",
      "0  d18O  prePETMmean  0.0         0.0     2.0 -5.132015 -3.773568 -4.446489\n",
      "1  d18O  prePETMmean  0.0         0.0     2.0 -5.131957 -3.397277 -4.456344\n",
      "2  d18O  prePETMmean  0.0         0.0     2.0 -2.954112       NaN -2.249525\n",
      "3  d18O  prePETMmean  0.0         0.0     2.0 -3.609945 -2.345740 -2.901556\n",
      "4  d18O  prePETMmean  0.0         0.0     2.0 -3.803660       NaN -3.100056\n",
      "5  d18O  prePETMmean  0.0         0.0     2.0 -3.609365 -2.500314 -2.901647\n",
      "0   -5.132015\n",
      "1   -5.131957\n",
      "2   -2.954112\n",
      "3   -3.609945\n",
      "4   -3.803660\n",
      "5   -3.609365\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_zscore_j = pandas.DataFrame()\n",
    "                        \n",
    "print(MCn)\n",
    "for MCii in range(MCn): df_zscore_j.loc[MCii, ['proxy']] = proxy_i\n",
    "for MCii in range(MCn): df_zscore_j.loc[MCii, ['reconi']] = data_period_id_i\n",
    "for MCii in range(MCn): df_zscore_j.loc[MCii, ['loc']] = locRadi\n",
    "for MCii in range(MCn): df_zscore_j.loc[MCii, ['proxy_frac']] = proxy_fraci\n",
    "for MCii in range(MCn): df_zscore_j.loc[MCii, ['Rscale']] = Rscale\n",
    "\n",
    "df_zscore_j['xb'] = df_xb_pi_all\n",
    "df_zscore_j['ob'] = df_ob_pi_all\n",
    "df_zscore_j['xa'] = df_xa_pi_all\n",
    "\n",
    "print(df_zscore_j)\n",
    "print(df_xb_pi_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  B   C   D\n",
      "0      0  1   2   3\n",
      "1      4  5   6   7\n",
      "2      8  9  10  11\n"
     ]
    }
   ],
   "source": [
    "dfdf = pandas.DataFrame(np.arange(12).reshape(3, 4),\n",
    "                  columns=['index', 'B', 'C', 'D'])\n",
    "print(dfdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   B   C   D\n",
      "0  1   2   3\n",
      "1  5   6   7\n",
      "2  9  10  11\n"
     ]
    }
   ],
   "source": [
    "dfdf = dfdf.drop(columns='index')\n",
    "print(dfdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
