{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No module named 'bayspline'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/Users/mingsongli/miniconda3/envs/deepda/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No module named 'bayspline'\n",
      ">>  Import packages...  => Okay\n",
      "\n",
      " ########## Load yml config file ########## \n",
      "\n",
      "Set limit for ['sed_CaCO3', 'atm_pCO2']\n",
      ">>  Load dataset for plot => Okay\n",
      ">>  Prior member size: 100\n",
      ">>  Recon_period 1 - 1. \n",
      "      List: [1]\n",
      ">>  Proxy error evaluation: proxy_err_psm_fixed\n",
      ">>  Proxy full list:\n",
      "      ['Marine sediments_uk37', 'Marine sediments_d18o_pooled', 'Marine sediments_tex86', 'Marine sediments_mgca_pooled_bcp', 'Marine sediments_mgca_pooled_red', 'Marine sediments_caco3']\n",
      ">>  Proxy blacklist:\n",
      "      []\n",
      ">>  Proxy may be assimilated (some may not exist)\n",
      "      ['Marine sediments_uk37', 'Marine sediments_d18o_pooled', 'Marine sediments_tex86', 'Marine sediments_mgca_pooled_bcp', 'Marine sediments_mgca_pooled_red', 'Marine sediments_caco3']\n",
      ">>  Proxy quality control selection: None\n",
      ">>    Mg/Ca proxy found \n",
      "\n",
      "########## Read prior ######### \n",
      "\n",
      ">>  Number of 2d prior variables is: 7.\n",
      "      List:\n",
      "        biogem/fields_biogem_2d.nc/ocn_sur_temp\n",
      "        biogem/fields_biogem_2d.nc/atm_temp\n",
      "        biogem/fields_biogem_2d.nc/atm_pCO2\n",
      "        biogem/fields_biogem_2d.nc/ocn_sur_sal\n",
      "        biogem/fields_biogem_2d.nc/misc_pH\n",
      "        biogem/fields_biogem_2d.nc/carb_sur_ohm_cal\n",
      "        sedgem/fields_sedgem_2d.nc/sed_CaCO3\n",
      ">>  Number of 3d prior variables is: 0\n",
      ">>  Reading prior state variables\n",
      ">>  Shape of dum_dmax 16, dum_imax 36, dum_jmax 36, dum_ijmax 1296\n",
      ">>  Reading prior ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingsongli/miniconda3/envs/deepda/lib/python3.6/site-packages/ipykernel_launcher.py:329: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Last member: 99: ML.petm018.ID.89: ocn_sur_temp\n",
      "    Last member: 99: ML.petm018.ID.89: atm_temp\n",
      "    Last member: 99: ML.petm018.ID.89: atm_pCO2\n",
      "    Last member: 99: ML.petm018.ID.89: ocn_sur_sal\n",
      "    Last member: 99: ML.petm018.ID.89: misc_pH\n",
      "    Last member: 99: ML.petm018.ID.89: carb_sur_ohm_cal\n",
      "    Last member: 99: ML.petm018.ID.89: sed_CaCO3\n",
      ">>  Units of state variables ['ocn_sur_temp', 'atm_temp', 'atm_pCO2', 'ocn_sur_sal', 'misc_pH', 'carb_sur_ohm_cal', 'sed_CaCO3']: ['unit', 'degrees C', 'atm', 'unit', 'pH units (SWS)', 'unit', 'wt%']\n",
      ">>  Prepare Mg/Ca related state variable ...\n",
      ">>  Reading Prior => Okay\n",
      "\n",
      " ########## Read proxies database ########## \n",
      "\n",
      ">>  Proxy: selected proxy dataset number 121: remove those in blacklist\n",
      ">>  Proxy: selected proxy dataset number 106: remove those unknown/frosty\n",
      ">>  Localization id 0 radius distance None km\n",
      ">>  Starting Monte Carlo ... \n",
      ">>  Proxy fraction is 0.7\n",
      "Setting current prior iteration seed: 0\n",
      ">>  Selected index: [49, 97, 53, 5, 33, 65, 62, 51, 38, 61, 45, 74, 27, 64, 17, 36, 91, 12, 79, 32, 68, 77, 18, 39, 88, 9, 42, 60, 71, 81, 95, 55, 40, 26, 70, 96, 56, 66, 101, 7, 1, 11, 98, 75, 52, 50, 87, 73, 0, 82, 31, 84, 21, 15, 46, 20, 99, 4, 76, 90, 14, 54, 80, 34, 28, 102, 58, 78, 86, 94, 6, 19, 83, 85]\n",
      ">>  Unselected index: [2, 3, 8, 10, 13, 16, 22, 23, 24, 25, 29, 30, 35, 37, 41, 43, 44, 47, 48, 57, 59, 63, 67, 69, 72, 89, 92, 93, 100, 103, 104, 105]\n",
      ">>  Proxy order: all random.\n",
      ">>  Selected proxy data length 74\n",
      ">>  OKAY.\n",
      "\n",
      "########## Check the consistency of the config.yml file and proxy database ##########\n",
      "\n",
      "\n",
      ">>  All looks good.\n",
      "\n",
      "##########  Ye calculation  ##########\n",
      "\n",
      ">>  0. File: SSP (1995), grid [lon lat] [4, 21], index 8536, PSM for caco3 is cgenie_caco3\n",
      ">>  1. File: aze2014-tanzaniad18omorozovella.txt, grid [lon lat] [20, 13], index 488, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  2. File: tripati2003-865mgcamorozovella.txt, grid [lon lat] [4, 21], index 760, PSM for mgca_m.subbotinae:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  3. File: Babila 2016, grid [lon lat] [12, 29], index 1056, PSM for mgca_morozovella:reductive is bayesreg_mgca_pooled_red\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 1\n",
      ">>  4. File: SSP (2000), grid [lon lat] [24, 3], index 7908, PSM for caco3 is cgenie_caco3\n",
      ">>  5. File: Hollis et al., 2015, grid [lon lat] [0, 3], index 7884, PSM for caco3 is cgenie_caco3\n",
      ">>  6. File: zachos2006-wilsonlakepetmd18o.txt, grid [lon lat] [12, 28], index 1020, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  7. File: Babila 2016, grid [lon lat] [12, 29], index 1056, PSM for mgca_acarinina:reductive is bayesreg_mgca_pooled_red\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 1\n",
      ">>  8. File: john2008-tumeygulchd18o.txt, grid [lon lat] [6, 30], index 1086, PSM for d18o_m.velascoensis is bayesreg_d18o_pooled\n",
      ">>  9. File: Hines et al. 2017, grid [lon lat] [0, 3], index 108, PSM for mgca_morozovella:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  10. File: Bralower et al. (1997), grid [lon lat] [9, 21], index 8541, PSM for caco3 is cgenie_caco3\n",
      ">>  11. File: Thomas & Bralower (2005), grid [lon lat] [15, 29], index 8835, PSM for caco3 is cgenie_caco3\n",
      ">>  12. File: Penman et al. 2014; Harper et al. 2020, grid [lon lat] [2, 26], index 938, PSM for mgca_morozovella:reductive is bayesreg_mgca_pooled_red\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 1\n",
      ">>  13. File: zachos2006-wilsonlakepetmd18o.txt, grid [lon lat] [12, 28], index 1020, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  14. File: Thomas et al. (1999), grid [lon lat] [17, 1], index 7829, PSM for caco3 is cgenie_caco3\n",
      ">>  15. File: Zachos et al. (2005), grid [lon lat] [16, 7], index 8044, PSM for caco3 is cgenie_caco3\n",
      ">>  16. File: john2008-lodod18o.txt, grid [lon lat] [6, 30], index 1086, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  17. File: Colosimo et al. (2006), grid [lon lat] [2, 26], index 8714, PSM for caco3 is cgenie_caco3\n",
      ">>  18. File: john2008-bassriverd18o.txt, grid [lon lat] [12, 29], index 1056, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  19. File: Hines et al. 2017, grid [lon lat] [0, 3], index 108, PSM for mgca_acarinina:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  20. File: gutjahr2017-dsdp401d18omgca.txt, grid [lon lat] [16, 29], index 1060, PSM for d18o_m.subb is bayesreg_d18o_pooled\n",
      ">>  21. File: tripati2005-527mgcam.subb.txt, grid [lon lat] [16, 7], index 268, PSM for mgca_m.subb:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  22. File: tripati2004-865mgcaasoldadoensis.txt, grid [lon lat] [4, 21], index 760, PSM for mgca_acarinina:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  23. File: Bralower et al. (1997), grid [lon lat] [11, 22], index 8579, PSM for caco3 is cgenie_caco3\n",
      ">>  24. File: Rudnicki et al. (2001), grid [lon lat] [11, 27], index 8759, PSM for caco3 is cgenie_caco3\n",
      ">>  25. File: Frieling et al. (2018), grid [lon lat] [17, 14], index 8297, PSM for caco3 is cgenie_caco3\n",
      ">>  26. File: thomas1996-690d18ofora.txt, grid [lon lat] [17, 1], index 53, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  27. File: john2008-bassriverd18o.txt, grid [lon lat] [12, 29], index 1056, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  28. File: Si et al. 2018, grid [lon lat] [18, 1], index 54, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  29. File: Si et al. 2018, grid [lon lat] [12, 28], index 1020, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  30. File: Rudnicki et al. (2001), grid [lon lat] [11, 27], index 8759, PSM for caco3 is cgenie_caco3\n",
      ">>  31. File: Si et al. 2018, grid [lon lat] [12, 29], index 1056, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  32. File: Mutterlose et al. (2007), grid [lon lat] [13, 18], index 8437, PSM for caco3 is cgenie_caco3\n",
      ">>  33. File: Bralower et al. (2002),Quillévéré et al. (2002), grid [lon lat] [2, 26], index 8714, PSM for caco3 is cgenie_caco3\n",
      ">>  34. File: frieling2017-sqofnigeria.txt, grid [lon lat] [17, 14], index 521, PSM for mgca_morozovella:reductive is bayesreg_mgca_pooled_red\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 1\n",
      ">>  35. File: frieling2017-sqofnigeria.txt, grid [lon lat] [17, 14], index 521, PSM for mgca_acarinina:reductive is bayesreg_mgca_pooled_red\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 1\n",
      ">>  36. File: Zachos et al. (2005), grid [lon lat] [16, 7], index 8044, PSM for caco3 is cgenie_caco3\n",
      ">>  37. File: Si et al. 2018, grid [lon lat] [12, 29], index 1056, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  38. File: tripati2004-865mgcamorozovella.txt, grid [lon lat] [4, 21], index 760, PSM for mgca_morozovella:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  39. File: Sluijs et al. (2011), grid [lon lat] [32, 1], index 7844, PSM for caco3 is cgenie_caco3\n",
      ">>  40. File: Penman et al., 2016, grid [lon lat] [14, 29], index 8834, PSM for caco3 is cgenie_caco3\n",
      ">>  41. File: Stokke2020-TEX-Fur, grid [lon lat] [14, 32], index 1166, PSM for tex86 is bayesreg_tex86\n",
      ">>  42. File: Zachos et al. (2005), grid [lon lat] [16, 6], index 8008, PSM for caco3 is cgenie_caco3\n",
      ">>  43. File: schoon2013-fursectionnorthsea.txt, grid [lon lat] [14, 32], index 1166, PSM for tex86 is bayesreg_tex86\n",
      ">>  44. File: zachos2006-wilsonlake.txt, grid [lon lat] [12, 28], index 1020, PSM for tex86 is bayesreg_tex86\n",
      ">>  45. File: Aze et al. (2014), grid [lon lat] [20, 13], index 8264, PSM for caco3 is cgenie_caco3\n",
      ">>  46. File: kozdon2013-865d18omorozovellasims.txt, grid [lon lat] [4, 21], index 760, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  47. File: Colosimo et al. (2006), grid [lon lat] [2, 26], index 8714, PSM for caco3 is cgenie_caco3\n",
      ">>  48. File: SSP (1988)§, grid [lon lat] [18, 1], index 7830, PSM for caco3 is cgenie_caco3\n",
      ">>  49. File: hollis2012-waiparatex-mgca-d18o.txt, grid [lon lat] [1, 4], index 145, PSM for tex86 is bayesreg_tex86\n",
      ">>  50. File: Babila 2016, grid [lon lat] [12, 29], index 1056, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  51. File: john2008-tumeygulchd18o.txt, grid [lon lat] [6, 30], index 1086, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  52. File: Zachos et al. (2005), grid [lon lat] [16, 7], index 8044, PSM for caco3 is cgenie_caco3\n",
      ">>  53. File: frieling2017-sqofnigeriatex86.txt, grid [lon lat] [17, 14], index 521, PSM for tex86 is bayesreg_tex86\n",
      ">>  54. File: SSP (1990)§, grid [lon lat] [26, 5], index 7982, PSM for caco3 is cgenie_caco3\n",
      ">>  55. File: kozdon2020-690-d18O, grid [lon lat] [17, 1], index 53, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  56. File: Colosimo et al. (2006), grid [lon lat] [2, 26], index 8714, PSM for caco3 is cgenie_caco3\n",
      ">>  57. File: gutjahr2017-dsdp401d18omgca.txt, grid [lon lat] [16, 29], index 1060, PSM for mgca_m.subb:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  58. File: Bornemann et al., 2014, grid [lon lat] [16, 29], index 1060, PSM for mgca_m.subbotinae:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  59. File: SSP (1989)§, grid [lon lat] [25, 2], index 7873, PSM for caco3 is cgenie_caco3\n",
      ">>  60. File: Bornemann et al., 2014, grid [lon lat] [16, 29], index 8836, PSM for caco3 is cgenie_caco3\n",
      ">>  61. File: Si et al. 2018, grid [lon lat] [12, 29], index 1056, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  62. File: Hines et al. 2017, grid [lon lat] [1, 4], index 145, PSM for mgca_acarinina:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  63. File: sluijs2014-harrellcore.txt, grid [lon lat] [10, 27], index 982, PSM for tex86 is bayesreg_tex86\n",
      ">>  64. File: Leon-Rodriguez & Dickens 2010, grid [lon lat] [5, 22], index 8573, PSM for caco3 is cgenie_caco3\n",
      ">>  65. File: zachos2003-1209mgcaa.soldadoensis.txt, grid [lon lat] [2, 26], index 938, PSM for mgca_acarinina:reductive is bayesreg_mgca_pooled_red\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 1\n",
      ">>  66. File: sluijs2006-acex302-4a.txt, grid [lon lat] [20, 35], index 1280, PSM for tex86 is bayesreg_tex86\n",
      ">>  67. File: tripati2003-865mgcamorozovella.txt, grid [lon lat] [4, 21], index 760, PSM for mgca_m.velascoensis:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  68. File: frieling2017-sqofnigeria.txt, grid [lon lat] [17, 14], index 521, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  69. File: frieling2017-sqofnigeria.txt, grid [lon lat] [17, 14], index 521, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  70. File: john2008-lodod18o.txt, grid [lon lat] [6, 30], index 1086, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  71. File: Bornemann et al., 2014, grid [lon lat] [16, 29], index 1060, PSM for d18o_m.subb is bayesreg_d18o_pooled\n",
      ">>  72. File: Penman et al. 2014; Harper et al. 2020, grid [lon lat] [2, 26], index 938, PSM for mgca_acarinina:reductive is bayesreg_mgca_pooled_red\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 1\n",
      ">>  73. File: Zachos et al. (2005), grid [lon lat] [17, 6], index 8009, PSM for caco3 is cgenie_caco3\n",
      "\n",
      ">>  Summary of this Monte Carlo simulation\n",
      "[Ye, Ob_value]\n",
      ">>  [[ 8.61949625e+01  9.25000000e+01]\n",
      " [-5.83627426e+00 -3.75000000e+00]\n",
      " [ 6.47220540e+02             nan]\n",
      " [ 3.58252894e+02  4.49500000e+00]\n",
      " [ 7.37592046e+01             nan]\n",
      " [ 8.71909196e+01  3.46700000e+01]\n",
      " [-4.05604095e+00 -3.93000000e+00]\n",
      " [ 3.58089712e+02  3.31000000e+00]\n",
      " [-3.11303744e+00 -3.16000000e+00]\n",
      " [ 3.54252946e+02  5.84000000e+00]\n",
      " [ 3.23264499e+01  2.55000000e-01]\n",
      " [ 4.80084660e+01  6.82000000e-01]\n",
      " [ 5.17044727e+02  5.42000000e+00]\n",
      " [-4.05735885e+00 -3.94000000e+00]\n",
      " [ 9.22162148e+01  5.95600000e+01]\n",
      " [ 5.22859853e+01  6.88888889e-01]\n",
      " [-3.19234044e+00 -3.02000000e+00]\n",
      " [ 6.51182011e+01  8.40000000e+01]\n",
      " [-3.85615897e+00 -3.57000000e+00]\n",
      " [ 3.54942196e+02  5.85000000e+00]\n",
      " [-4.19637050e+00 -2.57189519e+00]\n",
      " [ 5.39063676e+02  4.56704240e+00]\n",
      " [ 6.46968594e+02  4.69142300e+00]\n",
      " [ 4.73230754e+01  2.63666667e+00]\n",
      " [ 2.97680616e+01  5.70000000e+01]\n",
      " [ 9.02010927e+01  4.56600455e-01]\n",
      " [-1.75852657e+00 -1.67000000e+00]\n",
      " [-3.85522476e+00 -4.24000000e+00]\n",
      " [-2.24107671e+00 -1.83594000e+00]\n",
      " [-4.05661775e+00 -4.76354000e+00]\n",
      " [ 2.97680616e+01  5.20000000e+01]\n",
      " [-3.85695065e+00 -3.54009500e+00]\n",
      " [ 7.88936464e+01  1.00000000e+00]\n",
      " [ 6.51182011e+01             nan]\n",
      " [ 6.89705462e+02             nan]\n",
      " [ 6.92513136e+02             nan]\n",
      " [ 5.22859853e+01  1.30000000e+00]\n",
      " [-3.85612675e+00 -3.95545000e+00]\n",
      " [ 6.47315221e+02  4.71068140e+00]\n",
      " [ 6.61042150e+01  1.46600000e-02]\n",
      " [ 2.60032624e+01  4.38300000e+01]\n",
      " [ 5.77835144e-01  7.44205670e-01]\n",
      " [ 8.88650460e+01  3.23000000e+01]\n",
      " [ 5.77886214e-01  7.70000000e-01]\n",
      " [ 7.44569442e-01  9.33000000e-01]\n",
      " [ 7.51863602e+01  0.00000000e+00]\n",
      " [-5.34470878e+00 -4.27000000e+00]\n",
      " [ 6.51182011e+01  8.58300000e+01]\n",
      " [ 9.24446751e+01  8.17000000e+01]\n",
      " [ 6.93218294e-01  8.56914894e-01]\n",
      " [-3.85563943e+00 -3.78000000e+00]\n",
      " [-3.11317337e+00 -3.37000000e+00]\n",
      " [ 5.22859853e+01  1.33500000e+00]\n",
      " [ 8.52174331e-01             nan]\n",
      " [ 5.30186297e+01             nan]\n",
      " [-1.75965071e+00 -2.43600000e+00]\n",
      " [ 6.51182011e+01  8.33300000e+01]\n",
      " [ 3.88072529e+02  4.00000000e+00]\n",
      " [ 3.87938997e+02  4.05700000e+00]\n",
      " [ 8.85982088e+01  6.96000000e+01]\n",
      " [ 3.82881332e+00  3.41254686e+01]\n",
      " [-3.85639748e+00 -3.61885333e+00]\n",
      " [ 3.86722892e+02             nan]\n",
      " [ 7.78440553e-01  8.89000000e-01]\n",
      " [ 4.47448253e+01  8.25613835e+00]\n",
      " [ 5.16384396e+02  5.92400000e+00]\n",
      " [ 4.18812551e-01  6.30000000e-01]\n",
      " [ 6.46679723e+02             nan]\n",
      " [-5.40016517e+00             nan]\n",
      " [-5.40015799e+00             nan]\n",
      " [-3.19250716e+00 -3.28000000e+00]\n",
      " [-4.19740801e+00 -2.74200000e+00]\n",
      " [ 5.16465547e+02  5.21000000e+00]\n",
      " [ 7.78007767e+01  6.00000000e-01]]\n",
      "##########  Monte Carlo 1 / 2 => Okay   ##########\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingsongli/miniconda3/envs/deepda/lib/python3.6/site-packages/pandas/core/generic.py:2530: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['File', 'Site', 'Type', 'Proxy', 'DepthOri', 'Glassy', 'mg_bcp_red']]\n",
      "\n",
      "  pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  prior2proxyunit hdf5 file saved\n",
      "      /volumes/DA/DeepDA/wrk/petmproxy3slices_v0.0.18.csv_petm18_v18_2021030_all_e400_MC2seed_testMac/_loc_0_proxy_frac_0.7_Rscale_1.0_MC_0.hdf5\n",
      ">>  Finished Step 1. Preparation\n",
      ">>  Now Run: Step 2. Data Assimilation ...\n",
      "\n",
      ">>  No 3d variable listed in DeepDA_config.yml\n",
      "\n",
      ">>Mg/Ca proxy found. Loading salinity, pH and omega\n",
      ">>  Reconstruction time intervals: 1; Observation data set number: 74\n",
      ">>  ID Recon: 0, obser: 0. Loc: [-138.05   10.35]. Mean of Ye 86.194963, var 0.262068, obs 92.500000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 1. Loc: [ 29. -16.]. Mean of Ye -5.844756, var 1.980224, obs -3.750000, obs_err 0.296299\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 2. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 3. Loc: [-52.    38.45]. Mean of Ye 215.969184, var 649.247417, obs 4.495000, obs_err 60307.839324\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 4. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 5. Loc: [-178.55  -56.15]. Mean of Ye 88.847220, var 7.100991, obs 34.670000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 6. Loc: [-51.    35.25]. Mean of Ye -2.435764, var 0.201615, obs -3.930000, obs_err 0.294421\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 7. Loc: [-52.    38.45]. Mean of Ye 254.585432, var 492.602267, obs 3.310000, obs_err 60821.455672\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 8. Loc: [-116.     42.25]. Mean of Ye -2.082716, var 0.116203, obs -3.160000, obs_err 0.298598\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 9. Loc: [-178.55  -56.15]. Mean of Ye 262.624011, var 524.364572, obs 5.840000, obs_err 81948.241654\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 10. Loc: [-87.45   9.6 ]. Mean of Ye 33.149341, var 498.241426, obs 0.255000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 11. Loc: [-20.01  41.8 ]. Mean of Ye 34.039224, var 172.162310, obs 0.682000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 12. Loc: [-155.45   28.35]. Mean of Ye 401.245034, var 1005.903509, obs 5.420000, obs_err 58372.775809\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 13. Loc: [-51.    35.25]. Mean of Ye -3.287055, var 0.081782, obs -3.940000, obs_err 0.299529\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 14. Loc: [ -5.   -65.05]. Mean of Ye 91.354245, var 0.123590, obs 59.560000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 15. Loc: [-11. -37.]. Mean of Ye 17.099680, var 176.014262, obs 0.688889, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 16. Loc: [-116.     44.05]. Mean of Ye -2.592424, var 0.062638, obs -3.020000, obs_err 0.300046\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 17. Loc: [-155.45   28.35]. Mean of Ye 57.819452, var 6.842400, obs 84.000000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 18. Loc: [-52.    38.45]. Mean of Ye -3.310376, var 0.054054, obs -3.570000, obs_err 0.295035\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 19. Loc: [-178.55  -56.15]. Mean of Ye 282.635136, var 300.731433, obs 5.850000, obs_err 83567.304760\n",
      ">>  ID Recon: 0, obser: 20. Loc: [-10.95  41.8 ]. Mean of Ye -3.694503, var 0.043755, obs -2.571895, obs_err 0.297018\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 21. Loc: [-17.75 -34.95]. Mean of Ye 424.216932, var 500.285361, obs 4.567042, obs_err 82564.936222\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 22. Loc: [-138.05   10.35]. Mean of Ye 499.035449, var 669.077636, obs 4.691423, obs_err 82323.285051\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 23. Loc: [-69.15  12.9 ]. Mean of Ye 16.117301, var 98.496066, obs 2.636667, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 24. Loc: [-61.25  30.1 ]. Mean of Ye 4.439421, var 56.299945, obs 57.000000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 25. Loc: [ -3.4 -10. ]. Mean of Ye 89.861383, var 0.038308, obs 0.456600, obs_err 400.000000\n",
      ">>  ID Recon: 0, obser: 26. Loc: [ -5.   -65.05]. Mean of Ye -0.922517, var 0.052056, obs -1.670000, obs_err 0.290139\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 27. Loc: [-52.    38.45]. Mean of Ye -3.233959, var 0.032744, obs -4.240000, obs_err 0.302248\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 28. Loc: [  4.15 -70.  ]. Mean of Ye -1.628772, var 0.039816, obs -1.835940, obs_err 0.298470\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 29. Loc: [-51.    35.25]. Mean of Ye -3.558519, var 0.026619, obs -4.763540, obs_err 0.291746\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 30. Loc: [-61.25  30.1 ]. Mean of Ye 10.666199, var 49.345064, obs 52.000000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 31. Loc: [-56.    38.25]. Mean of Ye -3.452861, var 0.024324, obs -3.540095, obs_err 0.296007\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 32. Loc: [-46.25   0.25]. Mean of Ye 70.692841, var 8.682639, obs 1.000000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 33. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 34. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 35. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 36. Loc: [-12.  -37.6]. Mean of Ye 13.986073, var 83.353495, obs 1.300000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 37. Loc: [-56.    38.25]. Mean of Ye -3.457871, var 0.022267, obs -3.955450, obs_err 0.299839\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 38. Loc: [-138.05   10.35]. Mean of Ye 546.876309, var 345.125835, obs 4.710681, obs_err 85032.084896\n",
      ">>  ID Recon: 0, obser: 39. Loc: [149.   -64.45]. Mean of Ye 34.752647, var 93.694925, obs 0.014660, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 40. Loc: [-39.  38.]. Mean of Ye 11.126745, var 48.782212, obs 43.830000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 41. Loc: [-35.    52.65]. Mean of Ye 0.552449, var 0.000080, obs 0.744206, obs_err 0.006430\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 42. Loc: [-13.  -38.5]. Mean of Ye 87.071233, var 0.169610, obs 32.300000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 43. Loc: [-35.    52.65]. Mean of Ye 0.555708, var 0.000080, obs 0.770000, obs_err 0.006515\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 44. Loc: [-51.    35.25]. Mean of Ye 0.721374, var 0.000083, obs 0.933000, obs_err 0.006348\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 45. Loc: [ 29. -16.]. Mean of Ye 56.062761, var 18.231251, obs 0.000000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 46. Loc: [-138.05   10.35]. Mean of Ye -5.064463, var 0.021422, obs -4.270000, obs_err 0.291990\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 47. Loc: [-156.55   27.45]. Mean of Ye 56.858909, var 4.799055, obs 85.830000, obs_err 400.000000\n",
      ">>  ID Recon: 0, obser: 48. Loc: [  4.15 -70.  ]. Mean of Ye 91.676342, var 0.045383, obs 81.700000, obs_err 400.000000\n",
      ">>  ID Recon: 0, obser: 49. Loc: [-161.    -48.75]. Mean of Ye 0.667614, var 0.000094, obs 0.856915, obs_err 0.006405\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 50. Loc: [-52.    38.45]. Mean of Ye -3.574725, var 0.018229, obs -3.780000, obs_err 0.301932\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 51. Loc: [-116.     42.25]. Mean of Ye -2.855971, var 0.016592, obs -3.370000, obs_err 0.302356\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 52. Loc: [-10.5  -37.65]. Mean of Ye 7.104703, var 38.675594, obs 1.335000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 53. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 54. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 55. Loc: [ -5.   -65.05]. Mean of Ye -1.474530, var 0.021722, obs -2.436000, obs_err 0.292213\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 56. Loc: [-156.55   27.45]. Mean of Ye 57.438567, var 4.622108, obs 83.330000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 57. Loc: [-10.95  41.8 ]. Mean of Ye 349.199233, var 44.402412, obs 4.000000, obs_err 81453.786495\n",
      ">>  ID Recon: 0, obser: 58. Loc: [-10.95  41.8 ]. Mean of Ye 348.624050, var 48.809153, obs 4.057000, obs_err 86038.794594\n",
      ">>  ID Recon: 0, obser: 59. Loc: [ 79.4 -62.2]. Mean of Ye 88.742362, var 0.348168, obs 69.600000, obs_err 400.000000\n",
      ">>  ID Recon: 0, obser: 60. Loc: [-10.95  41.8 ]. Mean of Ye 5.115839, var 56.009313, obs 34.125469, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 61. Loc: [-52.    38.45]. Mean of Ye -3.657199, var 0.015228, obs -3.618853, obs_err 0.294078\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 62. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 63. Loc: [-71.    31.15]. Mean of Ye 0.759325, var 0.000065, obs 0.889000, obs_err 0.006430\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 64. Loc: [-127.3   15.3]. Mean of Ye 7.867276, var 41.636528, obs 8.256138, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 65. Loc: [-155.45   28.35]. Mean of Ye 463.136434, var 191.742992, obs 5.924000, obs_err 61004.999543\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 66. Loc: [26.15 76.95]. Mean of Ye 0.411846, var 0.000080, obs 0.630000, obs_err 0.006381\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 67. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 68. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 69. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 70. Loc: [-116.     44.05]. Mean of Ye -3.037436, var 0.013876, obs -3.280000, obs_err 0.297679\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 71. Loc: [-10.95  41.8 ]. Mean of Ye -4.041713, var 0.012954, obs -2.742000, obs_err 0.300677\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 72. Loc: [-155.45   28.35]. Mean of Ye 458.842055, var 197.428462, obs 5.210000, obs_err 61454.120511\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 73. Loc: [ -9.9 -38.1]. Mean of Ye 58.793908, var 13.033380, obs 0.600000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>\n",
      ">>  Finished Step 2. Data Assimilation\n",
      ">>  Now      Step 3. Save results\n",
      "\n",
      "(9072, 100, 1)\n",
      ">>  Start writing netCDF ...\n",
      "Writing 2d field.\n",
      "\n",
      ">>    ID from 0 to 1296: field is ocn_sur_temp\n",
      ">>    Xb mean is 33.38204193, std is 5.73264876, var is 32.86326182\n",
      ">>      Recon 0. Xa mean is 32.39248276, std is 0.52747214, var is 0.27822685\n",
      "\n",
      ">>    ID from 1296 to 2592: field is atm_temp\n",
      ">>    Xb mean is 30.49624443, std is 6.70969378, var is 45.01999063\n",
      ">>      Recon 0. Xa mean is 29.26382256, std is 0.70934671, var is 0.50317276\n",
      "\n",
      ">>    ID from 2592 to 3888: field is atm_pCO2\n",
      ">>    Xb mean is 1667.49194336, std is 802.34120595, var is 643751.41076001\n",
      ">>      Recon 0. Xa mean is 1850.52124023, std is 97.45944214, var is 9498.34277344\n",
      "\n",
      ">>    ID from 3888 to 5184: field is ocn_sur_sal\n",
      ">>    Xb mean is 33.62309265, std is 0.61725562, var is 0.38100450\n",
      ">>      Recon 0. Xa mean is 33.64516068, std is 0.06768382, var is 0.00458110\n",
      "\n",
      ">>    ID from 5184 to 6480: field is misc_pH\n",
      ">>    Xb mean is 7.52868843, std is 0.24024050, var is 0.05771550\n",
      ">>      Recon 0. Xa mean is 7.49256086, std is 0.04219903, var is 0.00178076\n",
      "\n",
      ">>    ID from 6480 to 7776: field is carb_sur_ohm_cal\n",
      ">>    Xb mean is 4.81338263, std is 2.23041471, var is 4.97474978\n",
      ">>      Recon 0. Xa mean is 4.79714489, std is 0.63268715, var is 0.40029302\n",
      "\n",
      ">>    ID from 7776 to 9072: field is sed_CaCO3\n",
      ">>    Xb mean is 41.64755630, std is 20.34868120, var is 414.06882655\n",
      ">>      Recon 0. Xa mean is 26.94945145, std is 5.85035467, var is 34.22665024\n",
      ">>  Data saved in netCDF file:\n",
      "/volumes/DA/DeepDA/wrk/petmproxy3slices_v0.0.18.csv_petm18_v18_2021030_all_e400_MC2seed_testMac/_loc_0_proxy_frac_0.7_Rscale_1.0_MC_0.nc\n",
      "\n",
      "##########                    ##########\n",
      "##########   This loop done   ##########\n",
      "##########                    ##########\n",
      "\n",
      "\n",
      ">>  Proxy fraction is 0.7\n",
      "Setting current prior iteration seed: 1\n",
      ">>  Selected index: [17, 72, 102, 97, 8, 32, 15, 63, 103, 57, 60, 83, 48, 26, 12, 62, 3, 49, 55, 77, 0, 96, 34, 29, 75, 13, 40, 89, 2, 78, 69, 1, 93, 27, 54, 76, 67, 28, 56, 98, 82, 44, 65, 43, 14, 73, 66, 18, 74, 92, 53, 35, 41, 6, 11, 79, 46, 58, 7, 21, 45, 100, 104, 64, 91, 19, 95, 37, 31, 42, 25, 86, 30, 99]\n",
      ">>  Unselected index: [4, 5, 9, 10, 16, 20, 22, 23, 24, 33, 36, 38, 39, 47, 50, 51, 52, 59, 61, 68, 70, 71, 80, 81, 84, 85, 87, 88, 90, 94, 101, 105]\n",
      ">>  Proxy order: all random.\n",
      ">>  Selected proxy data length 74\n",
      ">>  OKAY.\n",
      "\n",
      "########## Check the consistency of the config.yml file and proxy database ##########\n",
      "\n",
      "\n",
      ">>  All looks good.\n",
      "\n",
      "##########  Ye calculation  ##########\n",
      "\n",
      ">>  0. File: Babila 2016, grid [lon lat] [12, 29], index 1056, PSM for d18o_a.soldadoensis is bayesreg_d18o_pooled\n",
      ">>  1. File: Murphy et al. (2006), grid [lon lat] [4, 18], index 8428, PSM for caco3 is cgenie_caco3\n",
      ">>  2. File: Bralower et al. (1997), grid [lon lat] [11, 22], index 8579, PSM for caco3 is cgenie_caco3\n",
      ">>  3. File: zachos2006-wilsonlakepetmd18o.txt, grid [lon lat] [12, 28], index 1020, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  4. File: kozdon2020-690-d18O, grid [lon lat] [17, 1], index 53, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  5. File: aze2014-tanzaniad18omorozovella.txt, grid [lon lat] [20, 13], index 488, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  6. File: SSP (1989)§, grid [lon lat] [25, 2], index 7873, PSM for caco3 is cgenie_caco3\n",
      ">>  7. File: Crouch et al., 2003, grid [lon lat] [1, 4], index 7921, PSM for caco3 is cgenie_caco3\n",
      ">>  8. File: SSP (1990)§, grid [lon lat] [26, 5], index 7982, PSM for caco3 is cgenie_caco3\n",
      ">>  9. File: Zachos et al. (2005), grid [lon lat] [16, 6], index 8008, PSM for caco3 is cgenie_caco3\n",
      ">>  10. File: Leon-Rodriguez & Dickens 2010, grid [lon lat] [5, 22], index 8573, PSM for caco3 is cgenie_caco3\n",
      ">>  11. File: Penman et al. 2014; Harper et al. 2020, grid [lon lat] [2, 26], index 938, PSM for mgca_acarinina:reductive is bayesreg_mgca_pooled_red\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 1\n",
      ">>  12. File: Barnet et al. 2020, grid [lon lat] [13, 28], index 1021, PSM for mgca_morozovella:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  13. File: Hines et al. 2017, grid [lon lat] [1, 4], index 145, PSM for mgca_acarinina:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  14. File: tripati2004-865mgcaasoldadoensis.txt, grid [lon lat] [4, 21], index 760, PSM for mgca_acarinina:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  15. File: Babila 2016, grid [lon lat] [12, 29], index 1056, PSM for mgca_morozovella:reductive is bayesreg_mgca_pooled_red\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 1\n",
      ">>  16. File: Hines et al. 2017, grid [lon lat] [0, 3], index 108, PSM for mgca_acarinina:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  17. File: Bralower et al. (2002),Quillévéré et al. (2002), grid [lon lat] [2, 26], index 8714, PSM for caco3 is cgenie_caco3\n",
      ">>  18. File: Stokke2020-TEX-Fur, grid [lon lat] [14, 32], index 1166, PSM for tex86 is bayesreg_tex86\n",
      ">>  19. File: frieling2014-westsiberian.txt, grid [lon lat] [22, 32], index 1174, PSM for tex86 is bayesreg_tex86\n",
      ">>  20. File: aze2014-tanzaniad18oacarinina.txt, grid [lon lat] [20, 13], index 488, PSM for d18o_a.soldadoensis is bayesreg_d18o_pooled\n",
      ">>  21. File: zachos2006-wilsonlake.txt, grid [lon lat] [12, 28], index 1020, PSM for tex86 is bayesreg_tex86\n",
      ">>  22. File: john2008-tumeygulchd18o.txt, grid [lon lat] [6, 30], index 1086, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  23. File: Sluijs et al. (2011), grid [lon lat] [32, 1], index 7844, PSM for caco3 is cgenie_caco3\n",
      ">>  24. File: hollis2012-waiparatex-mgca-d18o.txt, grid [lon lat] [1, 4], index 145, PSM for tex86 is bayesreg_tex86\n",
      ">>  25. File: SSP (1995), grid [lon lat] [4, 21], index 8536, PSM for caco3 is cgenie_caco3\n",
      ">>  26. File: zachos2003-1209mgcam.velascoensis.txt, grid [lon lat] [2, 26], index 938, PSM for mgca_morozovella:reductive is bayesreg_mgca_pooled_red\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 1\n",
      ">>  27. File: tripati2005-527mgcam.subb.txt, grid [lon lat] [16, 7], index 268, PSM for mgca_m.subb:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  28. File: Colosimo et al. (2006), grid [lon lat] [2, 26], index 8714, PSM for caco3 is cgenie_caco3\n",
      ">>  29. File: john2008-bassriverd18o.txt, grid [lon lat] [12, 29], index 1056, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  30. File: Smith et al. 2020, grid [lon lat] [9, 24], index 873, PSM for tex86 is bayesreg_tex86\n",
      ">>  31. File: Rudnicki et al. (2001), grid [lon lat] [11, 27], index 8759, PSM for caco3 is cgenie_caco3\n",
      ">>  32. File: sluijs2014-harrellcore.txt, grid [lon lat] [10, 27], index 982, PSM for tex86 is bayesreg_tex86\n",
      ">>  33. File: Aze et al. (2014), grid [lon lat] [20, 13], index 8264, PSM for caco3 is cgenie_caco3\n",
      ">>  34. File: Zachos et al. (2005), grid [lon lat] [17, 6], index 8009, PSM for caco3 is cgenie_caco3\n",
      ">>  35. File: Hollis et al. 2015, grid [lon lat] [0, 3], index 108, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  36. File: Hollis et al., 2012, grid [lon lat] [1, 4], index 7921, PSM for caco3 is cgenie_caco3\n",
      ">>  37. File: john2008-lodod18o.txt, grid [lon lat] [6, 30], index 1086, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  38. File: tripati2003-865mgcamorozovella.txt, grid [lon lat] [4, 21], index 760, PSM for mgca_m.subbotinae:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  39. File: Bornemann et al., 2014, grid [lon lat] [16, 29], index 1060, PSM for d18o_m.subb is bayesreg_d18o_pooled\n",
      ">>  40. File: frieling2017-sqofnigeria.txt, grid [lon lat] [17, 14], index 521, PSM for mgca_acarinina:reductive is bayesreg_mgca_pooled_red\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 1\n",
      ">>  41. File: frieling2017-sqofnigeria.txt, grid [lon lat] [17, 14], index 521, PSM for mgca_morozovella:reductive is bayesreg_mgca_pooled_red\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 1\n",
      ">>  42. File: Hines et al. 2017, grid [lon lat] [0, 3], index 108, PSM for mgca_morozovella:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  43. File: Penman et al. 2014; Harper et al. 2020, grid [lon lat] [2, 26], index 938, PSM for mgca_morozovella:reductive is bayesreg_mgca_pooled_red\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 1\n",
      ">>  44. File: frieling2017-ib10bofnigeria.txt, grid [lon lat] [16, 17], index 628, PSM for tex86 is bayesreg_tex86\n",
      ">>  45. File: SSP (2002g)§, grid [lon lat] [5, 17], index 8393, PSM for caco3 is cgenie_caco3\n",
      ">>  46. File: Thomas et al. (1999), grid [lon lat] [16, 7], index 8044, PSM for caco3 is cgenie_caco3\n",
      ">>  47. File: zachos2003-1209mgcaa.soldadoensis.txt, grid [lon lat] [2, 26], index 938, PSM for mgca_acarinina:reductive is bayesreg_mgca_pooled_red\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 1\n",
      ">>  48. File: Zachos et al. (2005), grid [lon lat] [16, 7], index 8044, PSM for caco3 is cgenie_caco3\n",
      ">>  49. File: john2008-bassriverd18o.txt, grid [lon lat] [12, 29], index 1056, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  50. File: Si et al. 2018, grid [lon lat] [18, 1], index 54, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  51. File: Bornemann et al., 2014, grid [lon lat] [16, 29], index 1060, PSM for d18o_a.soldadoensis is bayesreg_d18o_pooled\n",
      ">>  52. File: SSP (1988)§, grid [lon lat] [18, 1], index 7830, PSM for caco3 is cgenie_caco3\n",
      ">>  53. File: frieling2017-sqofnigeriatex86.txt, grid [lon lat] [17, 14], index 521, PSM for tex86 is bayesreg_tex86\n",
      ">>  54. File: tripati2003-865mgcamorozovella.txt, grid [lon lat] [4, 21], index 760, PSM for mgca_m.velascoensis:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  55. File: Zachos et al. (2005), grid [lon lat] [16, 7], index 8044, PSM for caco3 is cgenie_caco3\n",
      ">>  56. File: Si et al. 2018, grid [lon lat] [12, 28], index 1020, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  57. File: schoon2013-storebaelt.txt, grid [lon lat] [19, 30], index 1099, PSM for tex86 is bayesreg_tex86\n",
      ">>  58. File: john2008-lodod18o.txt, grid [lon lat] [6, 30], index 1086, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  59. File: Thomas et al. (1999), grid [lon lat] [17, 1], index 7829, PSM for caco3 is cgenie_caco3\n",
      ">>  60. File: sluijs2007-bassriver.txt, grid [lon lat] [12, 29], index 1056, PSM for tex86 is bayesreg_tex86\n",
      ">>  61. File: thomas1996-690d18ofora.txt, grid [lon lat] [17, 1], index 53, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  62. File: kozdon2013-865d18omorozovellasims.txt, grid [lon lat] [4, 21], index 760, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  63. File: frieling2017-ib10aofnigeria.txt, grid [lon lat] [16, 17], index 628, PSM for tex86 is bayesreg_tex86\n",
      ">>  64. File: zachos2006-wilsonlakepetmd18o.txt, grid [lon lat] [12, 28], index 1020, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  65. File: Si et al. 2018, grid [lon lat] [12, 29], index 1056, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  66. File: Si et al. 2018, grid [lon lat] [12, 29], index 1056, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  67. File: gutjahr2017-dsdp401d18omgca.txt, grid [lon lat] [16, 29], index 1060, PSM for mgca_m.subb:barker is bayesreg_mgca_pooled_bcp\n",
      ">>    mean of Xb_sal 33.623093194719175, Xb_ph 7.528687894752671, Xb_omega 4.813382761272525, cleaning 0\n",
      ">>  68. File: Si et al. 2018, grid [lon lat] [18, 1], index 54, PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  69. File: Hancock et al. (2006), grid [lon lat] [26, 4], index 7946, PSM for caco3 is cgenie_caco3\n",
      ">>  70. File: Hollis et al. 2015, grid [lon lat] [0, 3], index 108, PSM for d18o_acarinina is bayesreg_d18o_pooled\n",
      ">>  71. File: Penman et al., 2016, grid [lon lat] [13, 28], index 8797, PSM for caco3 is cgenie_caco3\n",
      ">>  72. File: Zachos et al. (2005), grid [lon lat] [16, 7], index 8044, PSM for caco3 is cgenie_caco3\n",
      ">>  73. File: Thomas & Bralower (2005), grid [lon lat] [15, 29], index 8835, PSM for caco3 is cgenie_caco3\n",
      "\n",
      ">>  Summary of this Monte Carlo simulation\n",
      "[Ye, Ob_value]\n",
      ">>  [[-3.85545302e+00 -3.42000000e+00]\n",
      " [ 1.97402204e+01  2.72384615e+00]\n",
      " [ 4.73230754e+01  2.63666667e+00]\n",
      " [-4.05557212e+00 -3.94000000e+00]\n",
      " [-1.75965908e+00 -2.43600000e+00]\n",
      " [-5.83730939e+00 -3.75000000e+00]\n",
      " [ 8.85982088e+01  6.96000000e+01]\n",
      " [ 9.16739689e+01  9.55000000e+00]\n",
      " [ 5.30186297e+01             nan]\n",
      " [ 8.88650460e+01  3.23000000e+01]\n",
      " [ 4.47448253e+01  8.25613835e+00]\n",
      " [ 5.16522773e+02  5.21000000e+00]\n",
      " [ 4.59855401e+02  4.80644832e+00]\n",
      " [ 3.85880988e+02             nan]\n",
      " [ 6.47937982e+02  4.69142300e+00]\n",
      " [ 3.57938126e+02  4.49500000e+00]\n",
      " [ 3.54593905e+02  5.85000000e+00]\n",
      " [ 6.51182011e+01             nan]\n",
      " [ 5.77758655e-01  7.44205670e-01]\n",
      " [ 5.69453832e-01  7.00000000e-01]\n",
      " [-5.83680116e+00 -4.08692000e+00]\n",
      " [ 7.44515813e-01  9.33000000e-01]\n",
      " [-3.11339154e+00 -3.37000000e+00]\n",
      " [ 6.61042150e+01  1.46600000e-02]\n",
      " [ 6.93390314e-01  8.56914894e-01]\n",
      " [ 8.61949625e+01  9.25000000e+01]\n",
      " [ 5.17458463e+02  5.59200000e+00]\n",
      " [ 5.40182445e+02  4.56704240e+00]\n",
      " [ 6.51182011e+01  7.83300000e+01]\n",
      " [-3.85520657e+00 -4.24000000e+00]\n",
      " [ 8.11898434e-01  9.81431235e-01]\n",
      " [ 2.97680616e+01  5.70000000e+01]\n",
      " [ 7.78532054e-01  8.89000000e-01]\n",
      " [ 7.51863602e+01  0.00000000e+00]\n",
      " [ 7.78007767e+01  6.00000000e-01]\n",
      " [-4.64735912e+00 -2.97000000e+00]\n",
      " [ 9.16739689e+01  1.66077381e-01]\n",
      " [-3.19291125e+00 -3.02000000e+00]\n",
      " [ 6.46654170e+02             nan]\n",
      " [-4.19608959e+00 -2.74200000e+00]\n",
      " [ 6.91376480e+02             nan]\n",
      " [ 6.91057233e+02             nan]\n",
      " [ 3.54088662e+02  5.84000000e+00]\n",
      " [ 5.16902534e+02  5.42000000e+00]\n",
      " [ 8.58294047e-01  9.50000000e-01]\n",
      " [ 4.10430746e+01  0.00000000e+00]\n",
      " [ 5.22859853e+01  1.55000000e+00]\n",
      " [ 5.16259460e+02  5.92400000e+00]\n",
      " [ 5.22859853e+01  6.88888889e-01]\n",
      " [-3.85617356e+00 -3.57000000e+00]\n",
      " [-2.24161616e+00 -1.83594000e+00]\n",
      " [-4.19680343e+00 -2.47800000e+00]\n",
      " [ 9.24446751e+01  8.17000000e+01]\n",
      " [ 8.52194408e-01             nan]\n",
      " [ 6.47475586e+02             nan]\n",
      " [ 5.22859853e+01  1.30000000e+00]\n",
      " [-4.05555622e+00 -3.73514000e+00]\n",
      " [ 6.83356081e-01  7.34500000e-01]\n",
      " [-3.19286878e+00 -3.28000000e+00]\n",
      " [ 9.22162148e+01  5.95600000e+01]\n",
      " [ 7.25973597e-01  9.20000000e-01]\n",
      " [-1.75950155e+00 -1.67000000e+00]\n",
      " [-5.34481380e+00 -4.27000000e+00]\n",
      " [ 8.58233497e-01  9.50000000e-01]\n",
      " [-4.05620296e+00 -3.93000000e+00]\n",
      " [-3.85597448e+00 -3.61610667e+00]\n",
      " [-3.85578029e+00 -3.54009500e+00]\n",
      " [ 3.88563865e+02  4.00000000e+00]\n",
      " [-2.24032212e+00 -1.78589800e+00]\n",
      " [ 3.25348939e+01  3.79400000e+01]\n",
      " [-4.64728355e+00 -2.11713233e+00]\n",
      " [ 7.57073785e+00  3.40000000e-01]\n",
      " [ 5.22859853e+01  1.33500000e+00]\n",
      " [ 4.80084660e+01  6.82000000e-01]]\n",
      "##########  Monte Carlo 2 / 2 => Okay   ##########\n",
      "\n",
      ">>  prior2proxyunit hdf5 file saved\n",
      "      /volumes/DA/DeepDA/wrk/petmproxy3slices_v0.0.18.csv_petm18_v18_2021030_all_e400_MC2seed_testMac/_loc_0_proxy_frac_0.7_Rscale_1.0_MC_1.hdf5\n",
      ">>  Finished Step 1. Preparation\n",
      ">>  Now Run: Step 2. Data Assimilation ...\n",
      "\n",
      ">>  No 3d variable listed in DeepDA_config.yml\n",
      "\n",
      ">>Mg/Ca proxy found. Loading salinity, pH and omega\n",
      ">>  Reconstruction time intervals: 1; Observation data set number: 74\n",
      ">>  ID Recon: 0, obser: 0. Loc: [-52.    38.45]. Mean of Ye -3.855821, var 1.581318, obs -3.420000, obs_err 0.302095\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 1. Loc: [-130.1     1.15]. Mean of Ye 23.692096, var 456.915074, obs 2.723846, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 2. Loc: [-69.15  12.9 ]. Mean of Ye 40.557492, var 224.175056, obs 2.636667, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 3. Loc: [-51.    35.25]. Mean of Ye -3.784878, var 0.242066, obs -3.940000, obs_err 0.287416\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 4. Loc: [ -5.   -65.05]. Mean of Ye -1.519054, var 0.175182, obs -2.436000, obs_err 0.297144\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 5. Loc: [ 29. -16.]. Mean of Ye -5.932078, var 0.105310, obs -3.750000, obs_err 0.294546\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 6. Loc: [ 79.4 -62.2]. Mean of Ye 89.106956, var 0.388863, obs 69.600000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 7. Loc: [-165.95  -46.95]. Mean of Ye 91.451156, var 0.011660, obs 9.550000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 8. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 9. Loc: [-13.  -38.5]. Mean of Ye 87.762877, var 0.452475, obs 32.300000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 10. Loc: [-127.3   15.3]. Mean of Ye 20.440478, var 227.633830, obs 8.256138, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 11. Loc: [-155.45   28.35]. Mean of Ye 435.504715, var 888.033464, obs 5.210000, obs_err 59927.482889\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 12. Loc: [-41.   37.5]. Mean of Ye 382.985690, var 519.294020, obs 4.806448, obs_err 83226.698643\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 13. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 14. Loc: [-138.05   10.35]. Mean of Ye 528.105816, var 1226.151838, obs 4.691423, obs_err 83337.643435\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 15. Loc: [-52.    38.45]. Mean of Ye 290.481506, var 287.490225, obs 4.495000, obs_err 60057.775411\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 16. Loc: [-178.55  -56.15]. Mean of Ye 277.810475, var 411.114538, obs 5.850000, obs_err 84605.970813\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 17. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 18. Loc: [-35.    52.65]. Mean of Ye 0.541208, var 0.000221, obs 0.744206, obs_err 0.006349\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 19. Loc: [49.99 51.25]. Mean of Ye 0.537752, var 0.000240, obs 0.700000, obs_err 0.006470\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 20. Loc: [ 29. -16.]. Mean of Ye -5.400639, var 0.068985, obs -4.086920, obs_err 0.292214\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 21. Loc: [-51.    35.25]. Mean of Ye 0.700759, var 0.000178, obs 0.933000, obs_err 0.006254\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 22. Loc: [-116.     42.25]. Mean of Ye -2.636128, var 0.041750, obs -3.370000, obs_err 0.294523\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 23. Loc: [149.   -64.45]. Mean of Ye 45.776381, var 134.644853, obs 0.014660, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 24. Loc: [-161.    -48.75]. Mean of Ye 0.661614, var 0.000186, obs 0.856915, obs_err 0.006520\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 25. Loc: [-138.05   10.35]. Mean of Ye 85.549265, var 0.034954, obs 92.500000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 26. Loc: [-155.45   28.35]. Mean of Ye 446.149118, var 538.247850, obs 5.592000, obs_err 60774.010339\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 27. Loc: [-17.75 -34.95]. Mean of Ye 462.283389, var 533.498510, obs 4.567042, obs_err 84639.825171\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 28. Loc: [-156.55   27.45]. Mean of Ye 57.752115, var 6.176793, obs 78.330000, obs_err 400.000000\n",
      ">>  ID Recon: 0, obser: 29. Loc: [-52.    38.45]. Mean of Ye -3.483150, var 0.036151, obs -4.240000, obs_err 0.292936\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 30. Loc: [-81.    20.85]. Mean of Ye 0.792554, var 0.000151, obs 0.981431, obs_err 0.006262\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 31. Loc: [-61.25  30.1 ]. Mean of Ye 5.258466, var 58.285264, obs 57.000000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 32. Loc: [-71.    31.15]. Mean of Ye 0.757719, var 0.000139, obs 0.889000, obs_err 0.006413\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 33. Loc: [ 29. -16.]. Mean of Ye 59.542242, var 25.641721, obs 0.000000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 34. Loc: [ -9.9 -38.1]. Mean of Ye 60.868579, var 19.336631, obs 0.600000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 35. Loc: [-178.55  -56.15]. Mean of Ye -4.445250, var 0.037799, obs -2.970000, obs_err 0.301675\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 36. Loc: [-161.    -48.75]. Mean of Ye 91.360402, var 0.006398, obs 0.166077, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 37. Loc: [-116.     44.05]. Mean of Ye -2.871952, var 0.026460, obs -3.020000, obs_err 0.301451\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 38. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 39. Loc: [-10.95  41.8 ]. Mean of Ye -3.876849, var 0.024604, obs -2.742000, obs_err 0.303103\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 40. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 41. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 42. Loc: [-178.55  -56.15]. Mean of Ye 290.375834, var 155.117749, obs 5.840000, obs_err 82960.392978\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 43. Loc: [-155.45   28.35]. Mean of Ye 434.173721, var 346.551283, obs 5.420000, obs_err 60877.500775\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 44. Loc: [-10.1   -0.35]. Mean of Ye 0.828325, var 0.000112, obs 0.950000, obs_err 0.006375\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 45. Loc: [-123.2   -0.9]. Mean of Ye 5.812720, var 46.823769, obs 0.000000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 46. Loc: [-17.75 -34.95]. Mean of Ye 6.298011, var 40.902306, obs 1.550000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 47. Loc: [-155.45   28.35]. Mean of Ye 434.746224, var 279.949746, obs 5.924000, obs_err 61298.049817\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 48. Loc: [-11. -37.]. Mean of Ye 5.857592, var 35.926154, obs 0.688889, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 49. Loc: [-52.    38.45]. Mean of Ye -3.425378, var 0.022206, obs -3.570000, obs_err 0.294221\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 50. Loc: [  4.15 -70.  ]. Mean of Ye -1.744616, var 0.028386, obs -1.835940, obs_err 0.301265\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 51. Loc: [-10.95  41.8 ]. Mean of Ye -3.793741, var 0.018767, obs -2.478000, obs_err 0.295084\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 52. Loc: [  4.15 -70.  ]. Mean of Ye 91.485791, var 0.050830, obs 81.700000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 53. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 54. Skip invalid obs.\n",
      ">>  ID Recon: 0, obser: 55. Loc: [-12.  -37.6]. Mean of Ye 5.356174, var 30.761423, obs 1.300000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 56. Loc: [-51.    35.25]. Mean of Ye -3.565887, var 0.018274, obs -3.735140, obs_err 0.296740\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 57. Loc: [11.65 44.55]. Mean of Ye 0.644541, var 0.000069, obs 0.734500, obs_err 0.006487\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 58. Loc: [-116.     44.05]. Mean of Ye -2.747100, var 0.016400, obs -3.280000, obs_err 0.289312\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 59. Loc: [ -5.   -65.05]. Mean of Ye 91.039258, var 0.052406, obs 59.560000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 60. Loc: [-55.55  38.45]. Mean of Ye 0.696098, var 0.000066, obs 0.920000, obs_err 0.006474\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 61. Loc: [ -5.   -65.05]. Mean of Ye -1.284256, var 0.021051, obs -1.670000, obs_err 0.296827\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 62. Loc: [-138.05   10.35]. Mean of Ye -4.952641, var 0.015734, obs -4.270000, obs_err 0.297611\n",
      ">>  ID Recon: 0, obser: 63. Loc: [-10.1   -0.35]. Mean of Ye 0.829979, var 0.000069, obs 0.950000, obs_err 0.006273\n",
      ">>  ID Recon: 0, obser: 64. Loc: [-51.    35.25]. Mean of Ye -3.661773, var 0.013730, obs -3.930000, obs_err 0.290426\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 65. Loc: [-52.    38.45]. Mean of Ye -3.470036, var 0.013419, obs -3.616107, obs_err 0.295062\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 66. Loc: [-56.    38.25]. Mean of Ye -3.476818, var 0.012796, obs -3.540095, obs_err 0.294619\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 67. Loc: [-10.95  41.8 ]. Mean of Ye 331.372033, var 28.166702, obs 4.000000, obs_err 84431.117351\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 68. Loc: [  4.15 -70.  ]. Mean of Ye -1.792046, var 0.016464, obs -1.785898, obs_err 0.296903\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 69. Loc: [ 85. -51.]. Mean of Ye 4.565022, var 42.979955, obs 37.940000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      ">>  ID Recon: 0, obser: 70. Loc: [-178.55  -56.15]. Mean of Ye -4.236666, var 0.013821, obs -2.117132, obs_err 0.302908\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 71. Loc: [-41.   37.5]. Mean of Ye 9.396699, var 51.504780, obs 0.340000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 72. Loc: [-10.5  -37.65]. Mean of Ye 6.899020, var 26.916664, obs 1.335000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>  ID Recon: 0, obser: 73. Loc: [-20.01  41.8 ]. Mean of Ye 14.925436, var 48.405956, obs 0.682000, obs_err 400.000000\n",
      " set variable sed_CaCO3 : id 7776 - 9072 min limit to 0.0\n",
      " set variable sed_CaCO3 : id 7776 - 9072 max limit to 100.0\n",
      ">>\n",
      ">>  Finished Step 2. Data Assimilation\n",
      ">>  Now      Step 3. Save results\n",
      "\n",
      "(9072, 100, 1)\n",
      ">>  Start writing netCDF ...\n",
      "Writing 2d field.\n",
      "\n",
      ">>    ID from 0 to 1296: field is ocn_sur_temp\n",
      ">>    Xb mean is 33.38204193, std is 5.73264876, var is 32.86326182\n",
      ">>      Recon 0. Xa mean is 31.30056953, std is 0.48809147, var is 0.23823327\n",
      "\n",
      ">>    ID from 1296 to 2592: field is atm_temp\n",
      ">>    Xb mean is 30.49624443, std is 6.70969378, var is 45.01999063\n",
      ">>      Recon 0. Xa mean is 28.02216339, std is 0.67069000, var is 0.44982505\n",
      "\n",
      ">>    ID from 2592 to 3888: field is atm_pCO2\n",
      ">>    Xb mean is 1667.49194336, std is 802.34120595, var is 643751.41076001\n",
      ">>      Recon 0. Xa mean is 1690.85339355, std is 93.28314209, var is 8701.74414062\n",
      "\n",
      ">>    ID from 3888 to 5184: field is ocn_sur_sal\n",
      ">>    Xb mean is 33.62309265, std is 0.61725562, var is 0.38100450\n",
      ">>      Recon 0. Xa mean is 33.66253281, std is 0.06375745, var is 0.00406501\n",
      "\n",
      ">>    ID from 5184 to 6480: field is misc_pH\n",
      ">>    Xb mean is 7.52868843, std is 0.24024050, var is 0.05771550\n",
      ">>      Recon 0. Xa mean is 7.48683977, std is 0.04185158, var is 0.00175156\n",
      "\n",
      ">>    ID from 6480 to 7776: field is carb_sur_ohm_cal\n",
      ">>    Xb mean is 4.81338263, std is 2.23041471, var is 4.97474978\n",
      ">>      Recon 0. Xa mean is 4.38292456, std is 0.62682968, var is 0.39291546\n",
      "\n",
      ">>    ID from 7776 to 9072: field is sed_CaCO3\n",
      ">>    Xb mean is 41.64755630, std is 20.34868120, var is 414.06882655\n",
      ">>      Recon 0. Xa mean is 25.91469574, std is 5.98739481, var is 35.84889603\n",
      ">>  Data saved in netCDF file:\n",
      "/volumes/DA/DeepDA/wrk/petmproxy3slices_v0.0.18.csv_petm18_v18_2021030_all_e400_MC2seed_testMac/_loc_0_proxy_frac_0.7_Rscale_1.0_MC_1.nc\n",
      "\n",
      "##########                    ##########\n",
      "##########   This loop done   ##########\n",
      "##########                    ##########\n",
      "\n",
      "\n",
      "/volumes/DA/DeepDA/wrk/petmproxy3slices_v0.0.18.csv_petm18_v18_2021030_all_e400_MC2seed_testMac.yml\n",
      "\n",
      "This page saved as DeepDA_allMC.html in the working directory\n",
      "\n",
      "########## All Done ##########\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DeepDA with Monte Carlo options\n",
    "Feb 26, 2020\n",
    "based on DeepDA_priorprep.ipynb and DeepDA_main.ipynb, which has been commited to the DeepDA github page\n",
    "\n",
    "Updated\n",
    "    Mar. 3. 2020\n",
    "        partly clean the code; add MC for local_rad, withheld_rate, and scaled Rg\n",
    "    June 2020\n",
    "        include d18O of CESM by Zhu et al., 2019 Sci Adv\n",
    "    August 2020\n",
    "        Two options for the proxy order: all random & use the given list\n",
    "    Oct. 12, 2020\n",
    "        Add multi_seed for Monte Carlo simulations\n",
    "\n",
    "Note:\n",
    "    if Mg/Ca proxy is included, need to run\n",
    "        correct_cgenie_carb_ohm_cal.ipynb for the estimation of carb_ohm_cal_ben field\n",
    "    if d13C proxy is included, need to run\n",
    "        correct_cgenie_sed_caco3_13c.ipynb for the correction of d13C\n",
    "'''\n",
    "\n",
    "### Import packages\n",
    "from DeepDA_lib import LMR_DA\n",
    "from DeepDA_lib import modules_nc\n",
    "from DeepDA_lib import DeepDA_psm\n",
    "from DeepDA_lib import DeepDA_tools\n",
    "import h5py\n",
    "import time\n",
    "import yaml\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas\n",
    "import os\n",
    "import shutil\n",
    "from netCDF4 import Dataset\n",
    "import numpy.ma as ma\n",
    "import numpy.matlib as mat\n",
    "from sys import platform as sys_pf\n",
    "import matplotlib.pyplot as plt\n",
    "if sys_pf == 'darwin':\n",
    "    import matplotlib\n",
    "    matplotlib.use(\"TkAgg\")\n",
    "    import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.basemap import Basemap, shiftgrid, cm\n",
    "\n",
    "try:\n",
    "    import bayspar\n",
    "except ImportError as e2:\n",
    "    print('Warning:', e2)\n",
    "try:\n",
    "    import bayfox\n",
    "except ImportError as e3:\n",
    "    print('Warning:', e3)\n",
    "try:\n",
    "    import baymag\n",
    "except ImportError as e4:\n",
    "    print('Warning:', e4)\n",
    "    \n",
    "print('>>  Import packages...  => Okay')\n",
    "\n",
    "### Read config file\n",
    "\n",
    "config_name = \"DeepDA_config.yml\"\n",
    "#config_name = \"petmproxy3slices_v0.0.10gt1.csvexp_petm78_og1_qc_obs_20200203_test2.yml\"\n",
    "f = open(config_name, 'r')\n",
    "yml_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "f.close()\n",
    "\n",
    "t = -1  # last time slice, cGENIE\n",
    "k = 0   # surface layer, SST\n",
    "\n",
    "kcov_saving = 0 # save covariance??? 0=no, 1 = yes\n",
    "\n",
    "# read config.yml settings\n",
    "print('')\n",
    "print(' ########## Load yml config file ########## ')\n",
    "print('')\n",
    "########## Proxy + PSM #########\n",
    "MCn = yml_dict['MonteCarlo']['number']\n",
    "multi_seed = yml_dict['MonteCarlo']['multi_seed']\n",
    "dir_proxy         = yml_dict['core']['proxy_dir']\n",
    "dir_proxy_data    = dir_proxy +'/'+ yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['dbversion']\n",
    "dir_proxy_save_dir= yml_dict['core']['wrkdir'] + '/'\n",
    "dir_proxy_save    = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['dbversion']\n",
    "proxy_psm_type    = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_psm_type']\n",
    "proxy_assim2      = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_assim2']\n",
    "proxy_order       = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_order']\n",
    "proxy_err_eval   = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_err_eval']\n",
    "proxy_blacklist   = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_blacklist']\n",
    "proxy_list = [item for item in proxy_order if item not in proxy_blacklist]\n",
    "psm_d18osw_adjust = yml_dict['psm']['bayesreg_d18o_pooled']['psm_d18osw_adjust']\n",
    "d18osw_local_choice = yml_dict['psm']['bayesreg_d18o_pooled']['d18osw_local_choice']\n",
    "d18osw_icesm_pco2 = yml_dict['psm']['bayesreg_d18o_pooled']['d18osw_icesm_pco2']\n",
    "\n",
    "proxy_qc          = yml_dict['proxies']['proxy_qc']\n",
    "lon_label = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['lon_label']\n",
    "lat_label = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['lat_label']\n",
    "\n",
    "prior_source = yml_dict['prior']['prior_source'] #\n",
    "prior_state_variable = yml_dict['prior'][prior_source]['state_variable']  # note: ['2d': xxx; '3d': xxx]\n",
    "dum_lon_offset = yml_dict['prior'][prior_source]['dum_lon_offset'] # longitude offset\n",
    "dir_prior = yml_dict['core']['prior_dir']\n",
    "dir_prior_full = os.listdir(dir_prior)\n",
    "prior_len = len(dir_prior_full)\n",
    "\n",
    "nexp = yml_dict['core']['nexp']\n",
    "data_period_id    = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['data_period_id']\n",
    "data_period_idstd = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['data_period_idstd']\n",
    "recon_period = yml_dict['core']['recon_period']\n",
    "recon_timescale = yml_dict['core']['recon_timescale_interval']\n",
    "recon_period_full = np.arange(recon_period[0],recon_period[1]+1,recon_timescale)\n",
    "recon_period_len = recon_period_full.shape[0]\n",
    "geologic_age = yml_dict['core']['geologic_age']\n",
    "limit_hard_keys = list(yml_dict['prior'][prior_source]['limit_hard'].keys())\n",
    "print('Set limit for {}'.format(limit_hard_keys))\n",
    "\n",
    "nens = yml_dict['core']['nens']\n",
    "save_ens_full = yml_dict['core']['save_ens_full']\n",
    "\n",
    "proxy_err_eval = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_err_eval']\n",
    "# glassy d18O blacklist\n",
    "proxy_d18o_glassy  = yml_dict['proxies']['proxy_d18o_glassy']\n",
    "proxy_assim3 = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_assim3']\n",
    "data_glassy_label_blacklist = proxy_assim3['Marine sediments_d18o_pooled_glassy']\n",
    "# bayspar\n",
    "search_tol_i = yml_dict['psm']['bayesreg_tex86']['search_tol']\n",
    "nens_i = yml_dict['psm']['bayesreg_tex86']['nens']\n",
    "\n",
    "# ========= dataset for plot =========\n",
    "cGENIEGrid = yml_dict['core']['proj_dir'] + '/data_misc/cGENIEGrid.csv'\n",
    "cGENIEGrid = pandas.read_csv(cGENIEGrid)\n",
    "cGENIEGridB_lat36 = cGENIEGrid['lat']\n",
    "cGENIEGridB_lon36 = cGENIEGrid['lon']\n",
    "#print(cGENIEGridB_lat36.shape)\n",
    "cGENIEGrid = cGENIEGrid.to_numpy()\n",
    "print('>>  Load dataset for plot => Okay')\n",
    "\n",
    "# ========= Monte Carlo =========\n",
    "local_rad_list = yml_dict['core']['local_rad_list'] #\n",
    "locRadn= len(local_rad_list)\n",
    "local_rad_list = np.asarray(local_rad_list)\n",
    "#print(local_rad_list)\n",
    "#print(locRadn)\n",
    "proxy_frac_list   = yml_dict['proxies']['proxy_frac']\n",
    "proxy_fracn = len(proxy_frac_list)\n",
    "proxy_frac_list = np.asarray(proxy_frac_list)\n",
    "proxy_order_type = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_order_type']\n",
    "\n",
    "Rscale_list = yml_dict['core']['Rscale']\n",
    "Rscalen = len(Rscale_list)\n",
    "Rscale_list = np.asarray(Rscale_list)\n",
    "\n",
    "#print('dir_prior: {}'.format(dir_prior))\n",
    "print('>>  Prior member size: {}'.format(prior_len))\n",
    "print('>>  Recon_period {} - {}. '.format(recon_period[0], recon_period[1]))\n",
    "print('      List: {}'.format(recon_period_full))\n",
    "print('>>  Proxy error evaluation: {}'.format(proxy_err_eval))\n",
    "print('>>  Proxy full list:')\n",
    "print('      {}'.format(proxy_order))\n",
    "print('>>  Proxy blacklist:')\n",
    "print('      {}'.format(proxy_blacklist))\n",
    "print('>>  Proxy may be assimilated (some may not exist)')\n",
    "print('      {}'.format(proxy_list))\n",
    "print('>>  Proxy quality control selection: {}'.format(proxy_qc))\n",
    "if 'Marine sediments_mgca_pooled_bcp' in proxy_list or 'Marine sediments_mgca_pooled_red' in proxy_list:\n",
    "    data_psm_mgca_find = 1\n",
    "    print('>>    Mg/Ca proxy found ')\n",
    "else:\n",
    "    data_psm_mgca_find = 0\n",
    "print('')\n",
    "print('########## Read prior ######### ')\n",
    "print('')\n",
    "\n",
    "########## Prior #########\n",
    "# save prior variable list\n",
    "prior_variable_dict = []  # variable list\n",
    "prior_nc_file_list = []  # nc file list\n",
    "prior_variable_dict_3d = []  # variable list\n",
    "prior_nc_file_list_3d = []  # nc file list\n",
    "\n",
    "for key, value in prior_state_variable.items():\n",
    "    nc_keyvalue = prior_state_variable[key]['ncname']  # note: 2d or 3d dict\n",
    "    #print('      nc_keyvalue {}...'.format(nc_keyvalue))\n",
    "    for key1, value1 in nc_keyvalue.items():\n",
    "        #print('      {}: {}'.format(key1,value1))\n",
    "        for i in range(len(prior_state_variable[key][value1])):\n",
    "            if key in ['2d']:\n",
    "                prior_variable_dict.append(prior_state_variable[key][value1][i])\n",
    "                prior_nc_file_list.append(key1+'/'+value1+'.nc')\n",
    "            elif key in ['3d']:\n",
    "                prior_variable_dict_3d.append(prior_state_variable[key][value1][i])\n",
    "                prior_nc_file_list_3d.append(key1+'/'+value1+'.nc')\n",
    "\n",
    "# prepare variable list for Xb\n",
    "prior_variable2d_len = len(prior_variable_dict)\n",
    "prior_variable3d_len = len(prior_variable_dict_3d)\n",
    "print('>>  Number of 2d prior variables is: {}.'.format(prior_variable2d_len))\n",
    "if prior_variable2d_len>0:\n",
    "    print('      List:')\n",
    "    for i in range(prior_variable2d_len):\n",
    "        print('        {}/{}'.format(prior_nc_file_list[i], prior_variable_dict[i]))\n",
    "\n",
    "print('>>  Number of 3d prior variables is: {}'.format(prior_variable3d_len))\n",
    "if prior_variable3d_len>0:\n",
    "    print('      List:')\n",
    "    for i in range(prior_variable3d_len):\n",
    "        print('        {}/{}'.format(prior_nc_file_list_3d[i], prior_variable_dict_3d[i]))\n",
    "   \n",
    "# If there is no field in the model, convert model unit to proxy unit\n",
    "print('>>  Reading prior state variables')\n",
    "# read first variable data, first time slice, to get the shape of prior grid\n",
    "try:\n",
    "    #x0 = Dataset(dir_prior+'/'+dir_prior_full[0]+'/'+ nc_file_2d).variables[prior_variable_dict[0]][0,:,:]\n",
    "    x1 = Dataset(dir_prior+'/'+dir_prior_full[0]+'/'+ prior_nc_file_list_3d[0]).variables[prior_variable_dict_3d[0]][0,:,:,:]\n",
    "    #print('    Shape of prior 2d grid {}'.format(x0.shape))\n",
    "    dum_dmax = x1.shape[0] # depth\n",
    "    dum_imax = x1.shape[1]  # lon\n",
    "    dum_jmax = x1.shape[2]  # lat\n",
    "except:\n",
    "    try:\n",
    "        x0 = Dataset(dir_prior+'/'+dir_prior_full[0]+'/'+ prior_nc_file_list[0]).variables[prior_variable_dict[0]][0,:,:]\n",
    "        dum_imax = 36 #x1.shape[0]  # lon\n",
    "        dum_jmax = 36 #x1.shape[1]  # lat\n",
    "        dum_dmax = 16\n",
    "    except:\n",
    "        dum_dmax = 16\n",
    "        dum_imax = 36\n",
    "        dum_jmax = 36\n",
    "# prepare 2d Xb for lon-lat state \n",
    "dum_ijmax = dum_imax*dum_jmax  # lonn * latn\n",
    "print('>>  Shape of dum_dmax {}, dum_imax {}, dum_jmax {}, dum_ijmax {}'.format(dum_dmax,dum_imax,dum_jmax,dum_ijmax))\n",
    "# save units of each variable\n",
    "prior_variable_units = list()\n",
    "prior_variable_units_init = 0\n",
    "\n",
    "# nan matrix for storing 2d and 3d variables\n",
    "if prior_variable2d_len>0:\n",
    "    Xb_shape = (prior_variable2d_len*dum_jmax*dum_imax, prior_len)  # lonn * latn * varn\n",
    "    Xb   = np.full(Xb_shape,np.nan)\n",
    "# prep 3d version of Xb\n",
    "if prior_variable3d_len > 0:\n",
    "    Xb3d_shape = (prior_variable3d_len*dum_dmax*dum_jmax*dum_imax, prior_len)  # lonn * latn * varn\n",
    "    Xb3d = np.full(Xb3d_shape,np.nan)\n",
    "    # read prior and save Xb\n",
    "    #Xb = np.full((dum_ijmax, prior_len),np.nan)\n",
    "print('>>  Reading prior ...')\n",
    "if data_psm_mgca_find == 1:\n",
    "    #print('>>  Prepare Mg/Ca related state variable ...')\n",
    "    # for Mg/Ca SST proxy salinity, ph, omega\n",
    "    Xb_sal       = np.full(Xb_shape,np.nan)\n",
    "    Xb_ph        = np.full(Xb_shape,np.nan)\n",
    "    Xb_omega     = np.full(Xb_shape,np.nan)\n",
    "    spp = 'all'\n",
    "    # ``1`` for reductive, ``0`` for BCP (Barker).\n",
    "    cleaningr = np.tile(np.array([1]),prior_len)\n",
    "    cleaningb = np.tile(np.array([0]),prior_len)\n",
    "# read units of each variable from prior and save as prior_variable_units\n",
    "if prior_variable2d_len > 0:\n",
    "    for j in range(prior_variable2d_len):\n",
    "        name_nc_2d = dir_prior+'/'+dir_prior_full[0]+'/'+ prior_nc_file_list[j]\n",
    "        nc_field = prior_variable_dict[j]\n",
    "        try:\n",
    "            unit_j = Dataset(name_nc_2d).variables[nc_field].units\n",
    "        except:\n",
    "            unit_j ='unit'\n",
    "        prior_variable_units.append((unit_j))\n",
    "if prior_variable3d_len > 0:\n",
    "    for j in range(prior_variable3d_len):\n",
    "        name_nc_3d = dir_prior+'/'+dir_prior_full[0]+'/'+ prior_nc_file_list_3d[j]\n",
    "        nc_field = prior_variable_dict_3d[j]\n",
    "        try:\n",
    "            try:\n",
    "                unit_j = Dataset(name_nc_3d).variables[nc_field].units\n",
    "            except:\n",
    "                unit_j ='unit'\n",
    "            prior_variable_units.append((unit_j))\n",
    "        except:\n",
    "            prior_variable_units.append((''))\n",
    "    \n",
    "# loop for each member of an ensemble\n",
    "for i in range(prior_len):\n",
    "    # loop for each variable of each member\n",
    "    if data_psm_mgca_find == 1:\n",
    "        water_saturation = yml_dict['psm']['bayesreg_mgca_pooled_red']['water_saturation']\n",
    "        water_saturation_field = yml_dict['psm']['bayesreg_mgca_pooled_red']['water_saturation_field']\n",
    "        psm_required_nc = yml_dict['psm']['bayesreg_mgca_pooled_red']['psm_required_nc']\n",
    "        psm_required_nc_mg = yml_dict['psm']['bayesreg_mgca_pooled_red']['psm_required_nc_mg']\n",
    "        name_nc_2d = dir_prior+'/'+dir_prior_full[i]+psm_required_nc\n",
    "        name_nc_2d_mgca = dir_prior+'/'+dir_prior_full[i]+psm_required_nc_mg\n",
    "        \n",
    "        x00 = Dataset(name_nc_2d).variables['ocn_sur_sal'][t,:,:] # time-lat-lon\n",
    "        x01 = Dataset(name_nc_2d).variables['misc_pH'][t,:,:] # time-lat-lon | core top pH\n",
    "        \n",
    "        if water_saturation in ['surface']:\n",
    "            x02 = Dataset(name_nc_2d_mgca).variables[water_saturation_field][t,:,:] # time-lat-lon  | surface water ohmega calcite\n",
    "        if water_saturation in ['bottom']:\n",
    "            x02 = Dataset(name_nc_2d_mgca).variables[water_saturation_field][t,:,:]\n",
    "            \n",
    "    if prior_variable2d_len > 0:\n",
    "        for j in range(prior_variable2d_len):\n",
    "            # full directory of netcdf file\n",
    "            name_nc_2d = dir_prior+'/'+dir_prior_full[i]+'/'+ prior_nc_file_list[j]\n",
    "            j0 = dum_ijmax * j\n",
    "            j1 = dum_ijmax * (j+1)\n",
    "            nc_field = prior_variable_dict[j]\n",
    "            x = Dataset(name_nc_2d).variables[nc_field][t,:,:]  # time-lat-lon\n",
    "            # pCO2 from 1 to ppm\n",
    "            if nc_field in ['atm_pCO2']:\n",
    "                x = x * 1.0e+06\n",
    "            Xb[j0:j1,i] = np.copy(x.reshape(dum_ijmax))  # var-lat-lon: Nx x 1\n",
    "            \n",
    "            if data_psm_mgca_find == 1:\n",
    "                try:\n",
    "                    Xb_sal[j0:j1,i] = np.copy(x00.reshape(dum_ijmax)) # var-lat-lon: Nx x 1  | surface water salinity\n",
    "                    Xb_ph[j0:j1,i] = np.copy(x01.reshape(dum_ijmax)) # var-lat-lon: Nx x 1\n",
    "                    Xb_omega[j0:j1,i] = np.copy(x02.reshape(dum_ijmax)) # var-lat-lon: Nx x 1\n",
    "                except:\n",
    "                    if i == 0:\n",
    "                        # warning one time\n",
    "                        print('>>  Warning: reading state variable error. ocn_sur_sal, misc_pH, carb_ohm_cal')\n",
    "            # print the last one data\n",
    "            if i > prior_len-2:\n",
    "                print('    Last member: {}: {}: {}'.format(i, dir_prior_full[i], prior_variable_dict[j]))\n",
    "        Xb = np.ma.MaskedArray(Xb, Xb >= 9.9692e+36)\n",
    "    # if 3d variables are used\n",
    "    if prior_variable3d_len > 0:\n",
    "        for k in range(prior_variable3d_len):\n",
    "            name_nc_3d = dir_prior+'/'+dir_prior_full[i]+'/'+ prior_nc_file_list_3d[k]\n",
    "            nc_field = prior_variable_dict_3d[k]\n",
    "            k0 = dum_ijmax*dum_dmax * k\n",
    "            k1 = dum_ijmax*dum_dmax * (k+1)\n",
    "            x = Dataset(name_nc_3d).variables[nc_field][t,:,:,:]  # time-depth-lat-lon\n",
    "            Xb3d[k0:k1,i] = np.copy(x.reshape(dum_dmax*dum_ijmax)) # var-depth-lat-lon\n",
    "        Xb3d = np.ma.MaskedArray(Xb3d, Xb3d >= 9.9692e+36)\n",
    "\n",
    "print('>>  Units of state variables {}: {}'.format(prior_variable_dict+prior_variable_dict_3d,prior_variable_units))\n",
    "\n",
    "Xb_prior = np.copy(Xb)\n",
    "if prior_variable3d_len > 0:\n",
    "    Xb3d_prior = np.copy(Xb3d)\n",
    "\n",
    "if data_psm_mgca_find == 1:\n",
    "    print('>>  Prepare Mg/Ca related state variable ...')\n",
    "    # for Mg/Ca SST proxy salinity, ph, omega\n",
    "    Xb_sal_prior       = np.copy(Xb_sal)\n",
    "    Xb_ph_prior        = np.copy(Xb_ph)\n",
    "    Xb_omega_prior     = np.copy(Xb_omega)\n",
    "    # ``1`` for reductive, ``0`` for BCP (Barker).\n",
    "    cleaningr_prior = np.copy(cleaningr)\n",
    "    cleaningb_prior = np.copy(cleaningb)\n",
    "    \n",
    "print('>>  Reading Prior => Okay')\n",
    "print('')\n",
    "print(' ########## Read proxies database ########## ')\n",
    "print('')\n",
    "### read proxies database ###\n",
    "proxies = pandas.read_csv(dir_proxy_data)\n",
    "proxies_len0 = len(proxies)\n",
    "#proxy_select = pandas.DataFrame()\n",
    "#print(proxy_select)\n",
    "proxy_select_0 = 0\n",
    "### check proxy data in the blacklist or not ###\n",
    "for j in range(proxies_len0):\n",
    "    # Read proxy type from the database\n",
    "    data_psm_type = proxies['Proxy'][j]\n",
    "    # initial default 0 : this proxy is not included\n",
    "    data_assimilate_i = 0\n",
    "    for jlist in range(len(proxy_list)):\n",
    "        if data_psm_type in proxy_assim2[proxy_list[jlist]]:\n",
    "            # find and save this proxy\n",
    "            data_assimilate_i = 1\n",
    "    if data_assimilate_i == 1:\n",
    "        #print('>>    file {}, {} included'.format(proxies.loc[j,'File'], data_psm_type))\n",
    "        if proxy_select_0 == 0:\n",
    "            proxy_select0 = proxies.iloc[[j]]\n",
    "            proxy_select0 = proxy_select0.reset_index(drop=True) # reset_index, avoid index error\n",
    "            proxy_select_0 = 1\n",
    "        else:\n",
    "            #proxy_select.append(proxies.iloc[[j]])\n",
    "            proxy_select0 = proxy_select0.append(proxies.iloc[[j]], ignore_index=True)\n",
    "proxies_select_len0 = len(proxy_select0)\n",
    "print('>>  Proxy: selected proxy dataset number {}: remove those in blacklist'.format(proxies_select_len0))\n",
    "\n",
    "### check glassy only data or not\n",
    "proxy_select_0 = 0\n",
    "if proxy_d18o_glassy:\n",
    "    for jj in range(proxies_select_len0):\n",
    "        data_glassy_label = proxy_select0['Glassy'][jj]\n",
    "        if data_glassy_label not in data_glassy_label_blacklist:\n",
    "            if proxy_select_0 == 0:\n",
    "                proxy_select = proxy_select0.iloc[[jj]]\n",
    "                proxy_select = proxy_select.reset_index(drop=True) # reset_index, avoid index error\n",
    "                proxy_select_0 = 1\n",
    "            else:\n",
    "                proxy_select = proxy_select.append(proxy_select0.iloc[[jj]], ignore_index=True)\n",
    "\n",
    "    #print(proxy_select)\n",
    "    proxies_select_len0 = len(proxy_select)\n",
    "    print('>>  Proxy: selected proxy dataset number {}: remove those unknown/frosty'.format(proxies_select_len0))\n",
    "else:\n",
    "    proxy_select = proxy_select0.copy()\n",
    "    \n",
    "#######     ########     #######     ########     #######     ########     #######     ######## \n",
    "#######                  OKAY, setting read, now let's DA                              ######## \n",
    "#######     ########     #######     ########     #######     ########     #######     ######## \n",
    "\n",
    "for locRadi in range(locRadn):\n",
    "    locRad = local_rad_list[locRadi]\n",
    "    print('>>  Localization id {} radius distance {} km'.format(locRadi, locRad))\n",
    "    if locRad is None:\n",
    "        locRadv = 0 # for filename only\n",
    "    else:\n",
    "        locRadv = locRad\n",
    "    for proxy_fraci in range(proxy_fracn):\n",
    "        proxy_frac = proxy_frac_list[proxy_fraci]\n",
    "        \n",
    "        for Rscalei in range(Rscalen):\n",
    "            Rscale = Rscale_list[Rscalei]\n",
    "            #######     ########     #######     ########     #######     ########     #######     ########     \n",
    "            print('>>  Starting Monte Carlo ... ')\n",
    "            #######     ########     #######     ########     #######     ########     #######     ########\n",
    "            for MCi in range(MCn):\n",
    "                # copy back:\n",
    "                Xb = np.copy(Xb_prior)\n",
    "                if prior_variable3d_len > 0:\n",
    "                    Xb3d = np.copy(Xb3d_prior)\n",
    "                if data_psm_mgca_find == 1:\n",
    "                    Xb_sal       = np.copy(Xb_sal_prior)\n",
    "                    Xb_ph        = np.copy(Xb_ph_prior)\n",
    "                    Xb_omega     = np.copy(Xb_omega_prior)\n",
    "                    # ``1`` for reductive, ``0`` for BCP (Barker).\n",
    "                    cleaningr = np.copy(cleaningr_prior)\n",
    "                    cleaningb = np.copy(cleaningb_prior)\n",
    "                \n",
    "                ### Select a fraction of proxy sites ###\n",
    "                if proxy_frac <= 1.0:\n",
    "                    print('>>  Proxy fraction is {}'.format(proxy_frac))\n",
    "                    ## Seed\n",
    "                    curr_seed = multi_seed[MCi]\n",
    "                    print('Setting current prior iteration seed: {}'.format(curr_seed))\n",
    "                    random.seed(curr_seed)\n",
    "                    sites_assim, sites_eval = DeepDA_psm.proxy_frac_4da_eval(proxy_select,proxy_frac)\n",
    "                else:\n",
    "                    sites_assim = proxy_select.copy()\n",
    "                    sites_eval = []\n",
    "                ###\n",
    "                #print('>>  Randomly selected proxy sties: ')\n",
    "                #print(sites_assim)\n",
    "                #print('>>  Randomly un-selected proxy sties: ')\n",
    "                #print(sites_eval)                \n",
    "                \n",
    "                ### sort proxy data using the given order ###\n",
    "                proxies_frac_len = len(sites_assim)\n",
    "                proxy_select_1 = 0\n",
    "                #print(proxy_select)\n",
    "                if proxy_order_type in ['use_list']:\n",
    "                    for i in range(len(proxy_order)):\n",
    "                        proxy_order_i = proxy_assim2[proxy_order[i]]\n",
    "                        for j in range(proxies_frac_len):\n",
    "                            # Read proxy type from the database\n",
    "                            data_psm_type = sites_assim['Proxy'][j]\n",
    "                            if data_psm_type in proxy_order_i:\n",
    "                                if proxy_select_1 == 0:\n",
    "                                    # first element\n",
    "                                    #proxy_select_sort = proxy_select.iloc[[j]]\n",
    "                                    proxy_select_sort = sites_assim.iloc[[j]]\n",
    "                                    proxy_select_1 = 1  # proxy included\n",
    "                                else:\n",
    "                                    # rest elements\n",
    "                                    proxy_select_sort = proxy_select_sort.append(sites_assim.iloc[[j]], ignore_index=True)\n",
    "                    print('>>  Proxy order: use list')\n",
    "                else:\n",
    "                    proxy_select_sort = sites_assim.sample(frac=1).reset_index(drop=True);\n",
    "                    print('>>  Proxy order: all random.')\n",
    "                \n",
    "                ### update proxies using sorted proxy order ###\n",
    "                proxies =   proxy_select_sort.copy()\n",
    "                proxies_len = len(proxies)\n",
    "\n",
    "                if proxies_len0 > proxies_len:\n",
    "                    print('>>  Selected proxy data length {}'.format(proxies_len))\n",
    "\n",
    "                ######## Ye   ########\n",
    "                # for saving proxy unit data Ye\n",
    "                Ye       = np.full((proxies_len,prior_len),np.nan)\n",
    "                obvalue  = np.full((proxies_len,recon_period_len),np.nan)\n",
    "                ob_err   = np.full((proxies_len,recon_period_len),np.nan) # data obs error\n",
    "                ob_err0  = np.full((proxies_len,recon_period_len),np.nan) # PSM obs error\n",
    "                ob_err_comb  = np.full((proxies_len,recon_period_len),np.nan) # PSM obs error\n",
    "                yo_all = np.full((proxies_len,2),np.nan) # PSM obs error\n",
    "                print('>>  OKAY.')\n",
    "                print('')\n",
    "                # check the consistency of the config.yml file and proxy database\n",
    "                # AND get obs R\n",
    "                print('########## Check the consistency of the config.yml file and proxy database ##########')\n",
    "                print('')\n",
    "                \n",
    "                proxy_psm_type_dict = {}\n",
    "                for j in range(proxies_len):\n",
    "                    # Read proxy type from the database\n",
    "                    data_psm_type = proxies['Proxy'][j]\n",
    "                    # Read allowed proxy from the DTDA-config.yml\n",
    "                    data_psm_type_find = 0\n",
    "                    for key, value in proxy_assim2.items():\n",
    "                        #print(key,value)\n",
    "                        # check this proxy type exist or not, and how many times it occurrs\n",
    "                        if data_psm_type in proxy_assim2[key]:\n",
    "                            data_psm_type_find = data_psm_type_find + 1\n",
    "                    if data_psm_type_find == 1:\n",
    "                        for key, value in proxy_psm_type.items():\n",
    "                            if data_psm_type in proxy_assim2[key]:\n",
    "                                data_psm_key = key\n",
    "                        proxy_psm_type_i = proxy_psm_type[data_psm_key]\n",
    "\n",
    "                        proxy_psm_type_dict[j] =proxy_psm_type_i\n",
    "\n",
    "                        #print('>>  {}. PSM for {} is {}'.format(j, data_psm_type,proxy_psm_type_i))\n",
    "\n",
    "                    elif data_psm_type_find == 0:\n",
    "                        print('>>  Warning, {} in database is not find in DTDA-config.yml dictionary'.format(data_psm_type))\n",
    "                    else:\n",
    "                        print('>>  Warning, {} in database appears more than 1 time in DTDA-config.yml dictionary'.format(data_psm_type))\n",
    "\n",
    "                    # Now PSM type has been found. Let's precal Ye\n",
    "\n",
    "                    if proxy_psm_type_i in ['bayesreg_mgca_pooled_red','bayesreg_mgca_pooled_bcp']:\n",
    "                        data_psm_mgca_find = 1\n",
    "\n",
    "                #print('>>  Proxy_psm_type_dict: ')\n",
    "                #print(proxy_psm_type_dict)\n",
    "                print('')\n",
    "                print('>>  All looks good.')\n",
    "                print('')\n",
    "                \n",
    "                ##### Ye calculation ####\n",
    "                \n",
    "                print('##########  Ye calculation  ##########')\n",
    "                print('')\n",
    "                # precal_Ye\n",
    "                proi = 0\n",
    "                for j in range(proxies_len):\n",
    "                    # Read proxy type from the database\n",
    "                    data_psm_type = proxies['Proxy'][j]\n",
    "                    proxy_psm_type_i = proxy_psm_type_dict[j]\n",
    "                    psm_required_variable_key = list(yml_dict['psm'][proxy_psm_type_i]['psm_required_variables'].keys())[0]\n",
    "                    #print(psm_required_variable_key)\n",
    "                    # ID-ID match: proxy type matches with the prior type. This allows assimilate multiple proxy types for multiple state variables\n",
    "                    if psm_required_variable_key in prior_variable_dict:\n",
    "                        psm_required_variable_key_index = prior_variable_dict.index(psm_required_variable_key)\n",
    "                    elif psm_required_variable_key in prior_variable_dict_3d:\n",
    "                        psm_required_variable_key_index = prior_variable_dict_3d.index(psm_required_variable_key)\n",
    "\n",
    "                ######################## FOR 2D field ONLY TO DO: adjusted to include 3d proxies ##############\n",
    "                \n",
    "                    # read lon lat for each line of proxy\n",
    "                    dum_lat = proxies[lat_label][j]  # (paleo)latitude of this site\n",
    "                    dum_lon = proxies[lon_label][j]  # (paleo)longitude of this site\n",
    "                    yo_all[proi,:] = np.array([dum_lon, dum_lat])  # save location of this site\n",
    "\n",
    "                    lonlat = modules_nc.cal_find_ij(dum_lon,dum_lat,dum_lon_offset,dum_imax,dum_jmax)\n",
    "                    # output [lon, lat], \n",
    "                    # lon ranges from 0 (-180) to 35 (180), lat ranges from 0 (-90) to 35 (90)\n",
    "\n",
    "                    Filei = proxies['File'][j]\n",
    "                    # find 1d grid location\n",
    "                    lonlati = lonlat[1] * dum_jmax + lonlat[0] + psm_required_variable_key_index * dum_ijmax\n",
    "                    #print('>>  lonlat id is {}'.format(lonlati))\n",
    "                    # read prior\n",
    "                    prior_1grid = np.copy(Xb[lonlati,:])   # prior\n",
    "                    #print(prior_1grid.shape)\n",
    "                    #print(prior_1grid)\n",
    "                    \n",
    "                ######################## FOR 2D field ONLY. TO DO: adjusted to include 3d proxies ##############\n",
    "                    #print('')\n",
    "                    print('>>  {}. File: {}, grid [lon lat] {}, index {}, PSM for {} is {}'.format(j,Filei,lonlat,lonlati,data_psm_type,proxy_psm_type_i))\n",
    "                    #if psm_required_variable_key in prior_variable_dict:                     \n",
    "                    #    print('>>    Key Found: {} in prior_variable_dict 2d list, index = {}'.format(psm_required_variable_key, psm_required_variable_key_index))\n",
    "                    #elif psm_required_variable_key in prior_variable_dict_3d:\n",
    "                    #    print('>>    Key Found: {} in prior_variable_dict_3d list, index = {}'.format(psm_required_variable_key, psm_required_variable_key_index))\n",
    "                        \n",
    "                    #print('>>      Mean of Prior is {:.6f}, variance is {:.6f}'.format(np.mean(prior_1grid), np.var(prior_1grid)))\n",
    "\n",
    "                    # Now PSM type has been found. Let's precal Ye\n",
    "\n",
    "                    if proxy_psm_type_i in ['bayesreg_d18o_pooled']:\n",
    "                        if d18osw_local_choice in ['zachos94']:\n",
    "                            # d18o_localsw using method by Zachos et al., 1994 PALEOCEANOGRAPHY\n",
    "                            d18o_localsw = DeepDA_psm.d18o_localsw(abs(dum_lat))\n",
    "                        else:\n",
    "                            if d18osw_icesm_pco2 == 1.0:\n",
    "                                proxy_col_d18osw = 'd18osw_1x'\n",
    "                            elif d18osw_icesm_pco2 == 3.0:\n",
    "                                proxy_col_d18osw = 'd18osw_3x'\n",
    "                            elif d18osw_icesm_pco2 == 6.0:\n",
    "                                proxy_col_d18osw = 'd18osw_6x'\n",
    "                            elif d18osw_icesm_pco2 == 9.0:\n",
    "                                proxy_col_d18osw = 'd18osw_9x'\n",
    "                            else:\n",
    "                                proxy_col_d18osw = 'd18osw_3x'\n",
    "                            d18o_localsw = proxies[proxy_col_d18osw][j]\n",
    "                            \n",
    "                        # total d18osw = d18o_localsw + d18o_adj + psm_d18osw_adjust\n",
    "                        # d18o_adj has been included in the bayfox model\n",
    "                        #print('>>  Prior is {}'.format(prior_1grid))\n",
    "                        if d18osw_local_choice in ['zachos94']:\n",
    "                            prediction_d18O = bayfox.predict_d18oc(prior_1grid,d18o_localsw + psm_d18osw_adjust) # pool model for bayfox\n",
    "                            #print('>>        Sea water d18O is {:.6f}, d18osw_adjust is {:.6f} '.format(d18o_localsw, psm_d18osw_adjust))\n",
    "                        else:\n",
    "                            prediction_d18O = bayfox.predict_d18oc(prior_1grid,d18o_localsw) # pool model for bayfox\n",
    "                            #print('>>        Sea water d18O is {:.6f}'.format(d18o_localsw))\n",
    "                        #print('>>  prediction_d18O.ensemble shape {}'.format(prediction_d18O.ensemble.shape))\n",
    "                        \n",
    "                        Ye[proi,:] = np.mean(prediction_d18O.ensemble, axis = 1)\n",
    "                        #print('>>  Ye is {}'.format(Ye[proi,:]))\n",
    "                        #print('>>      Mean of  Ye  is {:.6f}, variance is {:.6f} '.format(np.mean(Ye[proi,:]), np.var(Ye[proi,:],ddof=1)))\n",
    "                        for reconi in range(recon_period_len):\n",
    "                            reconid = recon_period_full[reconi]\n",
    "                            obvalue[proi,reconi] = proxies[data_period_id[reconid]][j]\n",
    "                            ob_err[proi,reconi] = proxies[data_period_idstd[reconid]][j] ** 2\n",
    "                            if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                if d18osw_local_choice in ['zachos94']:\n",
    "                                    ob_err0[proi,reconi]= DeepDA_psm.obs_estimate_r_d18o(obvalue[proi,reconi], d18o_localsw+psm_d18osw_adjust) * Rscale\n",
    "                                else:\n",
    "                                    ob_err0[proi,reconi]= DeepDA_psm.obs_estimate_r_d18o(obvalue[proi,reconi], d18o_localsw) * Rscale\n",
    "                            else:\n",
    "                                ob_err0[proi,reconi]= DeepDA_psm.obs_estimate_r_fixed_d18o(15) * Rscale\n",
    "                            ob_err_comb[proi,reconi] = np.nansum([ob_err[proi,reconi], ob_err0[proi,reconi]])\n",
    "                            if ob_err_comb[proi,reconi] == 0: ob_err_comb[proi,reconi] = np.nan\n",
    "                            #print('>>   {}. Proxy variance from PSM is {:.6f} vs. from PSM + time variance is {:.6f} '.format(reconi,ob_err0[proi,reconi], ob_err_comb[proi,reconi]))\n",
    "\n",
    "                            # Quality control\n",
    "                            #if proxy_qc is not None:\n",
    "                                #print('>>   Quality Control (QC) ...')\n",
    "                            if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc)\n",
    "                            else:\n",
    "                                qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err0[proi,reconi], proxy_qc)\n",
    "                            #print(qc_i)\n",
    "                            if qc_i:\n",
    "                                if proxy_qc is not None:\n",
    "                                    print('    Pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "                            else:\n",
    "                                ob_err_comb[proi,reconi] = np.nan\n",
    "                                if proxy_qc is not None:                    \n",
    "                                    print('    Failed QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "                        proi = proi + 1  # increasement\n",
    "                        #except:\n",
    "                        #    print('>>  Warning {}'.format(proxy_psm_type_i))\n",
    "                    elif proxy_psm_type_i in ['cgenie_caco3', 'cgenie_caco3_13c']:\n",
    "                        Ye[proi,:] = np.mean(prior_1grid)\n",
    "                        for reconi in range(recon_period_len):\n",
    "                            reconid = recon_period_full[reconi]\n",
    "                            obvalue[proi,reconi] = proxies[data_period_id[reconid]][j]\n",
    "                            ob_err[proi,reconi] = proxies[data_period_idstd[reconid]][j] ** 2\n",
    "                            ob_err0[proi,reconi] = yml_dict['psm'][proxy_psm_type_i]['psm_error']\n",
    "                            ob_err_comb[proi,reconi] = np.nansum([ob_err[proi,reconi], ob_err0[proi,reconi]])\n",
    "                            # Quality control\n",
    "                            if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc)\n",
    "                            else:\n",
    "                                qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err0[proi,reconi], proxy_qc)\n",
    "                            if qc_i:\n",
    "                                if proxy_qc is not None:\n",
    "                                    print('    Pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "                            else:\n",
    "                                ob_err_comb[proi,reconi] = np.nan\n",
    "                                if proxy_qc is not None:                    \n",
    "                                    print('    Failed QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "                        proi = proi + 1  # increasement\n",
    "                        \n",
    "                    elif proxy_psm_type_i in ['bayesreg_tex86']:\n",
    "                        # bayspar\n",
    "                        #try:\n",
    "                        prediction = bayspar.predict_tex_analog(prior_1grid, temptype = 'sst', search_tol = search_tol_i, nens=nens_i)\n",
    "                        Ye[proi,:] = np.mean(prediction.ensemble, axis = 1)\n",
    "                        #print('>>      Mean of  Ye   is {:.6f}, variance is {:.6f} '.format(np.mean(Ye[proi,:]), np.var(Ye[proi,:],ddof=1)))\n",
    "                        for reconi in range(recon_period_len):\n",
    "                            reconid = recon_period_full[reconi]\n",
    "                            obvalue[proi,reconi] = proxies[data_period_id[reconid]][j]\n",
    "                            ob_err[proi,reconi] = proxies[data_period_idstd[reconid]][j] ** 2\n",
    "                            if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                ob_err0[proi,reconi]= DeepDA_psm.obs_estimate_r_tex86(np.array([31]), 'sst', 15)  * Rscale\n",
    "                            else:\n",
    "                                ob_err0[proi,reconi]= DeepDA_psm.obs_estimate_r_fixed_tex86(31)  * Rscale\n",
    "                            #obvalue[proi,] = proxies['Lat'][j]\n",
    "                            ob_err_comb[proi,reconi] = np.nansum([ob_err[proi,reconi], ob_err0[proi,reconi]])\n",
    "                            if ob_err_comb[proi,reconi] == 0: ob_err_comb[proi,reconi] = np.nan\n",
    "                            #print('>>   {}. Proxy variance from PSM is {:.6f}, from PSM and selected interval is {:.6f} '.format(reconi,ob_err0[proi,reconi], ob_err_comb[proi,reconi]))\n",
    "                            # Quality control\n",
    "                            if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc)\n",
    "                            else:\n",
    "                                qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err0[proi,reconi], proxy_qc)\n",
    "                            if qc_i:\n",
    "                                if proxy_qc is not None:\n",
    "                                    print('    Pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "                            else:\n",
    "                                ob_err_comb[proi,reconi] = np.nan\n",
    "                                if proxy_qc is not None:                    \n",
    "                                    print('    Failed QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "                        proi = proi + 1  # increasement\n",
    "                        #except:\n",
    "                        #    print('>>  Warning {}'.format(proxy_psm_type_i))\n",
    "                        #    print('>>  search_tol too small for {}: mean sst is {}'.format(j, np.mean(prior_1grid)))\n",
    "\n",
    "                    #elif proxy_psm_type_i in ['bayesreg_uk37']:\n",
    "                        # \n",
    "                        #print('... bayesreg_uk37: To be done ...')\n",
    "\n",
    "                    elif proxy_psm_type_i in ['bayesreg_mgca_pooled_red', 'bayesreg_mgca_pooled_bcp']:\n",
    "                        if proxy_psm_type_i in ['bayesreg_mgca_pooled_red']:\n",
    "                            clearning_one = cleaningr\n",
    "                            proxy_explain = 'reductive'\n",
    "                        elif proxy_psm_type_i in ['bayesreg_mgca_pooled_bcp']:\n",
    "                            clearning_one = cleaningb\n",
    "                            proxy_explain = 'barker'\n",
    "                        #try:\n",
    "                        # prior_1grid = np.copy(Xb[lonlati,:])   # prior\n",
    "                        salinity =  np.copy(Xb_sal[lonlati,:])\n",
    "                        ph       =  np.copy(Xb_ph[lonlati,:])\n",
    "                        omega    =  np.copy(Xb_omega[lonlati,:])\n",
    "\n",
    "                        Xb_sal1 = np.copy(Xb_sal)\n",
    "                        Xb_sal1[Xb_sal1> 3.0e+36] = np.nan\n",
    "                        Xb_sal_mean = np.nanmean(Xb_sal1)\n",
    "                        Xb_ph1 = np.copy(Xb_ph)\n",
    "                        Xb_ph1[Xb_ph1> 3.0e+36] = np.nan\n",
    "                        Xb_ph_mean = np.nanmean(Xb_ph1)\n",
    "                        Xb_omega1 = np.copy(Xb_omega)\n",
    "                        Xb_omega1[Xb_omega1> 3.0e+36] = np.nan\n",
    "                        Xb_omega_mean = np.nanmean(Xb_omega1)\n",
    "                        print('>>    mean of Xb_sal {}, Xb_ph {}, Xb_omega {}, cleaning {}'.format(Xb_sal_mean, Xb_ph_mean, Xb_omega_mean, clearning_one[0]))\n",
    "                        prediction_mgca = baymag.predict_mgca(prior_1grid, clearning_one, salinity, ph, omega, spp) # pool model for baymag reductive\n",
    "                        #prediction_mgca = baymag.predict_mgca(prior_1grid, cleaningr, salinity, ph, omega, spp) # pool model for baymag reductive\n",
    "                        pred_mgca_adj = baymag.sw_correction(prediction_mgca, np.array([geologic_age]))\n",
    "                        Ye[proi,:] = np.mean(pred_mgca_adj.ensemble, axis = 1)\n",
    "                        #print('>>      Mean of  Ye   is {:.6f}, variance is {:.6f} '.format(np.mean(Ye[proi,:]), np.var(Ye[proi,:],ddof=1)))\n",
    "\n",
    "                        for reconi in range(recon_period_len):\n",
    "                            reconid = recon_period_full[reconi]\n",
    "                            obvalue[proi,reconi] = proxies[data_period_id[reconid]][j]\n",
    "                            ob_err[proi,reconi]  = proxies[data_period_idstd[reconid]][j] ** 2\n",
    "                            #obs_estimate_r_mgca_pooled(obs, cleaning, salinity, ph, omega, spp, age):\n",
    "                            if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                ob_err0[proi,reconi] = DeepDA_psm.obs_estimate_r_mgca_pooled(obvalue[proi,reconi], clearning_one[0], np.mean(salinity), np.mean(ph), np.mean(omega), spp, geologic_age) * Rscale\n",
    "                            else:\n",
    "                                #ob_err0[proi,reconi] = DeepDA_psm.obs_estimate_r_fixed_mgca_pooled((15, 16), clearning_one[0], np.mean(salinity), np.mean(ph), np.mean(omega), spp, geologic_age)\n",
    "                                ob_err0[proi,reconi] = DeepDA_psm.obs_estimate_r_fixed_mgca_pooled((15, 16), clearning_one[0], Xb_sal_mean, Xb_ph_mean, Xb_omega_mean, spp, geologic_age) * Rscale\n",
    "                            ob_err_comb[proi,reconi] = np.nansum([ob_err[proi,reconi], ob_err0[proi,reconi]])\n",
    "                            if ob_err_comb[proi,reconi] == 0: ob_err_comb[proi,reconi] = np.nan\n",
    "                            #print('>>   {}. Proxy variance from PSM is {:.6f}, from PSM and selected interval is {:.6f} '.format(reconi,ob_err0[proi,reconi], ob_err_comb[proi,reconi]))\n",
    "                            # Quality control\n",
    "                            if proxy_err_eval in ['proxy_err_psm']:\n",
    "                                qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc)\n",
    "                            else:\n",
    "                                qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err0[proi,reconi], proxy_qc)\n",
    "                            if qc_i:\n",
    "                                if proxy_qc is not None:\n",
    "                                    print('      Pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "                            else:\n",
    "                                ob_err_comb[proi,reconi] = np.nan\n",
    "                                if proxy_qc is not None:                    \n",
    "                                    print('      Failed QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "                            #print('        {}: mean salinity {}, ph {}, omega {}'.format(proxy_explain,np.mean(salinity), np.mean(ph), np.mean(omega)))\n",
    "                        proi = proi + 1  # increasement\n",
    "\n",
    "                    else:\n",
    "                        a = 1\n",
    "\n",
    "                print('')\n",
    "                print('>>  Summary of this Monte Carlo simulation')\n",
    "                #print('')\n",
    "                #print('>>  Ye mean')\n",
    "                Ye_mean_print = (np.mean(Ye,axis=1))[np.newaxis]\n",
    "                #print('>>  {}'.format(Ye_mean_print.T))\n",
    "                #print('>>  Observation value')\n",
    "                #print('>>  {}'.format(obvalue))\n",
    "                #print('>>  Observation error (ob_err0)')\n",
    "                #print('>>  {}'.format(ob_err0))\n",
    "                #print('>>  Observation error (ob_err_comb, from PSM and time-variance)')\n",
    "                #print('>>  {}'.format( ob_err_comb))\n",
    "                print('[Ye, Ob_value]')\n",
    "                Yeobvalue = np.concatenate((Ye_mean_print.T, obvalue), axis=1)\n",
    "                print('>>  {}'.format(Yeobvalue))\n",
    "                print('##########  Monte Carlo {} / {} => Okay   ##########'.format(MCi+1, MCn))\n",
    "                print('')\n",
    "\n",
    "                MC_dir = dir_proxy_save_dir + dir_proxy_save + nexp +'/'\n",
    "                \n",
    "                if not os.path.exists(MC_dir):\n",
    "                    os.makedirs(MC_dir)\n",
    "                # NetCDF file name\n",
    "                filename_short = '_loc_', str(locRadv),'_proxy_frac_', str(proxy_frac),'_Rscale_',str(Rscale),'_MC_' + str(MCi) \n",
    "                nc_filename = MC_dir + ''.join(filename_short) + '.nc'\n",
    "                hdf5name    = MC_dir + ''.join(filename_short) + '.hdf5'\n",
    "                #hdf5name_short    = '_loc_', str(locRadv),'_proxy_frac_', str(proxy_frac),'_Rscale_',str(Rscale),'_MC_' + str(MCi) +'.hdf5'\n",
    "                proxy_psm_type_dict_df = pandas.DataFrame.from_dict(proxy_psm_type_dict, orient='index')\n",
    "\n",
    "                with h5py.File(hdf5name, 'w') as f:\n",
    "                    # if any 2d field selected\n",
    "                    if prior_variable2d_len > 0:\n",
    "                        f.create_dataset('Xb', data=Xb)\n",
    "                    f.create_dataset('obvalue', data=obvalue)\n",
    "                    f.create_dataset('Ye', data=np.transpose(Ye))\n",
    "                    f.create_dataset('ob_err', data=ob_err)\n",
    "                    f.create_dataset('ob_err0', data=ob_err0)\n",
    "                    f.create_dataset('ob_err_comb', data=ob_err_comb)\n",
    "                    f.create_dataset('yo_all', data=yo_all)\n",
    "                    # If any 3d field saved\n",
    "                    if prior_variable3d_len>0:\n",
    "                        f.create_dataset('Xb3d', data=Xb3d)\n",
    "                    # if Mg/Ca proxy are used\n",
    "                    if data_psm_mgca_find == 1:\n",
    "                        f.create_dataset('Xb_sal', data=Xb_sal)\n",
    "                        f.create_dataset('Xb_ph', data=Xb_ph)\n",
    "                        f.create_dataset('Xb_omega', data=Xb_omega)\n",
    "\n",
    "                    metadata = {'Date': time.time(),\n",
    "                                'proxy_dbversion':yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['dbversion'],\n",
    "                                'exp_dir':dir_prior,\n",
    "                                'Nens':str(prior_len)}\n",
    "\n",
    "                    f.attrs.update(metadata)\n",
    "\n",
    "                # append proxy to hdf5 file\n",
    "                proxies.to_hdf(hdf5name, key='proxies')\n",
    "                proxy_psm_type_dict_df.to_hdf(hdf5name, key='proxy_psm_type_dict_df')\n",
    "\n",
    "                if proxy_frac < 1.0:\n",
    "                    sites_eval.to_hdf(hdf5name, key='sites_eval')\n",
    "                pandas.DataFrame(prior_variable_dict).to_hdf(hdf5name, key='prior_variable_dict')\n",
    "                pandas.DataFrame(prior_variable_dict_3d).to_hdf(hdf5name, key='prior_variable_dict_3d')\n",
    "                print('>>  prior2proxyunit hdf5 file saved')\n",
    "                print('      {}'.format(hdf5name))\n",
    "                print('>>  Finished Step 1. Preparation')\n",
    "                print('>>  Now Run: Step 2. Data Assimilation ...')\n",
    "                print('')\n",
    "\n",
    "\n",
    "                #######     ########     #######     ########     #######     ########     #######     ########     \n",
    "                # STEP 2 Data Assimilation\n",
    "                #######     ########     #######     ########     #######     ########     #######     ########\n",
    "\n",
    "\n",
    "                ########## Prior #########\n",
    "                # prior variable list\n",
    "                prior_variable_dict = []  # variable list\n",
    "                prior_nc_file_list = []  # nc file list\n",
    "                prior_variable_dict_3d = []  # variable list\n",
    "                prior_nc_file_list_3d = []  # nc file list\n",
    "\n",
    "                for key, value in prior_state_variable.items():\n",
    "                    nc_keyvalue = prior_state_variable[key]['ncname']  # note: 2d dict\n",
    "\n",
    "                    #print('>>  nc_keyvalue {}...'.format(nc_keyvalue))\n",
    "                    for key1, value1 in nc_keyvalue.items():\n",
    "                        #print('>>  {}: {}'.format(key1,value1))\n",
    "\n",
    "                        for i in range(len(prior_state_variable[key][value1])):\n",
    "                            if key in ['2d']:\n",
    "                                prior_variable_dict.append(prior_state_variable[key][value1][i])\n",
    "                                prior_nc_file_list.append(key1+'/'+value1+'.nc')\n",
    "                            elif key in ['3d']:\n",
    "                                prior_variable_dict_3d.append(prior_state_variable[key][value1][i])\n",
    "                                prior_nc_file_list_3d.append(key1+'/'+value1+'.nc')\n",
    "\n",
    "                # variable list\n",
    "                prior_variable_len = len(prior_variable_dict)\n",
    "                prior_variable3d_len = len(prior_variable_dict_3d)\n",
    "                #print('>>  Number of 2d prior variables is: {}. List:'.format(prior_variable_len))\n",
    "                #print('      {}'.format(prior_variable_dict))\n",
    "                #print('>>  Number of 3d prior variables is: {}. List:'.format(prior_variable3d_len))\n",
    "                #print('      {}'.format(prior_variable_dict_3d))\n",
    "\n",
    "                # for saving DA product Xa\n",
    "                if prior_variable_len > 0:\n",
    "                    Xa_output   = np.full((dum_ijmax * prior_variable_len, nens, recon_period_len),np.nan)\n",
    "                    Xa_output_all = Xa_output\n",
    "                    if prior_variable3d_len > 0:\n",
    "                        Xa3d_output   = np.full((dum_ijmax * dum_dmax * prior_variable_len, nens, recon_period_len),np.nan)\n",
    "                        Xa_output_all = np.concatenate((Xa_output, Xa3d_output), axis=0)\n",
    "                    else:\n",
    "                        print('>>  No 3d variable listed in {}'.format(config_name))\n",
    "                elif prior_variable_len == 0:\n",
    "                    if prior_variable3d_len > 0:\n",
    "                        Xa3d_output   = np.full((dum_ijmax * dum_dmax * prior_variable_len, nens, recon_period_len),np.nan)\n",
    "                        Xa_output_all = Xa3d_output\n",
    "                    print('>>  No 2d variable listed in {}'.format(config_name))\n",
    "                else:\n",
    "                    print('>>  Error! No 3d or 2d variables are listed in {}'.format(config_name))\n",
    "\n",
    "                # DA core script\n",
    "\n",
    "                proxies=pandas.read_hdf(hdf5name, 'proxies')\n",
    "                proxy_psm_type_dict_df = pandas.read_hdf(hdf5name, 'proxy_psm_type_dict_df')\n",
    "                proxy_psm_type_dict_list = proxy_psm_type_dict_df[0].values.tolist()\n",
    "\n",
    "                with h5py.File(hdf5name, 'r') as f:\n",
    "                    Xb = f.get('Xb')  # read Xb, background 2d field data\n",
    "                    Xb3d = f.get('Xb3d')  # read Xb, background 3d field data order: lon-lat-depth\n",
    "                    if Xb and Xb3d:\n",
    "                        Xball = np.concatenate((Xb, Xb3d), axis=0)\n",
    "                    elif Xb and Xb3d is None:\n",
    "                        Xball = Xb\n",
    "                    elif Xb is None and Xb3d:\n",
    "                        Xball = Xb3d\n",
    "                    else:\n",
    "                        print('>>  Error! No 3d or 2d variables are listed in {}'.format(config_name))\n",
    "\n",
    "                    Xb0 = np.copy(Xball)  # default Xb\n",
    "                    obvalue_full = f.get('obvalue')\n",
    "                    Ye_full = f.get('Ye')\n",
    "                    ob_err_full = f.get('ob_err')\n",
    "                    ob_err0_full = f.get('ob_err0')\n",
    "                    ob_err_comb = f.get('ob_err_comb')\n",
    "                    yo_all = f.get('yo_all')  # read location data\n",
    "\n",
    "                    if 'bayesreg_mgca_pooled_bcp' in proxy_psm_type_dict_list or 'bayesreg_mgca_pooled_red' in proxy_psm_type_dict_list:\n",
    "                        Xb_sal = f.get('Xb_sal')\n",
    "                        Xb_omega = f.get('Xb_omega')\n",
    "                        Xb_ph = f.get('Xb_ph')\n",
    "                        print('')\n",
    "                        print('>>Mg/Ca proxy found. Loading salinity, pH and omega')\n",
    "\n",
    "                    Xa_output_all = np.full((Xball.shape[0], Xball.shape[1], recon_period_len),np.nan)\n",
    "                    ob_len = obvalue_full.shape[0]\n",
    "\n",
    "                    print('>>  Reconstruction time intervals: {}; Observation data set number: {}'.format(recon_period_len,ob_len))\n",
    "                    for reconi in range(recon_period_len):\n",
    "                        Xball = Xb0.copy()  # initialize Xball\n",
    "                        for obi in range(ob_len):\n",
    "                            #print('>>ID Recon: {}, obser: {}'.format(reconi,obi))\n",
    "                            yo_loc = yo_all[obi,:]  # read location\n",
    "                            obvalue  = obvalue_full[obi, reconi]  # read observation value\n",
    "                            if proxy_err_eval in ['proxy_err_psm_mp']:\n",
    "                                ob_err = ob_err_comb[obi, reconi]  # read observation error, use PSM model + interval data uncertainty\n",
    "                            else:\n",
    "                                ob_err = ob_err0_full[obi, reconi] # read observation error, use PSM model only\n",
    "\n",
    "                            # proxy type\n",
    "                            proxy_psm_type_i = proxy_psm_type_dict_df[0][obi]\n",
    "                            if proxy_psm_type_i in ['bayesreg_tex86', 'bayesreg_d18o_pooled', 'cgenie_caco3', 'cgenie_caco3_13c']:\n",
    "                                Ye = DeepDA_psm.cal_ye_cgenie(yml_dict,proxies,obi,Xball,proxy_assim2,proxy_psm_type,dum_lon_offset,dum_imax,dum_jmax)\n",
    "                            elif proxy_psm_type_i in ['bayesreg_mgca_pooled_bcp', 'bayesreg_mgca_pooled_red']:\n",
    "                                Ye = DeepDA_psm.cal_ye_cgenie_mgca(yml_dict,proxies,obi,Xball,proxy_psm_type_i,dum_lon_offset,dum_imax,dum_jmax,Xb_sal,Xb_ph,Xb_omega,geologic_age)\n",
    "\n",
    "                            if ~np.isnan(obvalue) and ~np.isnan(ob_err_comb[obi, reconi]):\n",
    "                                print('>>  ID Recon: {}, obser: {}. Loc: {}. Mean of Ye {:.6f}, var {:.6f}, obs {:.6f}, obs_err {:.6f}'.format(reconi,obi,yo_loc,np.mean(Ye),np.var(Ye,ddof=1), obvalue, ob_err))\n",
    "                                if locRad:\n",
    "                                    covloc = modules_nc.covloc_eval(locRad, yo_loc, dum_jmax, dum_imax, cGENIEGrid)\n",
    "                                    covlocext = int(Xball.shape[0] / covloc.shape[0])\n",
    "                                    covloc = np.matlib.repmat(covloc, covlocext, 1).reshape((Xball.shape[0],))\n",
    "                                else:\n",
    "                                    covloc = np.full((Xball.shape[0],),1)\n",
    "                                #print('>>  Shape of Xball {}, ye {}, ob_err {}, covloc {}'.format(Xball.shape, Ye.shape, ob_err.shape, covloc.shape))\n",
    "                                Xa = LMR_DA.enkf_update_array(Xball, obvalue, Ye, ob_err, loc = covloc)\n",
    "                                #XaMean = np.ma.MaskedArray(Xa, np.matlib.repmat(np.copy(xbm) >= 9.9692e+36, 150,1))\n",
    "                                #print('>>    mean of Xa is {}'.format(np.nanmean(Xa)))\n",
    "                                \n",
    "                                # June 17, 2020 set hard limit for given variables\n",
    "                                Xa = DeepDA_tools.deepda_hard_limit(Xa, yml_dict, prior_variable_dict, dum_ijmax,1)\n",
    "\n",
    "                                if reconi == 0 and obi == 0:\n",
    "                                    kcov_saving = 1\n",
    "                                    ye = np.subtract(Ye, np.mean(Ye))\n",
    "                                    xbm = np.mean(Xball,axis=1)\n",
    "                                    Xbp = np.subtract(Xball,xbm[:,None])  # \"None\" means replicate in this dimension\n",
    "                                    kcov = np.dot(Xbp,np.transpose(ye)) / (nens-1)\n",
    "                                # update Xb using Xa, to assimilate next observation\n",
    "                                Xball = np.copy(Xa)\n",
    "                            else:\n",
    "                                print('>>  ID Recon: {}, obser: {}. Skip invalid obs.'.format(reconi,obi))\n",
    "                        #print('>>  ... global mean is {}'.format(np.nanmean(Xa)))\n",
    "                        Xa_output_all[:,:,reconi] = np.copy(Xa) # for each reconi, all observations were assimilated. Save final result for this reconi\n",
    "\n",
    "                    if Xb is not None:\n",
    "                        lenn1 = f.get('Xb').shape[0]\n",
    "                        Xa_output_2d = Xa_output_all[0:lenn1,:,:]\n",
    "                        if Xb3d:\n",
    "                            lenn2 = f.get('Xb3d').shape[0]\n",
    "                            Xa_output_3d = Xa_output_all[lenn1:lenn2+lenn1,:,:]\n",
    "                    elif Xb is None:\n",
    "                        if Xb3d:\n",
    "                            lenn2 = f.get('Xb3d').shape[0]\n",
    "                            Xa_output_3d = Xa_output_all[0:lenn2,:,:]\n",
    "                    else:\n",
    "                        print('>>  Error! No 3d or 2d variables are listed in {}'.format(config_name))\n",
    "                print('>>')\n",
    "                print('>>  Finished Step 2. Data Assimilation')\n",
    "                print('>>  Now      Step 3. Save results')\n",
    "                print('')\n",
    "                print(Xa_output_all.shape)\n",
    "\n",
    "                # DA save output in the netCDF file\n",
    "                \n",
    "                with h5py.File(hdf5name, 'r') as f:\n",
    "                    print('>>  Start writing netCDF ...')\n",
    "                    # save netCDF file\n",
    "                    nf = Dataset(nc_filename, 'w', format='NETCDF4')\n",
    "                    nf.description = 'DeepDA' + nc_filename\n",
    "                    #Specifying dimensions\n",
    "                    nf.createDimension('lon', len(cGENIEGridB_lon36))\n",
    "                    nf.createDimension('lat', len(cGENIEGridB_lat36))\n",
    "                    z = np.arange(0,1,1) # level 2d\n",
    "                    nf.createDimension('z', len(z))  # level\n",
    "                    nf.createDimension('nens', nens)  # number of ens\n",
    "                    nf.createDimension('time', recon_period_len)\n",
    "                    # Building variables\n",
    "                    longitude = nf.createVariable('Longitude', 'f4', 'lon')\n",
    "                    # Passing data into variables\n",
    "                    longitude[:] = cGENIEGridB_lon36.values\n",
    "\n",
    "                    latitude = nf.createVariable('Latitude', 'f4', 'lat')\n",
    "                    latitude[:] = cGENIEGridB_lat36.values\n",
    "\n",
    "                    levels = nf.createVariable('Levels', 'i4', 'z')\n",
    "                    levels[:] = z  # 2d level\n",
    "                    if Xb3d is not None:\n",
    "                        nf.createDimension('zt', len(zt))\n",
    "                        levels = nf.createVariable('zt', 'f4', 'zt')\n",
    "                        levels[:] = zt\n",
    "\n",
    "                    if locRad:\n",
    "                        #nf.createDimension('prior_var', prior_variable_len)  # level\n",
    "                        covloc_nc = nf.createVariable('covloc', 'f4', ('lat', 'lon'))\n",
    "                        covloc_nc[:,:] = np.copy(covloc[0:dum_ijmax].reshape(dum_jmax,dum_imax))\n",
    "\n",
    "                    if Xb is not None:\n",
    "                        print('Writing 2d field.')\n",
    "                        for nc_var_i in range(prior_variable_len):\n",
    "                            nc_var_name = prior_variable_dict[nc_var_i]\n",
    "\n",
    "                            j0 = dum_ijmax * nc_var_i\n",
    "                            j1 = dum_ijmax * (nc_var_i+1)\n",
    "                            print('')                            \n",
    "                            print('>>    ID from {} to {}: field is {}'.format(j0, j1,nc_var_name))\n",
    "\n",
    "                            Xb0_i = np.copy(f.get('Xb')[j0:j1,:])\n",
    "\n",
    "                            Xa_output_i = np.copy(Xa_output_2d[j0:j1,:,:])\n",
    "                            Xa_outputi = Xa_output_i.reshape(dum_imax,dum_jmax,nens,recon_period_len)\n",
    "\n",
    "                            XbNC_mean = nf.createVariable(nc_var_name+'_Xb_mean', 'f4', ('lat', 'lon','z'))\n",
    "                            xbm = np.mean(Xb0_i,axis=1)\n",
    "                            XbNC_mean[:,:,:] = np.copy(xbm.reshape(dum_jmax,dum_imax,1))\n",
    "\n",
    "                            XbNC_variance = nf.createVariable(nc_var_name+'_Xb_variance', 'f4', ('lat', 'lon','z'))\n",
    "                            Xb_temp = np.copy(np.var(Xb0_i,axis=1).reshape(dum_jmax,dum_imax,1))\n",
    "                            Xb_temp = np.ma.MaskedArray(Xb_temp, np.copy(xbm.reshape(dum_jmax,dum_imax,1)) >= 9.9692e+36)\n",
    "                            XbNC_variance[:,:,:] = Xb_temp\n",
    "                            print('>>    Xb mean is {:.8f}, std is {:.8f}, var is {:.8f}'.format(np.nanmean(XbNC_mean), np.sqrt(np.nanmean(Xb_temp)), np.nanmean(Xb_temp)))\n",
    "\n",
    "                            XaNC_mean = nf.createVariable(nc_var_name+'_Xa_mean', 'f4', ('lat', 'lon','z','time'))\n",
    "                            Xam_temp = np.copy(np.nanmean(Xa_outputi,axis=2).reshape(dum_jmax,dum_imax,1,recon_period_len))\n",
    "                            XaNC_mean[:,:,:,:] = Xam_temp\n",
    "\n",
    "                            XaNC_variance = nf.createVariable(nc_var_name+'_Xa_variance', 'f4', ('lat', 'lon','z','time'))\n",
    "                            #print(Xa_outputi[0,0:36,0,0])\n",
    "                            Xa_temp = np.copy(np.ma.var(Xa_outputi,axis=2).reshape(dum_jmax,dum_imax,1,recon_period_len))\n",
    "                            Xa_temp = np.ma.MaskedArray(Xa_temp, Xam_temp >= 9.9692e+36)\n",
    "                            XaNC_variance[:,:,:,:] = Xa_temp\n",
    "\n",
    "                            for reconii in range(recon_period_len):\n",
    "                                XaNC_mean_i = XaNC_mean[:,:,:,reconii]\n",
    "                                XaNC_var_i = XaNC_variance[:,:,:,reconii]\n",
    "                                print('>>      Recon {}. Xa mean is {:.8f}, std is {:.8f}, var is {:.8f}'.format(reconii, np.nanmean(XaNC_mean_i),np.sqrt(np.nanmean(XaNC_var_i)), np.nanmean(XaNC_var_i)))\n",
    "\n",
    "                            if save_ens_full:\n",
    "                                XaNC_full = nf.createVariable(nc_var_name+'_Xa_full', 'f4', ('lat', 'lon', 'nens', 'z','time'))\n",
    "                                XaNC_full[:,:,:,:,:] = np.copy(Xa_outputi.reshape(dum_jmax,dum_imax,nens,1,recon_period_len))\n",
    "\n",
    "                                XbNC_full = nf.createVariable(nc_var_name+'_Xb_full', 'f4', ('lat', 'lon', 'nens', 'z'))\n",
    "                                XbNC_full[:,:,:,:] = np.copy(Xb0_i.reshape(dum_jmax,dum_imax,nens,1))\n",
    "\n",
    "                            if kcov_saving > 0:\n",
    "                                kcov_i = np.copy(kcov[j0:j1]).reshape(dum_imax,dum_jmax,1)\n",
    "                                kcov_i = np.ma.MaskedArray(kcov_i, np.copy(xbm.reshape(dum_jmax,dum_imax,1)) >= 9.9692e+36)\n",
    "                                cov_ob0 = nf.createVariable(nc_var_name+'_obs0'+'_cov', 'f4', ('lat', 'lon','z'))\n",
    "                                cov_ob0[:,:,:] = kcov_i\n",
    "\n",
    "                            #Add local attributes to variable instances\n",
    "                            longitude.units = '°'\n",
    "                            latitude.units = '°'\n",
    "                            levels.units = 'm'\n",
    "                            #XbNC_mean.units = '°C'\n",
    "                            #XbNC_variance.units = '°C^2'\n",
    "                            #if save_ens_full:\n",
    "                            #    XaNC_full.units = '°C'\n",
    "                            #    XbNC_full.units = '°C'\n",
    "\n",
    "                            #variance.warning = 'test ...'\n",
    "                    if Xb3d is not None:\n",
    "                        print('Writing 3d field.')\n",
    "                        for nc_var_i in range(prior_variable3d_len):\n",
    "                            nc_var_name = prior_variable_dict_3d[nc_var_i]\n",
    "\n",
    "                            j0 = dum_ijmax * dum_dmax * nc_var_i\n",
    "                            j1 = dum_ijmax * dum_dmax * (nc_var_i+1)\n",
    "                            print('')\n",
    "                            print('>>    ID from {} to {}: field is {}'.format(j0, j1,nc_var_name))\n",
    "\n",
    "                            Xb0_i = np.copy(f.get('Xb3d')[j0:j1,:])\n",
    "                            Xa_output_i = np.copy(Xa_output_3d[j0:j1,:,:])\n",
    "                            Xa_outputi = Xa_output_i.reshape(dum_imax, dum_jmax,dum_dmax, nens,recon_period_len)\n",
    "\n",
    "                            XbNC_mean = nf.createVariable(nc_var_name+'_Xb_3d_mean', 'f4', ( 'zt', 'lat','lon'))\n",
    "                            xbm = np.mean(Xb0_i,axis=1)\n",
    "                            XbNC_mean[:,:,:] = np.copy(xbm.reshape(dum_dmax,dum_jmax,dum_imax))\n",
    "\n",
    "                            XbNC_variance = nf.createVariable(nc_var_name+'_Xb_3d_variance', 'f4', ( 'zt', 'lat','lon'))\n",
    "                            Xb_temp = np.copy(np.var(Xb0_i,axis= 1).reshape(dum_dmax,dum_jmax,dum_imax))\n",
    "                            Xb_temp = np.ma.MaskedArray(Xb_temp, np.copy(xbm.reshape(dum_dmax,dum_jmax,dum_imax)) >= 9.9692e+36)\n",
    "                            XbNC_variance[:,:,:] = Xb_temp\n",
    "                            print('>>    Xb mean is {:.8f}, std is {:.8f}, var is {:.8f}'.format(np.nanmean(XbNC_mean),np.sqrt(np.nanmean(Xb_temp)), np.nanmean(Xb_temp)))\n",
    "\n",
    "                            XaNC_mean = nf.createVariable(nc_var_name+'_Xa_3d_mean', 'f4', ('zt','lat', 'lon','time'))\n",
    "                            Xam_temp = np.copy(np.nanmean(Xa_outputi,axis=3).reshape(dum_dmax,dum_jmax,dum_imax,recon_period_len))\n",
    "                            XaNC_mean[:,:,:,:] = Xam_temp\n",
    "\n",
    "                            XaNC_variance = nf.createVariable(nc_var_name+'_Xa_3d_variance', 'f4', ('zt','lat', 'lon','time'))\n",
    "                            Xa_temp = np.copy(np.ma.var(Xa_outputi,axis=3).reshape(dum_dmax,dum_jmax,dum_imax,recon_period_len))\n",
    "                            Xa_temp = np.ma.MaskedArray(Xa_temp, Xam_temp >= 9.9692e+36)\n",
    "                            XaNC_variance[:,:,:,:] = Xa_temp\n",
    "\n",
    "                            for reconii in range(recon_period_len):\n",
    "                                XaNC_mean_i = XaNC_mean[:,:,:,reconii]\n",
    "                                XaNC_var_i = XaNC_variance[:,:,:,reconii]\n",
    "                                print('>>      Recon {}. Xa mean is {:.8f}, std is {:.8f}, var is {:.8f}'.format(reconii, np.nanmean(XaNC_mean_i), np.sqrt(np.nanmean(XaNC_var_i)), np.nanmean(XaNC_var_i)))\n",
    "\n",
    "                            if save_ens_full:\n",
    "                                XaNC_full = nf.createVariable(nc_var_name+'_Xa_3d_full', 'f4', ('zt','lat', 'lon', 'nens', 'time'))\n",
    "                                XaNC_full[:,:,:,:,:] = np.copy(Xa_outputi.reshape(dum_dmax,dum_jmax,dum_imax,nens,recon_period_len))\n",
    "\n",
    "                                XbNC_full = nf.createVariable(nc_var_name+'_Xb_3d_full', 'f4', ('zt','lat', 'lon', 'nens'))\n",
    "                                XbNC_full[:,:,:,:] = np.copy(Xb0_i.reshape(dum_dmax,dum_jmax,dum_imax,nens))\n",
    "\n",
    "                            if kcov_saving > 0:\n",
    "                                kcov_i = np.copy(kcov[lenn1:lenn1+dum_ijmax*dum_dmax]).reshape(dum_dmax,dum_jmax,dum_imax)\n",
    "                                kcov_i = np.ma.MaskedArray(kcov_i, np.copy(xbm.reshape(dum_dmax,dum_jmax,dum_imax)) >= 9.9692e+36)\n",
    "                                cov_ob0 = nf.createVariable(nc_var_name+'_3d_obs0'+'_cov', 'f4', ( 'zt', 'lat','lon'))\n",
    "                                cov_ob0[:,:,:] = kcov_i\n",
    "\n",
    "                            #Add local attributes to variable instances\n",
    "                            longitude.units = '°'\n",
    "                            latitude.units = '°'\n",
    "                            levels.units = 'm'\n",
    "                            #XbNC_mean.units = '°C'\n",
    "                            #XbNC_variance.units = '°C^2'\n",
    "                            #if save_ens_full:\n",
    "                            #    XaNC_full.units = '°C'\n",
    "                            #    XbNC_full.units = '°C'\n",
    "                    # Closing the dataset\n",
    "                    nf.close()  # close the new file\n",
    "                    print('>>  Data saved in netCDF file:')\n",
    "                    \n",
    "                print(nc_filename)\n",
    "                print('')\n",
    "                print('##########                    ##########')\n",
    "                print('##########   This loop done   ##########')\n",
    "                print('##########                    ##########')\n",
    "                print('')\n",
    "                print('')\n",
    "                \n",
    "config_save_name = dir_proxy_save_dir + dir_proxy_save + nexp + '.yml'\n",
    "print(config_save_name)\n",
    "configos = 'cp ' + config_name + ' ' +  config_save_name\n",
    "os.system(configos)\n",
    "print('')\n",
    "print('This page saved as DeepDA_allMC.html in the working directory')\n",
    "# export jupyter notebook as html, for reference\n",
    "os.system('jupyter nbconvert --to html DeepDA_allMC.ipynb')\n",
    "shutil.move(\"DeepDA_allMC.html\", MC_dir+\"DeepDA_allMC.html\")\n",
    "print('')\n",
    "print('########## All Done ##########')\n",
    "########## Check the consistency of the config.yml file and proxy database ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: Not a valid ID",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-113c5cd1b065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# close the new file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.close\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset._close\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: Not a valid ID"
     ]
    }
   ],
   "source": [
    "nf.close()  # close the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
