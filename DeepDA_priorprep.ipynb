{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Prepare prior for DeepDA\n",
    "\n",
    "OUTPUT:\n",
    "    example:\n",
    "    prior2proxyunit hdf5 file saved: /mnt/c/Users/mul450/Dropbox/git/deepDA/mlwrk/proxy/petmproxy3slices_v0.0.10gt1.csv.hdf5\n",
    "\n",
    "Mingsong Li\n",
    "1/15/2020\n",
    "'''\n",
    "from DeepDA_lib import modules_nc\n",
    "from DeepDA_lib import DeepDA_psm\n",
    "import h5py\n",
    "import time\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "try:\n",
    "    import bayspline\n",
    "except ImportError as e1:\n",
    "    print('Warning:', e1)\n",
    "try:\n",
    "    import bayspar\n",
    "except ImportError as e2:\n",
    "    print('Warning:', e2)\n",
    "try:\n",
    "    import bayfox\n",
    "except ImportError as e3:\n",
    "    print('Warning:', e3)\n",
    "try:\n",
    "    import baymag\n",
    "except ImportError as e4:\n",
    "    print('Warning:', e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"DeepDA_config.yml\", 'r')\n",
    "yml_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "f.close()\n",
    "\n",
    "t = 12  # last time slice, cGENIE\n",
    "k = 0   # first layer, SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ########## Proxy + PSM ######### \n",
      ">>  Proxy full list: ['Marine sediments_uk37', 'Marine sediments_tex86', 'Marine sediments_d18o_pooled', 'Marine sediments_mgca_pooled_bcp', 'Marine sediments_mgca_pooled_red'], blacklist: []\n",
      ">>  Proxy list to be assimilated: \n",
      "      ['Marine sediments_uk37', 'Marine sediments_tex86', 'Marine sediments_d18o_pooled', 'Marine sediments_mgca_pooled_bcp', 'Marine sediments_mgca_pooled_red']\n",
      "      Proxy quality control selection: None\n",
      " ########## read proxies database ######### \n",
      ">>  Database: proxy data length 1\n",
      " ########## Reconstruction ######### \n",
      ">>  recon_period 0 - 2. List: \n",
      "      [0 1 2]\n",
      "      nc_keyvalue {'biogem': 'fields_biogem_2d'}...\n",
      "      biogem: fields_biogem_2d\n",
      "      nc_keyvalue {'biogem': 'fields_biogem_3d'}...\n",
      "      biogem: fields_biogem_3d\n",
      ">>  Prior member size: 150\n",
      ">>  Number of 2d prior variables is: 3. List:\n",
      "      ['ocn_sur_temp', 'atm_pCO2', 'atm_temp']\n",
      ">>  Prior nc file list ['biogem/fields_biogem_2d.nc', 'biogem/fields_biogem_2d.nc', 'biogem/fields_biogem_2d.nc']\n",
      ">>  Number of 3d prior variables is: 1. List:\n",
      "      ['ocn_temp']\n",
      ">>  Prior nc file list ['biogem/fields_biogem_3d.nc']\n",
      ">>  OKAY.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# read config.yml settings\n",
    "print(' ########## Proxy + PSM ######### ')\n",
    "########## Proxy + PSM #########\n",
    "dir_proxy         = yml_dict['core']['proxy_dir']\n",
    "dir_proxy_data    = dir_proxy +'/'+ yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['dbversion']\n",
    "dir_proxy_save    = yml_dict['core']['wrkdir'] + '/'+ yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['dbversion']\n",
    "proxy_psm_type    = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_psm_type']\n",
    "proxy_assim2      = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_assim2']\n",
    "proxy_order       = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_order']\n",
    "proxy_blacklist   = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_blacklist']\n",
    "psm_d18osw_adjust = yml_dict['psm']['bayesreg_d18o_pooled']['psm_d18osw_adjust']\n",
    "proxy_qc          = yml_dict['proxies']['proxy_qc']\n",
    "\n",
    "proxy_list = [item for item in proxy_order if item not in proxy_blacklist]\n",
    "print('>>  Proxy full list: {}, blacklist: {}'.format(proxy_order, proxy_blacklist))\n",
    "print('>>  Proxy list to be assimilated: ')\n",
    "print('      {}'.format(proxy_list))\n",
    "print('      Proxy quality control selection: {}'.format(proxy_qc))\n",
    "\n",
    "print(' ########## read proxies database ######### ')\n",
    "#print(proxy_psm_type)\n",
    "#print(proxy_assim2)\n",
    "#print(psm_d18osw_adjust)\n",
    "\n",
    "# read proxies database\n",
    "proxies = pandas.read_csv(dir_proxy_data)\n",
    "proxies_len0 = len(proxies)\n",
    "#proxy_select = pandas.DataFrame()\n",
    "#print(proxy_select)\n",
    "proxy_select_0 = 0\n",
    "# check proxy data is in the blacklist or not\n",
    "for j in range(proxies_len0):\n",
    "    # Read proxy type from the database\n",
    "    data_psm_type = proxies['Proxy'][j]\n",
    "    # initial default 0 : this proxy is not included\n",
    "    data_assimilate_i = 0\n",
    "    for jlist in range(len(proxy_list)):\n",
    "        if data_psm_type in proxy_assim2[proxy_list[jlist]]:\n",
    "            # find and save this proxy\n",
    "            data_assimilate_i = 1\n",
    "    if data_assimilate_i == 1:\n",
    "        #print('>>    file {}, {} included'.format(proxies.loc[j,'File'], data_psm_type))\n",
    "        if proxy_select_0 == 0:\n",
    "            proxy_select = proxies.iloc[[j]]\n",
    "            proxy_select_0 = 1\n",
    "        else:\n",
    "            #proxy_select.append(proxies.iloc[[j]])\n",
    "            proxy_select = proxy_select.append(proxies.iloc[[j]], ignore_index=True)\n",
    "#print(proxy_select)\n",
    "# sort proxy data using given order\n",
    "proxy_select_1 = 0\n",
    "proxies_select_len0 = len(proxy_select)\n",
    "\n",
    "for i in range(len(proxy_order)):\n",
    "    proxy_order_i = proxy_assim2[proxy_order[i]]\n",
    "    for j in range(proxies_select_len0):\n",
    "        # Read proxy type from the database\n",
    "        data_psm_type = proxy_select['Proxy'][j]\n",
    "        # initial default 0 : this proxy is not included\n",
    "        data_assimilate_i = 0\n",
    "        if data_psm_type in proxy_order_i:\n",
    "            if proxy_select_1 == 0:\n",
    "                proxy_select_sort = proxy_select.iloc[[j]]\n",
    "                proxy_select_1 = 1\n",
    "            else:\n",
    "                proxy_select_sort = proxy_select_sort.append(proxy_select.iloc[[j]], ignore_index=True)\n",
    "\n",
    "#print(proxy_select_sort)\n",
    "\n",
    "print('>>  Database: proxy data length {}'.format(proxies_len0))\n",
    "\n",
    "#proxies =   proxy_select\n",
    "proxies =   proxy_select_sort\n",
    "proxies_len = len(proxies)\n",
    "\n",
    "\n",
    "if proxies_len0 > proxies_len:\n",
    "    print('>>    Selected proxy data length {}'.format(proxies_len))\n",
    "    #print(proxies)\n",
    "#print(proxies.iloc[1,:])\n",
    "print(' ########## Reconstruction ######### ')\n",
    "\n",
    "nexp = yml_dict['core']['nexp']\n",
    "data_period_id    = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['data_period_id']\n",
    "data_period_idstd = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['data_period_idstd']\n",
    "recon_period = yml_dict['core']['recon_period']\n",
    "recon_timescale = yml_dict['core']['recon_timescale_interval']\n",
    "recon_period_full = np.arange(recon_period[0],recon_period[1]+1,recon_timescale)\n",
    "recon_period_len = recon_period_full.shape[0]\n",
    "geologic_age = yml_dict['core']['geologic_age']\n",
    "print('>>  recon_period {} - {}. List: '.format(recon_period[0], recon_period[1]))\n",
    "print('      {}'.format(recon_period_full))\n",
    "\n",
    "########## Prior #########\n",
    "prior_source = yml_dict['prior']['prior_source'] #\n",
    "prior_state_variable = yml_dict['prior'][prior_source]['state_variable']  # note: ['2d': xxx; '3d': xxx]\n",
    "\n",
    "# save prior variable list\n",
    "prior_variable_dict = []  # variable list\n",
    "prior_nc_file_list = []  # nc file list\n",
    "prior_variable_dict_3d = []  # variable list\n",
    "prior_nc_file_list_3d = []  # nc file list\n",
    "\n",
    "for key, value in prior_state_variable.items():\n",
    "    nc_keyvalue = prior_state_variable[key]['ncname']  # note: 2d dict\n",
    "    \n",
    "    print('      nc_keyvalue {}...'.format(nc_keyvalue))\n",
    "    for key1, value1 in nc_keyvalue.items():\n",
    "        print('      {}: {}'.format(key1,value1))\n",
    "        \n",
    "        for i in range(len(prior_state_variable[key][value1])):\n",
    "            if key in ['2d']:\n",
    "                prior_variable_dict.append(prior_state_variable[key][value1][i])\n",
    "                prior_nc_file_list.append(key1+'/'+value1+'.nc')\n",
    "            elif key in ['3d']:\n",
    "                prior_variable_dict_3d.append(prior_state_variable[key][value1][i])\n",
    "                prior_nc_file_list_3d.append(key1+'/'+value1+'.nc')\n",
    "\n",
    "dum_lon_offset = yml_dict['prior'][prior_source]['dum_lon_offset'] # longitude offset\n",
    "\n",
    "########  Prior read   ########\n",
    "dir_prior = yml_dict['core']['prior_dir']\n",
    "dir_prior_full = os.listdir(dir_prior)\n",
    "prior_len = len(dir_prior_full)\n",
    "#print('dir_prior: {}'.format(dir_prior))\n",
    "print('>>  Prior member size: {}'.format(prior_len))\n",
    "\n",
    "# prepare variable list for Xb\n",
    "prior_variable2d_len = len(prior_variable_dict)\n",
    "prior_variable3d_len = len(prior_variable_dict_3d)\n",
    "print('>>  Number of 2d prior variables is: {}. List:'.format(prior_variable2d_len))\n",
    "print('      {}'.format(prior_variable_dict))\n",
    "print('>>  Prior nc file list {}'.format(prior_nc_file_list))\n",
    "print('>>  Number of 3d prior variables is: {}. List:'.format(prior_variable3d_len))\n",
    "print('      {}'.format(prior_variable_dict_3d))\n",
    "print('>>  Prior nc file list {}'.format(prior_nc_file_list_3d))\n",
    "\n",
    "######## Ye   ########\n",
    "# for saving proxy unit data Ye\n",
    "Ye       = np.full((proxies_len,prior_len),np.nan)\n",
    "Yevar    = np.full((proxies_len,prior_len),np.nan)\n",
    "obvalue  = np.full((proxies_len,recon_period_len),np.nan)\n",
    "ob_err   = np.full((proxies_len,recon_period_len),np.nan) # data obs error\n",
    "ob_err0  = np.full((proxies_len,recon_period_len),np.nan) # PSM obs error\n",
    "ob_err_comb  = np.full((proxies_len,recon_period_len),np.nan) # PSM obs error\n",
    "yo_all = np.full((proxies_len,2),np.nan) # PSM obs error\n",
    "print('>>  OKAY.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  0. PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check the consistency of the config.yml file and proxy database\n",
    "# AND get obs R\n",
    "data_psm_mgca_find = 0\n",
    "for j in range(proxies_len):\n",
    "    # Read proxy type from the database\n",
    "    data_psm_type = proxies['Proxy'][j]\n",
    "    # Read allowed proxy from the DTDA-config.yml\n",
    "    data_psm_type_find = 0\n",
    "    for key, value in proxy_assim2.items():\n",
    "        #print(key,value)\n",
    "        # find this proxy type exist or not, how many times it occurrs\n",
    "        if data_psm_type in proxy_assim2[key]:\n",
    "            data_psm_type_find = data_psm_type_find + 1\n",
    "    if data_psm_type_find == 1:\n",
    "        for key, value in proxy_psm_type.items():\n",
    "            if data_psm_type in proxy_assim2[key]:\n",
    "                data_psm_key = key\n",
    "        proxy_psm_type_i = proxy_psm_type[data_psm_key]\n",
    "        print('>>  {}. PSM for {} is {}'.format(j, data_psm_type,proxy_psm_type_i))\n",
    "        \n",
    "    elif data_psm_type_find == 0:\n",
    "        print('>>  Warning, {} in database is not find in DTDA-config.yml dictionary'.format(data_psm_type))\n",
    "    else:\n",
    "        print('>>  Warning, {} in database appears more than 1 time in DTDA-config.yml dictionary'.format(data_psm_type))\n",
    "    \n",
    "    # Now PSM type has been found. Let's precal Ye\n",
    "    \n",
    "    if proxy_psm_type_i in ['bayesreg_mgca_pooled_red','bayesreg_mgca_pooled_bcp']:\n",
    "        data_psm_mgca_find = 1\n",
    "\n",
    "if data_psm_mgca_find == 1:\n",
    "    print('>>  MgCa proxy found')\n",
    "print('>>  Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  Reading prior state variables\n",
      ">>  Shape of dum_dmax 16, dum_imax 36, dum_jmax 36, dum_ijmax 1296\n",
      ">>  Last member: x.shape (36, 36)\n",
      "      149: ML.petm008.ID.9: ocn_sur_temp\n",
      ">>  Last member: x.shape (36, 36)\n",
      "      149: ML.petm008.ID.9: atm_pCO2\n",
      ">>  Last member: x.shape (36, 36)\n",
      "      149: ML.petm008.ID.9: atm_temp\n",
      ">>  OKAY.\n"
     ]
    }
   ],
   "source": [
    "# build Ye\n",
    "# If there is no field in the model, convert model unit to proxy unit\n",
    "print('>>  Reading prior state variables')\n",
    "# read first variable data, first time slice, to get the shape of prior grid\n",
    "try:\n",
    "    #x0 = Dataset(dir_prior+'/'+dir_prior_full[0]+'/'+ nc_file_2d).variables[prior_variable_dict[0]][0,:,:]\n",
    "    x1 = Dataset(dir_prior+'/'+dir_prior_full[0]+'/'+ prior_nc_file_list_3d[0]).variables[prior_variable_dict_3d[0]][0,:,:,:]\n",
    "    #print('    Shape of prior 2d grid {}'.format(x0.shape))\n",
    "    dum_dmax = x1.shape[0] # depth\n",
    "    dum_imax = x1.shape[1]  # lon\n",
    "    dum_jmax = x1.shape[2]  # lat\n",
    "except:\n",
    "    try:\n",
    "        x0 = Dataset(dir_prior+'/'+dir_prior_full[0]+'/'+ prior_nc_file_list[0]).variables[prior_variable_dict[0]][0,:,:]\n",
    "        dum_imax = 36 #x1.shape[0]  # lon\n",
    "        dum_jmax = 36 #x1.shape[1]  # lat\n",
    "        dum_dmax = 16\n",
    "    except:\n",
    "        dum_dmax = 16\n",
    "        dum_imax = 36\n",
    "        dum_jmax = 36\n",
    "# prepare 2d Xb for lon-lat state \n",
    "dum_ijmax = dum_imax*dum_jmax  # lonn * latn\n",
    "print('>>  Shape of dum_dmax {}, dum_imax {}, dum_jmax {}, dum_ijmax {}'.format(dum_dmax,dum_imax,dum_jmax,dum_ijmax))\n",
    "\n",
    "if prior_variable2d_len>0:\n",
    "    Xb_shape = (dum_ijmax*prior_variable2d_len, prior_len)  # lonn * latn * varn\n",
    "    Xb   = np.full(Xb_shape,np.nan)\n",
    "# prep 3d version of Xb\n",
    "if prior_variable3d_len > 0:\n",
    "    Xb3d_shape = (dum_ijmax*dum_dmax*prior_variable3d_len, prior_len)  # lonn * latn * varn\n",
    "    Xb3d = np.full(Xb3d_shape,np.nan)\n",
    "    # read prior and save Xb\n",
    "    #Xb = np.full((dum_ijmax, prior_len),np.nan)\n",
    "\n",
    "if data_psm_mgca_find == 1:\n",
    "    print('>>  Prepare Mg/Ca related state variable ...')\n",
    "    # for Mg/Ca SST proxy salinity, ph, omega\n",
    "    Xb_sal       = np.full(Xb_shape,np.nan)\n",
    "    Xb_ph        = np.full(Xb_shape,np.nan)\n",
    "    Xb_omega     = np.full(Xb_shape,np.nan)\n",
    "    spp = 'all'\n",
    "    # ``1`` for reductive, ``0`` for BCP (Barker).\n",
    "    cleaningr = np.tile(np.array([1]),prior_len)\n",
    "    cleaningb = np.tile(np.array([0]),prior_len)\n",
    "    \n",
    "# loop for each member of a prior\n",
    "for i in range(prior_len):\n",
    "    # loop for each variable of each member\n",
    "    if prior_variable2d_len>0:\n",
    "        for j in range(prior_variable2d_len):\n",
    "            # full directory of netcdf file\n",
    "            name_nc_2d = dir_prior+'/'+dir_prior_full[i]+'/'+ prior_nc_file_list[j]\n",
    "            j0 = dum_ijmax * j\n",
    "            j1 = dum_ijmax * (j+1)\n",
    "            nc_field = prior_variable_dict[j]\n",
    "            x = Dataset(name_nc_2d).variables[nc_field][t,:,:]  # time-lat-lon\n",
    "            #x = np.swapaxes(x,0,1)  # lon-lat  # NO, this is incorrect!\n",
    "            Xb[j0:j1,i] = np.copy(x.reshape(dum_ijmax))\n",
    "            \n",
    "            if data_psm_mgca_find == 1:\n",
    "                try:\n",
    "                    name_nc_2d_mgca = dir_prior+'/'+dir_prior_full[i]+'/biogem/'+ 'fields_biogem_2d.nc'\n",
    "                    x = Dataset(name_nc_2d_mgca).variables['ocn_sur_sal'][t,:,:]\n",
    "                    x = np.swapaxes(x,0,1)  # lon-lat\n",
    "                    Xb_sal[j0:j1,i] = np.copy(x.reshape(dum_ijmax))\n",
    "                    name_nc_3d_mgca = dir_prior+'/'+dir_prior_full[i]+'/biogem/'+ 'fields_biogem_3d.nc'\n",
    "                    x = Dataset(name_nc_3d_mgca).variables['misc_pH'][t,k,:,:]\n",
    "                    x = np.swapaxes(x,0,1)  # lon-lat\n",
    "                    Xb_ph[j0:j1,i] = np.copy(x.reshape(dum_ijmax))\n",
    "                    x = Dataset(name_nc_3d_mgca).variables['carb_ohm_cal'][t,k,:,:]\n",
    "                    x = np.swapaxes(x,0,1)  # lon-lat\n",
    "                    Xb_omega[j0:j1,i] = np.copy(x.reshape(dum_ijmax))\n",
    "                except:\n",
    "                    if i == 0:\n",
    "                        # warning one time\n",
    "                        print('>>  Warning: reading state variable error. ocn_sur_sal, misc_pH, carb_ohm_cal')\n",
    "\n",
    "            # print the last one data\n",
    "            if i > prior_len-2:\n",
    "                print('>>  Last member: x.shape {}'.format(x.shape))\n",
    "                print('      {}: {}: {}'.format(i, dir_prior_full[i], prior_variable_dict[j]))\n",
    "    # if 3d variables are used\n",
    "    if prior_variable3d_len > 0:\n",
    "        for k in range(prior_variable3d_len):\n",
    "            name_nc_3d = dir_prior+'/'+dir_prior_full[i]+'/'+ prior_nc_file_list_3d[k]\n",
    "            nc_field = prior_variable_dict_3d[k]\n",
    "            k0 = dum_ijmax*dum_dmax * k\n",
    "            k1 = dum_ijmax*dum_dmax * (k+1)\n",
    "            x = Dataset(name_nc_3d).variables[nc_field][t,:,:,:]  # depth-lat-lon\n",
    "            #x = np.swapaxes(x,1,2)  # depth-lon-lat\n",
    "            #x = np.swapaxes(x,0,2)  # lon-lat-depth\n",
    "            #x = np.swapaxes(x,0,1)  # lon-lat-depth\n",
    "            Xb3d[k0:k1,i] = np.copy(x.reshape(dum_ijmax*dum_dmax))\n",
    "            \n",
    "    #print(x)\n",
    "print('>>  OKAY.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Xb[0:36,0])\n",
    "#print(Xb[36:72,0])\n",
    "#print(Xb3d[0:36,0])\n",
    "#print(Xb3d[36:72,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>  0. kozdon2013-865d18omorozovellasims.txt, grid [lon lat] [1, 19], grid id 685\n",
      ">>  PSM for d18o_morozovella is bayesreg_d18o_pooled, prior mean is 34.39700023651123\n",
      ">>   bayesreg_d18o_pooled. Mean of Ye is -4.409776, variance is 0.000019 \n",
      "\n",
      ">>  Ye mean [-4.40977635]\n",
      "\n",
      ">>  obvalue [[-3.1044 -3.9734 -3.2864]],  ob_err [[0.061009 0.025281 0.085264]]\n",
      "\n",
      ">>  from psm  ob_err_comb [[0.3581246  0.32165219 0.38234225]]\n",
      ">>  OKAY.\n"
     ]
    }
   ],
   "source": [
    "# precal_Ye\n",
    "\n",
    "proi = 0\n",
    "for j in range(proxies_len):\n",
    "    # read lon lat for each line of proxy\n",
    "    dum_lat = proxies['Lat'][j]  # (paleo)latitude of this site\n",
    "    dum_lon = proxies['Lon'][j]  # (paleo)longitude of this site\n",
    "    yo_all[proi,:] = np.array([dum_lon, dum_lat])  # save location of this site\n",
    "    \n",
    "    lonlat = modules_nc.cal_find_ij(dum_lon,dum_lat,dum_lon_offset,dum_imax,dum_jmax) \n",
    "    Filei = proxies['File'][j]\n",
    "    ######################## TO DO: including d13C or other proxies ##############\n",
    "    # find 1d grid location\n",
    "    lonlati = lonlat[1] * dum_jmax + lonlat[0]\n",
    "    # read prior\n",
    "    prior_1grid = np.copy(Xb[lonlati,:])   # prior\n",
    "    \n",
    "    #print(prior_1grid.shape)\n",
    "    ######################## TO DO: add  dum_ijmax * j etc. ##############\n",
    "    \n",
    "    #print(Xb[lonlati,i])\n",
    "    #result = np.where(Xb[:,i] == Xb[lonlati,i])\n",
    "    #print(result)\n",
    "    \n",
    "    # Read proxy type from the database\n",
    "    data_psm_type = proxies['Proxy'][j]\n",
    "    # Read allowed proxy from the DTDA-config.yml\n",
    "    data_psm_type_find = 0\n",
    "    for key, value in proxy_assim2.items():\n",
    "        #print(key,value)\n",
    "        # find this proxy type exist or not, how many times it occurrs\n",
    "        if data_psm_type in proxy_assim2[key]:\n",
    "            data_psm_type_find = data_psm_type_find + 1\n",
    "            \n",
    "    if data_psm_type_find == 1:\n",
    "        for key, value in proxy_psm_type.items():\n",
    "            if data_psm_type in proxy_assim2[key]:\n",
    "                data_psm_key = key\n",
    "        proxy_psm_type_i = proxy_psm_type[data_psm_key]\n",
    "        print('')\n",
    "        print('>>  {}. {}, grid [lon lat] {}, grid id {}'.format(j,Filei,lonlat,lonlati))\n",
    "        print('>>  PSM for {} is {}, prior mean is {}'.format(data_psm_type,proxy_psm_type_i, np.mean(prior_1grid)))\n",
    "        \n",
    "    elif data_psm_type_find == 0:\n",
    "        print('Warning, this proxy type in database is not find in DTDA-config.yml dictionary')\n",
    "    else:\n",
    "        print('Warning, this proxy type in database appears more than 1 time in DTDA-config.yml dictionary')\n",
    "    \n",
    "    \n",
    "    # Now PSM type has been found. Let's precal Ye\n",
    "    \n",
    "    if proxy_psm_type_i in ['bayesreg_d18o_pooled']:\n",
    "        #try:\n",
    "            # bayfox\n",
    "        d18o_localsw = DeepDA_psm.d18o_localsw(abs(dum_lat))\n",
    "        psm_d18osw_adjust = yml_dict['psm']['bayesreg_d18o_pooled']['psm_d18osw_adjust']\n",
    "        # total d18osw = d18o_localsw + d18o_adj + psm_d18osw_adjust\n",
    "        # d18o_adj has been included in the bayfox model\n",
    "        prediction_d18O = bayfox.predict_d18oc(prior_1grid,d18o_localsw+psm_d18osw_adjust) # pool model for bayfox\n",
    "        #print('>>  prediction_d18O.ensemble shape {}'.format(prediction_d18O.ensemble.shape))\n",
    "        Ye[proi,:] = np.mean(prediction_d18O.ensemble, axis = 1)\n",
    "        Yevar[proi,:] = np.var(prediction_d18O.ensemble, axis = 1, ddof=1)\n",
    "        yo_all[proi,:] = np.array([dum_lon, dum_lat])\n",
    "        print('>>   {}. Mean of Ye is {:.6f}, variance is {:.6f} '.format(proxy_psm_type_i, np.mean(Ye[proi,:]), np.var(Yevar[proi,:])))\n",
    "        for reconi in range(recon_period_len):\n",
    "            obvalue[proi,reconi] = proxies[data_period_id[reconi]][j]\n",
    "            ob_err[proi,reconi] = proxies[data_period_idstd[reconi]][j] ** 2\n",
    "            ob_err0[proi,reconi]= DeepDA_psm.obs_estimate_r_d18o(obvalue[proi,reconi], d18o_localsw+psm_d18osw_adjust)\n",
    "\n",
    "            # Quality control\n",
    "            ob_err_comb[proi,reconi] = ob_err[proi,reconi] + ob_err0[proi,reconi]\n",
    "            qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc)\n",
    "            #print(qc_i)\n",
    "            if qc_i:\n",
    "                if proxy_qc is not None:\n",
    "                    print('    Pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "            else:\n",
    "                ob_err_comb[proi,reconi] = np.nan\n",
    "                if proxy_qc is not None:                    \n",
    "                    print('    Did not pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "        \n",
    "            #obvalue[proi,] = proxies['Lat'][j]\n",
    "            #print('>>  {}'.format(proxy_psm_type_i))\n",
    "            #print('>>  id {}, Ye, first 10 example {}'.format(proi,Ye[j,0:10]))\n",
    "            #print('>>  id {}, Yevar, first 10 example {}'.format(proi,Yevar[j,0:10]))\n",
    "            \n",
    "        proi = proi + 1  # increasement\n",
    "        #except:\n",
    "        #    print('>>  Warning {}'.format(proxy_psm_type_i))\n",
    "    elif proxy_psm_type_i in ['bayesreg_tex86']:\n",
    "        # bayspar\n",
    "        #try:\n",
    "        # bayspar\n",
    "        search_tol_i = yml_dict['psm']['bayesreg_tex86']['search_tol']\n",
    "        nens_i = yml_dict['psm']['bayesreg_tex86']['nens']\n",
    "        prediction = bayspar.predict_tex_analog(prior_1grid, temptype = 'sst', search_tol = search_tol_i, nens=nens_i)\n",
    "        Ye[proi,:] = np.mean(prediction.ensemble, axis = 1)\n",
    "        Yevar[proi,:] = np.var(prediction.ensemble, axis = 1, ddof=1)\n",
    "        print('>>   {}. Mean of Ye is {:.6f}, variance is {:.6f} '.format(proxy_psm_type_i, np.mean(Ye[proi,:]), np.var(Yevar[proi,:])))\n",
    "        yo_all[proi,:] = np.array([dum_lon, dum_lat])\n",
    "        for reconi in range(recon_period_len):\n",
    "            obvalue[proi,reconi] = proxies[data_period_id[reconi]][j]\n",
    "            ob_err[proi,reconi] = proxies[data_period_idstd[reconi]][j] ** 2\n",
    "            ob_err0[proi,reconi]= DeepDA_psm.obs_estimate_r_tex86(np.array([31]), 'sst', 15)\n",
    "            #obvalue[proi,] = proxies['Lat'][j]\n",
    "            \n",
    "            # Quality control\n",
    "            ob_err_comb[proi,reconi] = ob_err[proi,reconi] + ob_err0[proi,reconi]\n",
    "            qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc)\n",
    "            if qc_i:\n",
    "                if proxy_qc is not None:\n",
    "                    print('    Pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "            else:\n",
    "                ob_err_comb[proi,reconi] = np.nan\n",
    "                if proxy_qc is not None:                    \n",
    "                    print('    Did not pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "\n",
    "            #print('>>  {}'.format(proxy_psm_type_i))\n",
    "            #print('>>  id {}, Ye, first 10 example {}'.format(proi,Ye[j,0:10]))\n",
    "            #print('>>  id {}, Yevar, first 10 example {}'.format(proi,Yevar[j,0:10]))\n",
    "        proi = proi + 1  # increasement\n",
    "        #except:\n",
    "        #    print('>>  Warning {}'.format(proxy_psm_type_i))\n",
    "        #    print('>>  search_tol too small for {}: mean sst is {}'.format(j, np.mean(prior_1grid)))\n",
    "            \n",
    "    elif proxy_psm_type_i in ['bayesreg_uk37']:\n",
    "        # \n",
    "        print('... bayesreg_uk37: To be done ...')\n",
    "        \n",
    "    elif proxy_psm_type_i in ['bayesreg_mgca_pooled_red']:\n",
    "        #try:\n",
    "        # prior_1grid = np.copy(Xb[lonlati,:])   # prior\n",
    "        salinity =  np.copy(Xb_sal[lonlati,:])\n",
    "        ph       =  np.copy(Xb_ph[lonlati,:])\n",
    "        omega    =  np.copy(Xb_omega[lonlati,:])\n",
    "\n",
    "        prediction_mgca = baymag.predict_mgca(prior_1grid, cleaningr, salinity, ph, omega, spp) # pool model for baymag reductive\n",
    "        pred_mgca_adj = baymag.sw_correction(prediction_mgca, np.array([geologic_age]))\n",
    "        Ye[proi,:] = np.mean(pred_mgca_adj.ensemble, axis = 1)\n",
    "        Yevar[proi,:] = pred_mgca_adj.ensemble.var()\n",
    "        print('>>   {}. Mean of Ye is {:.6f}, variance is {:.6f} '.format(proxy_psm_type_i, np.mean(Ye[proi,:]), np.var(Yevar[proi,:])))\n",
    "        yo_all[proi,:] = np.array([dum_lon, dum_lat])\n",
    "        \n",
    "        for reconi in range(recon_period_len):\n",
    "            obvalue[proi,reconi] = proxies[data_period_id[reconi]][j]\n",
    "            ob_err[proi,reconi]  = proxies[data_period_idstd[reconi]][j] ** 2\n",
    "            #obs_estimate_r_mgca_pooled(obs, cleaning, salinity, ph, omega, spp, age):\n",
    "            ob_err0[proi,reconi] = DeepDA_psm.obs_estimate_r_mgca_pooled(obvalue[proi,reconi], 1, np.mean(salinity), np.mean(ph), np.mean(omega), spp, geologic_age)\n",
    "            \n",
    "            # Quality control\n",
    "            ob_err_comb[proi,reconi] = ob_err[proi,reconi] + ob_err0[proi,reconi]\n",
    "            qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc)\n",
    "            if qc_i:\n",
    "                if proxy_qc is not None:\n",
    "                    print('    Pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "            else:\n",
    "                ob_err_comb[proi,reconi] = np.nan\n",
    "                if proxy_qc is not None:                    \n",
    "                    print('    Did not pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "            #print('>>  {}'.format(proxy_psm_type_i))\n",
    "            #print('>>  id {}, Ye, first 10 example {}'.format(proi,Ye[j,0:10]))\n",
    "            #print('>>  id {}, Yevar, first 10 example {}'.format(proi,Yevar[j,0:10]))\n",
    "            print('      reductive: mean salinity {}, ph {}, omega {}'.format(np.mean(salinity), np.mean(ph), np.mean(omega)))\n",
    "        proi = proi + 1  # increasement\n",
    "        #except:\n",
    "        #    print('>>  Warning {}'.format(proxy_psm_type_i))\n",
    "\n",
    "    elif proxy_psm_type_i in ['bayesreg_mgca_pooled_bcp']:\n",
    "        #try:\n",
    "        # prior_1grid = np.copy(Xb[lonlati,:])   # prior\n",
    "        salinity =  np.copy(Xb_sal[lonlati,:])\n",
    "        ph       =  np.copy(Xb_ph[lonlati,:])\n",
    "        omega    =  np.copy(Xb_omega[lonlati,:])\n",
    "\n",
    "        prediction_mgca = baymag.predict_mgca(prior_1grid, cleaningb, salinity, ph, omega, spp) # pool model for baymag barker\n",
    "        pred_mgca_adj = baymag.sw_correction(prediction_mgca, np.array([geologic_age]))\n",
    "        Ye[proi,:] = np.mean(pred_mgca_adj.ensemble, axis = 1)\n",
    "        Yevar[proi,:] = pred_mgca_adj.ensemble.var()\n",
    "        print('>>   {}. Mean of Ye is {:.6f}, variance is {:.6f} '.format(proxy_psm_type_i, np.mean(Ye[proi,:]), np.var(Yevar[proi,:])))\n",
    "        yo_all[proi,:] = np.array([dum_lon, dum_lat])\n",
    "        \n",
    "        for reconi in range(recon_period_len):\n",
    "            obvalue[proi,reconi] = proxies[data_period_id[reconi]][j]\n",
    "            ob_err[proi,reconi] = proxies[data_period_idstd[reconi]][j] ** 2\n",
    "            ob_err0[proi,reconi] = DeepDA_psm.obs_estimate_r_mgca_pooled(obvalue[proi,reconi], 0, np.mean(salinity), np.mean(ph), np.mean(omega), spp, geologic_age)\n",
    "            \n",
    "            # Quality control\n",
    "            ob_err_comb[proi,reconi] = ob_err[proi,reconi] + ob_err0[proi,reconi]\n",
    "            qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc)\n",
    "            if qc_i:\n",
    "                if proxy_qc is not None:\n",
    "                    print('    Pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "            else:\n",
    "                ob_err_comb[proi,reconi] = np.nan\n",
    "                if proxy_qc is not None:\n",
    "                    print('    Did not pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "            #print('>>  {}'.format(proxy_psm_type_i))\n",
    "            #print('>>  id {}, Ye, first 10 example {}'.format(proi,Ye[j,0:10]))\n",
    "            #print('>>  id {}, Yevar, first 10 example {}'.format(proi,Yevar[j,0:10]))\n",
    "            print('      barker: mean salinity {}, ph {}, omega {}'.format(np.mean(salinity), np.mean(ph), np.mean(omega)))\n",
    "        proi = proi + 1  # increasement\n",
    "        #except:\n",
    "        #    print('>>  Warning {}'.format(proxy_psm_type_i))\n",
    "    else:\n",
    "        a = 1\n",
    "    \n",
    "    #innovi = obvalue[proi,:] - np.mean(Ye[proi,:])\n",
    "    #std3 = np.sqrt( ob_err0[proi,:] ) * 3\n",
    "    #print('Innovation {}, 3xStd {}'.format(innovi, std3))\n",
    "    #print( innovi > std3)\n",
    "    #ob_err0[proi,:] = np.ma.masked_where(innovi > std3, ob_err0[proi,:])\n",
    "    \n",
    "    #print( 'new ob_err0 {}'.format(ob_err0[proi,:]))\n",
    "print('')\n",
    "print('>>  Ye mean {}'.format(np.mean(Ye,axis=1)))\n",
    "print('')\n",
    "print('>>  obvalue {},  ob_err {}'.format(obvalue, ob_err))\n",
    "print('')\n",
    "print('>>  from psm  ob_err_comb {}'.format( ob_err_comb))\n",
    "print('>>  OKAY.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prior2proxyunit hdf5 file saved: /mnt/d/DeepDA/wrk/petmproxy3slices_v0.0.10gt1.csv.exp_petm78_og1_qc_obs_20200131_11_precal_ye.hdf5\n",
      "  Step 1 finished. Run Step 2: DeepDA_main.ipynb now\n",
      ">>  Done!\n"
     ]
    }
   ],
   "source": [
    "hdf5name = dir_proxy_save +'.' + nexp + '_precal_ye.hdf5'\n",
    "with h5py.File(hdf5name, 'w') as f:\n",
    "    if prior_variable2d_len>0:\n",
    "        f.create_dataset('Xb', data=Xb)\n",
    "    f.create_dataset('obvalue', data=obvalue)\n",
    "    f.create_dataset('Ye', data=np.transpose(Ye))\n",
    "    f.create_dataset('Yevar', data=np.transpose(Yevar))\n",
    "    f.create_dataset('ob_err', data=ob_err)\n",
    "    f.create_dataset('ob_err0', data=ob_err0)\n",
    "    f.create_dataset('ob_err_comb', data=ob_err_comb)\n",
    "    f.create_dataset('yo_all', data=yo_all)\n",
    "    if prior_variable3d_len>0:\n",
    "        f.create_dataset('Xb3d', data=Xb3d)\n",
    "\n",
    "    metadata = {'Date': time.time(),\n",
    "                'proxy_dbversion':yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['dbversion'],\n",
    "                'exp_dir':yml_dict['core']['prior_dir'],\n",
    "                'Nens':str(prior_len)}\n",
    "    f.attrs.update(metadata)\n",
    "# append proxy to hdf5 file\n",
    "proxies.to_hdf(hdf5name, key='proxies')\n",
    "print('  prior2proxyunit hdf5 file saved: {}'.format(hdf5name))\n",
    "print('  Step 1 finished. Run Step 2: DeepDA_main.ipynb now')\n",
    "print('>>  Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3888, 150)\n"
     ]
    }
   ],
   "source": [
    "print(Xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[155 -89]\n",
      "(12,)\n",
      "[-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      "(16,)\n",
      "[-76 -66 -56 -46 -36 -26 -16  -6   4  14  24  34  44  54  64  74]\n",
      "(16, 12)\n",
      "[[-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]\n",
      " [-175 -145 -115  -85  -55  -25    5   35   65   95  125  155]]\n",
      "(16, 12)\n",
      "[[-76 -76 -76 -76 -76 -76 -76 -76 -76 -76 -76 -76]\n",
      " [-66 -66 -66 -66 -66 -66 -66 -66 -66 -66 -66 -66]\n",
      " [-56 -56 -56 -56 -56 -56 -56 -56 -56 -56 -56 -56]\n",
      " [-46 -46 -46 -46 -46 -46 -46 -46 -46 -46 -46 -46]\n",
      " [-36 -36 -36 -36 -36 -36 -36 -36 -36 -36 -36 -36]\n",
      " [-26 -26 -26 -26 -26 -26 -26 -26 -26 -26 -26 -26]\n",
      " [-16 -16 -16 -16 -16 -16 -16 -16 -16 -16 -16 -16]\n",
      " [ -6  -6  -6  -6  -6  -6  -6  -6  -6  -6  -6  -6]\n",
      " [  4   4   4   4   4   4   4   4   4   4   4   4]\n",
      " [ 14  14  14  14  14  14  14  14  14  14  14  14]\n",
      " [ 24  24  24  24  24  24  24  24  24  24  24  24]\n",
      " [ 34  34  34  34  34  34  34  34  34  34  34  34]\n",
      " [ 44  44  44  44  44  44  44  44  44  44  44  44]\n",
      " [ 54  54  54  54  54  54  54  54  54  54  54  54]\n",
      " [ 64  64  64  64  64  64  64  64  64  64  64  64]\n",
      " [ 74  74  74  74  74  74  74  74  74  74  74  74]]\n",
      "-115\n",
      "-76\n"
     ]
    }
   ],
   "source": [
    "yo_all = np.array([155, -89])\n",
    "print(yo_all)\n",
    "# lon\n",
    "x = np.arange(-175, 175, 30)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "# lat\n",
    "y = np.arange(-76, 77, 10)\n",
    "print(y.shape)\n",
    "print(y)\n",
    "\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "print(xv.shape)\n",
    "print(xv)\n",
    "print(yv.shape)\n",
    "print(yv)\n",
    "vi = 2\n",
    "print(xv.reshape(len(x)*len(y))[vi])\n",
    "print(yv.reshape(len(x)*len(y))[vi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n"
     ]
    }
   ],
   "source": [
    "print(499 % 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
