{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  OKAY.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Prepare prior for DeepDA\n",
    "\n",
    "OUTPUT:\n",
    "    example:\n",
    "    prior2proxyunit hdf5 file saved: /mnt/c/Users/mul450/Dropbox/git/deepDA/mlwrk/proxy/petmproxy3slices_v0.0.10gt1.csv.hdf5\n",
    "\n",
    "Mingsong Li\n",
    "1/15/2020\n",
    "'''\n",
    "from DeepDA_lib import modules_nc\n",
    "from DeepDA_lib import DeepDA_psm\n",
    "import h5py\n",
    "import time\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "try:\n",
    "    import bayspline\n",
    "except ImportError as e1:\n",
    "    print('Warning:', e1)\n",
    "try:\n",
    "    import bayspar\n",
    "except ImportError as e2:\n",
    "    print('Warning:', e2)\n",
    "try:\n",
    "    import bayfox\n",
    "except ImportError as e3:\n",
    "    print('Warning:', e3)\n",
    "try:\n",
    "    import baymag\n",
    "except ImportError as e4:\n",
    "    print('Warning:', e4)\n",
    "    \n",
    "print('>>  OKAY.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ########## Proxy + PSM ######### \n",
      ">>  Proxy error evaluation: proxy_err_psm_fixed\n",
      ">>  Proxy full list: ['Marine sediments_uk37', 'Marine sediments_tex86', 'Marine sediments_d18o_pooled', 'Marine sediments_mgca_pooled_bcp', 'Marine sediments_mgca_pooled_red']\n",
      ">>  Proxy blacklist: []\n",
      ">>  Proxy list to be assimilated: \n",
      "      ['Marine sediments_uk37', 'Marine sediments_tex86', 'Marine sediments_d18o_pooled', 'Marine sediments_mgca_pooled_bcp', 'Marine sediments_mgca_pooled_red']\n",
      "      Proxy quality control selection: None\n",
      "\n",
      " ########## read proxies database ######### \n",
      ">>  Done\n",
      " ########## Reconstruction ######### \n",
      ">>  recon_period 0 - 2. List: \n",
      "      [0 1 2]\n",
      "      nc_keyvalue {'biogem': 'fields_biogem_2d'}...\n",
      "      biogem: fields_biogem_2d\n",
      "      nc_keyvalue {'biogem': 'fields_biogem_3d'}...\n",
      "      biogem: fields_biogem_3d\n",
      ">>  Prior member size: 150\n",
      ">>  Number of 2d prior variables is: 1. List:\n",
      "      ['ocn_sur_temp']\n",
      ">>  Prior nc file list ['biogem/fields_biogem_2d.nc']\n",
      ">>  Number of 3d prior variables is: 0. List:\n",
      "      []\n",
      ">>  Prior nc file list []\n",
      ">>  OKAY.\n"
     ]
    }
   ],
   "source": [
    "config_name = \"DeepDA_config.yml\"\n",
    "#config_name = \"petmproxy3slices_v0.0.10gt1.csvexp_petm78_og1_qc_obs_20200203_test2.yml\"\n",
    "f = open(config_name, 'r')\n",
    "yml_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "f.close()\n",
    "\n",
    "t = 12  # last time slice, cGENIE\n",
    "k = 0   # first layer, SST\n",
    "# read config.yml settings\n",
    "print(' ########## Proxy + PSM ######### ')\n",
    "########## Proxy + PSM #########\n",
    "dir_proxy         = yml_dict['core']['proxy_dir']\n",
    "dir_proxy_data    = dir_proxy +'/'+ yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['dbversion']\n",
    "dir_proxy_save    = yml_dict['core']['wrkdir'] + '/'+ yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['dbversion']\n",
    "proxy_psm_type    = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_psm_type']\n",
    "proxy_assim2      = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_assim2']\n",
    "proxy_order       = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_order']\n",
    "proxy_err_eval   = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_err_eval']\n",
    "proxy_blacklist   = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_blacklist']\n",
    "psm_d18osw_adjust = yml_dict['psm']['bayesreg_d18o_pooled']['psm_d18osw_adjust']\n",
    "proxy_qc          = yml_dict['proxies']['proxy_qc']\n",
    "\n",
    "proxy_list = [item for item in proxy_order if item not in proxy_blacklist]\n",
    "print('>>  Proxy error evaluation: {}'.format(proxy_err_eval))\n",
    "print('>>  Proxy full list: {}'.format(proxy_order))\n",
    "print('>>  Proxy blacklist: {}'.format(proxy_blacklist))\n",
    "print('>>  Proxy list to be assimilated: ')\n",
    "print('      {}'.format(proxy_list))\n",
    "print('      Proxy quality control selection: {}'.format(proxy_qc))\n",
    "print('')\n",
    "print(' ########## read proxies database ######### ')\n",
    "#print(proxy_psm_type)\n",
    "#print(proxy_assim2)\n",
    "#print(psm_d18osw_adjust)\n",
    "\n",
    "# read proxies database\n",
    "proxies = pandas.read_csv(dir_proxy_data)\n",
    "proxies_len0 = len(proxies)\n",
    "#proxy_select = pandas.DataFrame()\n",
    "#print(proxy_select)\n",
    "proxy_select_0 = 0\n",
    "\n",
    "# check proxy data in the blacklist or not\n",
    "for j in range(proxies_len0):\n",
    "    # Read proxy type from the database\n",
    "    data_psm_type = proxies['Proxy'][j]\n",
    "    # initial default 0 : this proxy is not included\n",
    "    data_assimilate_i = 0\n",
    "    for jlist in range(len(proxy_list)):\n",
    "        if data_psm_type in proxy_assim2[proxy_list[jlist]]:\n",
    "            # find and save this proxy\n",
    "            data_assimilate_i = 1\n",
    "    if data_assimilate_i == 1:\n",
    "        #print('>>    file {}, {} included'.format(proxies.loc[j,'File'], data_psm_type))\n",
    "        if proxy_select_0 == 0:\n",
    "            proxy_select = proxies.iloc[[j]]\n",
    "            proxy_select = proxy_select.reset_index() # reset_index, avoid index error\n",
    "            proxy_select_0 = 1\n",
    "        else:\n",
    "            #proxy_select.append(proxies.iloc[[j]])\n",
    "            proxy_select = proxy_select.append(proxies.iloc[[j]], ignore_index=True)\n",
    "#print(proxy_select)\n",
    "\n",
    "# sort proxy data using given order\n",
    "proxy_select_1 = 0\n",
    "proxies_select_len0 = len(proxy_select)\n",
    "#print('>>  Database: proxy data length {}'.format(proxies_select_len0))\n",
    "#print(proxy_select)\n",
    "\n",
    "for i in range(len(proxy_order)):\n",
    "    proxy_order_i = proxy_assim2[proxy_order[i]]\n",
    "    for j in range(proxies_select_len0):\n",
    "#        print(j)\n",
    "        # Read proxy type from the database\n",
    "        data_psm_type = proxy_select['Proxy'][j]\n",
    "        # initial default 0 : this proxy is not included\n",
    "        data_assimilate_i = 0\n",
    "        if data_psm_type in proxy_order_i:\n",
    "            if proxy_select_1 == 0:\n",
    "                proxy_select_sort = proxy_select.iloc[[j]]\n",
    "                proxy_select_1 = 1\n",
    "            else:\n",
    "                proxy_select_sort = proxy_select_sort.append(proxy_select.iloc[[j]], ignore_index=True)\n",
    "\n",
    "# update proxies using sorted proxy order\n",
    "#proxies =   proxy_select\n",
    "proxies =   proxy_select_sort\n",
    "proxies_len = len(proxies)\n",
    "\n",
    "if proxies_len0 > proxies_len:\n",
    "    print('>>    Selected proxy data length {}'.format(proxies_len))\n",
    "    #print(proxies)\n",
    "#print(proxies.iloc[1,:])\n",
    "print('>>  Done')\n",
    "print(' ########## Reconstruction ######### ')\n",
    "\n",
    "nexp = yml_dict['core']['nexp']\n",
    "data_period_id    = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['data_period_id']\n",
    "data_period_idstd = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['data_period_idstd']\n",
    "recon_period = yml_dict['core']['recon_period']\n",
    "recon_timescale = yml_dict['core']['recon_timescale_interval']\n",
    "recon_period_full = np.arange(recon_period[0],recon_period[1]+1,recon_timescale)\n",
    "recon_period_len = recon_period_full.shape[0]\n",
    "geologic_age = yml_dict['core']['geologic_age']\n",
    "print('>>  recon_period {} - {}. List: '.format(recon_period[0], recon_period[1]))\n",
    "print('      {}'.format(recon_period_full))\n",
    "\n",
    "# Prior\n",
    "########## Prior #########\n",
    "prior_source = yml_dict['prior']['prior_source'] #\n",
    "prior_state_variable = yml_dict['prior'][prior_source]['state_variable']  # note: ['2d': xxx; '3d': xxx]\n",
    "\n",
    "# save prior variable list\n",
    "prior_variable_dict = []  # variable list\n",
    "prior_nc_file_list = []  # nc file list\n",
    "prior_variable_dict_3d = []  # variable list\n",
    "prior_nc_file_list_3d = []  # nc file list\n",
    "\n",
    "for key, value in prior_state_variable.items():\n",
    "    nc_keyvalue = prior_state_variable[key]['ncname']  # note: 2d dict\n",
    "    \n",
    "    print('      nc_keyvalue {}...'.format(nc_keyvalue))\n",
    "    for key1, value1 in nc_keyvalue.items():\n",
    "        print('      {}: {}'.format(key1,value1))\n",
    "        \n",
    "        for i in range(len(prior_state_variable[key][value1])):\n",
    "            if key in ['2d']:\n",
    "                prior_variable_dict.append(prior_state_variable[key][value1][i])\n",
    "                prior_nc_file_list.append(key1+'/'+value1+'.nc')\n",
    "            elif key in ['3d']:\n",
    "                prior_variable_dict_3d.append(prior_state_variable[key][value1][i])\n",
    "                prior_nc_file_list_3d.append(key1+'/'+value1+'.nc')\n",
    "\n",
    "dum_lon_offset = yml_dict['prior'][prior_source]['dum_lon_offset'] # longitude offset\n",
    "\n",
    "########  Prior read   ########\n",
    "dir_prior = yml_dict['core']['prior_dir']\n",
    "dir_prior_full = os.listdir(dir_prior)\n",
    "prior_len = len(dir_prior_full)\n",
    "#print('dir_prior: {}'.format(dir_prior))\n",
    "print('>>  Prior member size: {}'.format(prior_len))\n",
    "\n",
    "# prepare variable list for Xb\n",
    "prior_variable2d_len = len(prior_variable_dict)\n",
    "prior_variable3d_len = len(prior_variable_dict_3d)\n",
    "print('>>  Number of 2d prior variables is: {}. List:'.format(prior_variable2d_len))\n",
    "print('      {}'.format(prior_variable_dict))\n",
    "print('>>  Prior nc file list {}'.format(prior_nc_file_list))\n",
    "print('>>  Number of 3d prior variables is: {}. List:'.format(prior_variable3d_len))\n",
    "print('      {}'.format(prior_variable_dict_3d))\n",
    "print('>>  Prior nc file list {}'.format(prior_nc_file_list_3d))\n",
    "\n",
    "######## Ye   ########\n",
    "# for saving proxy unit data Ye\n",
    "Ye       = np.full((proxies_len,prior_len),np.nan)\n",
    "obvalue  = np.full((proxies_len,recon_period_len),np.nan)\n",
    "ob_err   = np.full((proxies_len,recon_period_len),np.nan) # data obs error\n",
    "ob_err0  = np.full((proxies_len,recon_period_len),np.nan) # PSM obs error\n",
    "ob_err_comb  = np.full((proxies_len,recon_period_len),np.nan) # PSM obs error\n",
    "yo_all = np.full((proxies_len,2),np.nan) # PSM obs error\n",
    "print('>>  OKAY.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  0. PSM for tex86 is bayesreg_tex86\n",
      ">>  1. PSM for d18o_morozovella is bayesreg_d18o_pooled\n",
      ">>  Check the consistency of the config.yml file and proxy database\n",
      ">>  OKAY.\n"
     ]
    }
   ],
   "source": [
    "# check the consistency of the config.yml file and proxy database\n",
    "# AND get obs R\n",
    "data_psm_mgca_find = 0\n",
    "for j in range(proxies_len):\n",
    "    # Read proxy type from the database\n",
    "    data_psm_type = proxies['Proxy'][j]\n",
    "    # Read allowed proxy from the DTDA-config.yml\n",
    "    data_psm_type_find = 0\n",
    "    for key, value in proxy_assim2.items():\n",
    "        #print(key,value)\n",
    "        # find this proxy type exist or not, how many times it occurrs\n",
    "        if data_psm_type in proxy_assim2[key]:\n",
    "            data_psm_type_find = data_psm_type_find + 1\n",
    "    if data_psm_type_find == 1:\n",
    "        for key, value in proxy_psm_type.items():\n",
    "            if data_psm_type in proxy_assim2[key]:\n",
    "                data_psm_key = key\n",
    "        proxy_psm_type_i = proxy_psm_type[data_psm_key]\n",
    "        print('>>  {}. PSM for {} is {}'.format(j, data_psm_type,proxy_psm_type_i))\n",
    "        \n",
    "    elif data_psm_type_find == 0:\n",
    "        print('>>  Warning, {} in database is not find in DTDA-config.yml dictionary'.format(data_psm_type))\n",
    "    else:\n",
    "        print('>>  Warning, {} in database appears more than 1 time in DTDA-config.yml dictionary'.format(data_psm_type))\n",
    "    \n",
    "    # Now PSM type has been found. Let's precal Ye\n",
    "    \n",
    "    if proxy_psm_type_i in ['bayesreg_mgca_pooled_red','bayesreg_mgca_pooled_bcp']:\n",
    "        data_psm_mgca_find = 1\n",
    "\n",
    "if data_psm_mgca_find == 1:\n",
    "    print('>>  MgCa proxy found')\n",
    "print('>>  Check the consistency of the config.yml file and proxy database')\n",
    "print('>>  OKAY.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  Reading prior state variables\n",
      ">>  Shape of dum_dmax 16, dum_imax 36, dum_jmax 36, dum_ijmax 1296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mul450/miniconda3/envs/lmr_py3/lib/python3.6/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Last member: 149: ML.petm008.ID.9: ocn_sur_temp\n",
      ">>  Units of state variables ['ocn_sur_temp']: []\n",
      ">>  OKAY.\n"
     ]
    }
   ],
   "source": [
    "# build Ye\n",
    "# If there is no field in the model, convert model unit to proxy unit\n",
    "print('>>  Reading prior state variables')\n",
    "# read first variable data, first time slice, to get the shape of prior grid\n",
    "try:\n",
    "    #x0 = Dataset(dir_prior+'/'+dir_prior_full[0]+'/'+ nc_file_2d).variables[prior_variable_dict[0]][0,:,:]\n",
    "    x1 = Dataset(dir_prior+'/'+dir_prior_full[0]+'/'+ prior_nc_file_list_3d[0]).variables[prior_variable_dict_3d[0]][0,:,:,:]\n",
    "    #print('    Shape of prior 2d grid {}'.format(x0.shape))\n",
    "    dum_dmax = x1.shape[0] # depth\n",
    "    dum_imax = x1.shape[1]  # lon\n",
    "    dum_jmax = x1.shape[2]  # lat\n",
    "except:\n",
    "    try:\n",
    "        x0 = Dataset(dir_prior+'/'+dir_prior_full[0]+'/'+ prior_nc_file_list[0]).variables[prior_variable_dict[0]][0,:,:]\n",
    "        dum_imax = 36 #x1.shape[0]  # lon\n",
    "        dum_jmax = 36 #x1.shape[1]  # lat\n",
    "        dum_dmax = 16\n",
    "    except:\n",
    "        dum_dmax = 16\n",
    "        dum_imax = 36\n",
    "        dum_jmax = 36\n",
    "# prepare 2d Xb for lon-lat state \n",
    "dum_ijmax = dum_imax*dum_jmax  # lonn * latn\n",
    "print('>>  Shape of dum_dmax {}, dum_imax {}, dum_jmax {}, dum_ijmax {}'.format(dum_dmax,dum_imax,dum_jmax,dum_ijmax))\n",
    "# save units of each variable\n",
    "prior_variable_units = list()\n",
    "prior_variable_units_init = 0\n",
    "# nan matrix for storing 2d and 3d variables\n",
    "if prior_variable2d_len>0:\n",
    "    Xb_shape = (prior_variable2d_len*dum_jmax*dum_imax, prior_len)  # lonn * latn * varn\n",
    "    Xb   = np.full(Xb_shape,np.nan)\n",
    "# prep 3d version of Xb\n",
    "if prior_variable3d_len > 0:\n",
    "    Xb3d_shape = (prior_variable3d_len*dum_dmax*dum_jmax*dum_imax, prior_len)  # lonn * latn * varn\n",
    "    Xb3d = np.full(Xb3d_shape,np.nan)\n",
    "    # read prior and save Xb\n",
    "    #Xb = np.full((dum_ijmax, prior_len),np.nan)\n",
    "\n",
    "if data_psm_mgca_find == 1:\n",
    "    print('>>  Prepare Mg/Ca related state variable ...')\n",
    "    # for Mg/Ca SST proxy salinity, ph, omega\n",
    "    Xb_sal       = np.full(Xb_shape,np.nan)\n",
    "    Xb_ph        = np.full(Xb_shape,np.nan)\n",
    "    Xb_omega     = np.full(Xb_shape,np.nan)\n",
    "    spp = 'all'\n",
    "    # ``1`` for reductive, ``0`` for BCP (Barker).\n",
    "    cleaningr = np.tile(np.array([1]),prior_len)\n",
    "    cleaningb = np.tile(np.array([0]),prior_len)\n",
    "# read units of each variable from prior and save as prior_variable_units\n",
    "if prior_variable3d_len > 0:\n",
    "    for j in range(prior_variable2d_len):\n",
    "        name_nc_2d = dir_prior+'/'+dir_prior_full[0]+'/'+ prior_nc_file_list[j]\n",
    "        nc_field = prior_variable_dict[j]\n",
    "        unit_j = Dataset(name_nc_2d).variables[nc_field].units\n",
    "        prior_variable_units.append((unit_j))\n",
    "if prior_variable3d_len > 0:\n",
    "    for j in range(prior_variable3d_len):\n",
    "        name_nc_3d = dir_prior+'/'+dir_prior_full[0]+'/'+ prior_nc_file_list_3d[j]\n",
    "        nc_field = prior_variable_dict_3d[j]\n",
    "        unit_j = Dataset(name_nc_3d).variables[nc_field].units\n",
    "        prior_variable_units.append((unit_j))\n",
    "    \n",
    "# loop for each member of an ensemble\n",
    "for i in range(prior_len):\n",
    "    # loop for each variable of each member\n",
    "    if prior_variable2d_len>0:\n",
    "        for j in range(prior_variable2d_len):\n",
    "            # full directory of netcdf file\n",
    "            name_nc_2d = dir_prior+'/'+dir_prior_full[i]+'/'+ prior_nc_file_list[j]\n",
    "            j0 = dum_ijmax * j\n",
    "            j1 = dum_ijmax * (j+1)\n",
    "            nc_field = prior_variable_dict[j]\n",
    "            x = Dataset(name_nc_2d).variables[nc_field][t,:,:]  # time-lat-lon\n",
    "            \n",
    "            Xb[j0:j1,i] = np.copy(x.reshape(dum_ijmax))  # var-lat-lon: Nx x 1\n",
    "            \n",
    "            if data_psm_mgca_find == 1:\n",
    "                try:\n",
    "                    name_nc_2d_mgca = dir_prior+'/'+dir_prior_full[i]+'/biogem/'+ 'fields_biogem_2d.nc'\n",
    "                    x = Dataset(name_nc_2d_mgca).variables['ocn_sur_sal'][t,:,:] # time-lat-lon\n",
    "                    Xb_sal[j0:j1,i] = np.copy(x.reshape(dum_ijmax)) # var-lat-lon: Nx x 1\n",
    "                    name_nc_3d_mgca = dir_prior+'/'+dir_prior_full[i]+'/biogem/'+ 'fields_biogem_3d.nc'\n",
    "                    x = Dataset(name_nc_3d_mgca).variables['misc_pH'][t,k,:,:] # time-lat-lon\n",
    "                    Xb_ph[j0:j1,i] = np.copy(x.reshape(dum_ijmax)) # var-lat-lon: Nx x 1\n",
    "                    x = Dataset(name_nc_3d_mgca).variables['carb_ohm_cal'][t,k,:,:] # time-lat-lon\n",
    "                    Xb_omega[j0:j1,i] = np.copy(x.reshape(dum_ijmax)) # var-lat-lon: Nx x 1\n",
    "                except:\n",
    "                    if i == 0:\n",
    "                        # warning one time\n",
    "                        print('>>  Warning: reading state variable error. ocn_sur_sal, misc_pH, carb_ohm_cal')\n",
    "            # print the last one data\n",
    "            if i > prior_len-2:\n",
    "                print('    Last member: {}: {}: {}'.format(i, dir_prior_full[i], prior_variable_dict[j]))\n",
    "        Xb = np.ma.MaskedArray(Xb, Xb >= 9.9692e+36)\n",
    "    # if 3d variables are used\n",
    "    if prior_variable3d_len > 0:\n",
    "        for k in range(prior_variable3d_len):\n",
    "            name_nc_3d = dir_prior+'/'+dir_prior_full[i]+'/'+ prior_nc_file_list_3d[k]\n",
    "            nc_field = prior_variable_dict_3d[k]\n",
    "            k0 = dum_ijmax*dum_dmax * k\n",
    "            k1 = dum_ijmax*dum_dmax * (k+1)\n",
    "            x = Dataset(name_nc_3d).variables[nc_field][t,:,:,:]  # time-depth-lat-lon\n",
    "            Xb3d[k0:k1,i] = np.copy(x.reshape(dum_dmax*dum_ijmax)) # var-depth-lat-lon\n",
    "        Xb3d = np.ma.MaskedArray(Xb3d, Xb3d >= 9.9692e+36)\n",
    "print('>>  Units of state variables {}: {}'.format(prior_variable_dict+prior_variable_dict_3d,prior_variable_units))\n",
    "\n",
    "print('>>  OKAY.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Ye calculation ####\n",
      "\n",
      ">>  0. schoon2013-fursectionnorthsea.txt, grid [lon lat] [14, 32], grid id 1166\n",
      ">>  PSM for tex86 is bayesreg_tex86, prior mean is 17.58554220199585, variance is 8.574433476623026\n",
      ">>   bayesreg_tex86. Mean of Ye is 0.529581, variance is 0.001657 \n",
      ">>   0. Proxy variance from PSM is 0.004709, from PSM and selected interval is 0.009609 \n",
      ">>   1. Proxy variance from PSM is 0.004847, from PSM and selected interval is 0.006016 \n",
      ">>   2. Proxy variance from PSM is 0.004613, from PSM and selected interval is 0.006414 \n",
      "\n",
      ">>  1. kozdon2013-865d18omorozovellasims.txt, grid [lon lat] [1, 19], grid id 685\n",
      ">>  PSM for d18o_morozovella is bayesreg_d18o_pooled, prior mean is 34.39700023651123, variance is 9.344396974953979\n",
      ">>  Prior is [33.57349014 34.12887573 30.69619942 34.28969193 34.03006363 33.57300568\n",
      " 32.26852036 31.22074318 31.54815865 33.79447556 34.66971588 30.89491272\n",
      " 27.64361382 32.05685043 34.16950989 34.87135315 28.3027153  33.76076508\n",
      " 31.54567909 33.5694313  29.29301262 31.6589241  30.32250595 31.18109512\n",
      " 27.78229523 34.10218048 28.83289719 30.61797333 33.31474304 34.0868454\n",
      " 33.87979507 33.09749222 32.29188919 30.09930992 30.83588028 28.43485451\n",
      " 34.30435944 31.88685036 30.40224457 32.78900146 29.20979118 34.04518509\n",
      " 30.39857674 30.7153244  34.20137024 33.98411942 28.97279549 31.74213409\n",
      " 28.22349739 33.77928543 32.03718567 31.89745522 32.25539017 29.89420509\n",
      " 29.59038353 32.67717361 33.08515549 30.54550552 31.21637535 33.2526207\n",
      " 32.88940048 32.64094925 28.93626595 34.08568573 33.79909515 33.97808075\n",
      " 31.93482208 34.00948334 32.57029724 29.32120705 30.58138275 32.73831177\n",
      " 32.51823044 32.89596176 32.66856384 39.62905502 37.51328659 39.10073853\n",
      " 38.98862457 38.11299515 34.53812027 36.1448555  35.79621124 39.06966782\n",
      " 33.32351303 37.01738358 35.42819595 33.9526329  35.50834656 35.35311508\n",
      " 34.84125137 38.48726273 37.85103989 36.91086578 36.62295151 33.85781097\n",
      " 34.58886719 37.97006226 33.08864212 35.87981415 39.374897   38.42137146\n",
      " 35.86335373 36.4018631  38.84722519 38.14859009 38.2525177  39.36207199\n",
      " 36.84390259 35.03746033 36.51848221 35.86016846 38.98395157 35.70184708\n",
      " 33.89430618 34.28819275 38.47913742 38.79572678 36.34020996 35.36470032\n",
      " 37.67322159 36.69970322 37.66901779 38.19901657 34.10514832 39.35742188\n",
      " 37.77523041 37.77864456 35.83179474 38.10279846 37.01339722 37.86660004\n",
      " 37.28687286 35.11193085 38.53505325 38.48900604 37.37459564 39.45539856\n",
      " 37.96232605 38.27375412 38.66857147 37.88903046 36.80392456 35.34724808\n",
      " 36.10368347 38.9424324  33.12713623 36.74636459 33.12407303 34.76816559]\n",
      ">>  Ye is [-4.21356288 -4.35410995 -3.55711487 -4.39153772 -4.32550057 -4.23453024\n",
      " -3.91452093 -3.67320776 -3.75359171 -4.27842219 -4.48003722 -3.60184442\n",
      " -2.85199687 -3.86349554 -4.35104162 -4.52738892 -3.00738075 -4.25472199\n",
      " -3.75358418 -4.21081365 -3.23986122 -3.77728477 -3.47344677 -3.67430141\n",
      " -2.8830523  -4.34334043 -3.12008584 -3.53459983 -4.15779935 -4.3325393\n",
      " -4.27992844 -4.10354503 -3.926049   -3.41855923 -3.58004848 -3.02399023\n",
      " -4.39176606 -3.83109117 -3.49135412 -4.04701919 -3.2081394  -4.33160054\n",
      " -3.48314007 -3.56880181 -4.36254574 -4.31631326 -3.15059518 -3.79551707\n",
      " -2.98817526 -4.27210147 -3.86385896 -3.82859645 -3.92230617 -3.36823674\n",
      " -3.31047392 -4.01615093 -4.1038507  -3.51280923 -3.67407574 -4.15153608\n",
      " -4.06418327 -4.00586316 -3.15501798 -4.32905653 -4.26956706 -4.31067378\n",
      " -3.83064908 -4.31712573 -3.98925029 -3.23970206 -3.52484647 -4.02618321\n",
      " -3.97658115 -4.0659193  -4.00832583 -5.60658656 -5.11927526 -5.50209446\n",
      " -5.47663602 -5.26715112 -4.44243957 -4.81033151 -4.73423008 -5.4911661\n",
      " -4.15440415 -5.01898692 -4.64717736 -4.29641211 -4.6661167  -4.62763506\n",
      " -4.5074948  -5.34763571 -5.19589307 -4.99401266 -4.92441484 -4.28373562\n",
      " -4.45451604 -5.24121929 -4.10451213 -4.74839272 -5.55886278 -5.34718056\n",
      " -4.75475556 -4.87308833 -5.44162517 -5.28155826 -5.29812222 -5.55893642\n",
      " -4.97658217 -4.55813743 -4.89309238 -4.74863945 -5.46973058 -4.71335221\n",
      " -4.29042258 -4.38226638 -5.35437511 -5.4160182  -4.86214937 -4.63667661\n",
      " -5.16423173 -4.93824672 -5.15421185 -5.29110942 -4.34693328 -5.55270055\n",
      " -5.19132833 -5.18144397 -4.73779561 -5.25581094 -5.00382282 -5.20483039\n",
      " -5.07520332 -4.56064154 -5.37428144 -5.35379189 -5.09687138 -5.58275533\n",
      " -5.23576946 -5.3132192  -5.39592719 -5.22222762 -4.96587218 -4.62997404\n",
      " -4.80430118 -5.45594963 -4.11885785 -4.95350475 -4.11481234 -4.499123  ]\n",
      ">>   bayesreg_d18o_pooled. Mean of Ye is -4.409490, variance is 0.501336 \n",
      ">>   0. Proxy variance from PSM is 0.290276, from PSM and selected interval is 0.351285 \n",
      ">>   1. Proxy variance from PSM is 0.289664, from PSM and selected interval is 0.314945 \n",
      ">>   2. Proxy variance from PSM is 0.299388, from PSM and selected interval is 0.384652 \n",
      "\n",
      ">>  obvalue\n",
      ">>  [[ 0.53    0.738   0.56  ]\n",
      " [-3.1044 -3.9734 -3.2864]]\n",
      ">>  ob_err0\n",
      ">>  [[0.00470944 0.00484684 0.00461348]\n",
      " [0.29027606 0.28966411 0.29938818]]\n",
      ">>  from psm and interval:  ob_err_comb\n",
      ">>  [[0.00960944 0.00601648 0.00641378]\n",
      " [0.35128506 0.31494511 0.38465218]]\n",
      ">>  OKAY.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##### Ye calculation ####\n",
    "print('##### Ye calculation ####')\n",
    "# precal_Ye\n",
    "proi = 0\n",
    "for j in range(proxies_len):\n",
    "    # read lon lat for each line of proxy\n",
    "    dum_lat = proxies['Lat'][j]  # (paleo)latitude of this site\n",
    "    dum_lon = proxies['Lon'][j]  # (paleo)longitude of this site\n",
    "    yo_all[proi,:] = np.array([dum_lon, dum_lat])  # save location of this site\n",
    "    \n",
    "    lonlat = modules_nc.cal_find_ij(dum_lon,dum_lat,dum_lon_offset,dum_imax,dum_jmax) \n",
    "    # output [lon, lat], \n",
    "    # lon ranges from 0 (-180) to 35 (180), lat ranges from 0 (-90) to 35 (90)\n",
    "\n",
    "    Filei = proxies['File'][j]\n",
    "    ######################## TO DO: adjusted to include d13C or other proxies ##############\n",
    "    # find 1d grid location\n",
    "    lonlati = lonlat[1] * dum_jmax + lonlat[0]\n",
    "    # read prior\n",
    "    prior_1grid = np.copy(Xb[lonlati,:])   # prior\n",
    "    \n",
    "    #print(prior_1grid.shape)\n",
    "    #print(prior_1grid)\n",
    "    ######################## TO DO: add  dum_ijmax * j etc. ##############\n",
    "    \n",
    "    # Read proxy type from the database\n",
    "    data_psm_type = proxies['Proxy'][j]\n",
    "    \n",
    "    # Read allowed proxy from the DTDA-config.yml\n",
    "    data_psm_type_find = 0\n",
    "    for key, value in proxy_assim2.items():\n",
    "        #print(key,value)\n",
    "        # find this proxy type exist or not, how many times it occurrs\n",
    "        if data_psm_type in proxy_assim2[key]:\n",
    "            data_psm_type_find = data_psm_type_find + 1\n",
    "    if data_psm_type_find == 1:\n",
    "        for key, value in proxy_psm_type.items():\n",
    "            if data_psm_type in proxy_assim2[key]:\n",
    "                data_psm_key = key\n",
    "        proxy_psm_type_i = proxy_psm_type[data_psm_key]\n",
    "        print('')\n",
    "        print('>>  {}. {}, grid [lon lat] {}, grid id {}'.format(j,Filei,lonlat,lonlati))\n",
    "        print('>>  PSM for {} is {}, prior mean is {}, variance is {}'.format(data_psm_type,proxy_psm_type_i, np.mean(prior_1grid), np.var(prior_1grid)))\n",
    "    elif data_psm_type_find == 0:\n",
    "        print('Warning, this proxy type in database is not find in DTDA-config.yml dictionary')\n",
    "    else:\n",
    "        print('Warning, this proxy type in database appears more than 1 time in DTDA-config.yml dictionary')\n",
    "    \n",
    "    # Now PSM type has been found. Let's precal Ye\n",
    "    \n",
    "    if proxy_psm_type_i in ['bayesreg_d18o_pooled']:\n",
    "        #try:\n",
    "            # bayfox\n",
    "        d18o_localsw = DeepDA_psm.d18o_localsw(abs(dum_lat))\n",
    "        psm_d18osw_adjust = yml_dict['psm']['bayesreg_d18o_pooled']['psm_d18osw_adjust']\n",
    "        # total d18osw = d18o_localsw + d18o_adj + psm_d18osw_adjust\n",
    "        # d18o_adj has been included in the bayfox model\n",
    "        print('>>  Prior is {}'.format(prior_1grid))\n",
    "        prediction_d18O = bayfox.predict_d18oc(prior_1grid,d18o_localsw + psm_d18osw_adjust) # pool model for bayfox\n",
    "        #print('>>  prediction_d18O.ensemble shape {}'.format(prediction_d18O.ensemble.shape))\n",
    "        Ye[proi,:] = np.mean(prediction_d18O.ensemble, axis = 1)\n",
    "        yo_all[proi,:] = np.array([dum_lon, dum_lat])\n",
    "        print('>>  Ye is {}'.format(Ye[proi,:]))\n",
    "        print('>>   {}. Mean of Ye is {:.6f}, variance is {:.6f} '.format(proxy_psm_type_i, np.mean(Ye[proi,:]), np.var(Ye[proi,:],ddof=1)))\n",
    "        for reconi in range(recon_period_len):\n",
    "            obvalue[proi,reconi] = proxies[data_period_id[reconi]][j]\n",
    "            ob_err[proi,reconi] = proxies[data_period_idstd[reconi]][j] ** 2\n",
    "            if proxy_err_eval in ['proxy_err_psm']:\n",
    "                ob_err0[proi,reconi]= DeepDA_psm.obs_estimate_r_d18o(obvalue[proi,reconi], d18o_localsw+psm_d18osw_adjust)\n",
    "            else:\n",
    "                ob_err0[proi,reconi]= DeepDA_psm.obs_estimate_r_fixed_d18o(15)\n",
    "            ob_err_comb[proi,reconi] = np.nansum([ob_err[proi,reconi], ob_err0[proi,reconi]])\n",
    "            if ob_err_comb[proi,reconi] == 0: ob_err_comb[proi,reconi] = np.nan\n",
    "            print('>>   {}. Proxy variance from PSM is {:.6f}, from PSM and selected interval is {:.6f} '.format(reconi,ob_err0[proi,reconi], ob_err_comb[proi,reconi]))\n",
    "            \n",
    "            # Quality control\n",
    "            qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc)\n",
    "            #print(qc_i)\n",
    "            if qc_i:\n",
    "                if proxy_qc is not None:\n",
    "                    print('    Pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "            else:\n",
    "                ob_err_comb[proi,reconi] = np.nan\n",
    "                if proxy_qc is not None:                    \n",
    "                    print('    Did not pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "        proi = proi + 1  # increasement\n",
    "        #except:\n",
    "        #    print('>>  Warning {}'.format(proxy_psm_type_i))\n",
    "    elif proxy_psm_type_i in ['bayesreg_tex86']:\n",
    "        # bayspar\n",
    "        #try:\n",
    "        # bayspar\n",
    "        search_tol_i = yml_dict['psm']['bayesreg_tex86']['search_tol']\n",
    "        nens_i = yml_dict['psm']['bayesreg_tex86']['nens']\n",
    "        prediction = bayspar.predict_tex_analog(prior_1grid, temptype = 'sst', search_tol = search_tol_i, nens=nens_i)\n",
    "        Ye[proi,:] = np.mean(prediction.ensemble, axis = 1)\n",
    "        print('>>   {}. Mean of Ye is {:.6f}, variance is {:.6f} '.format(proxy_psm_type_i, np.mean(Ye[proi,:]), np.var(Ye[proi,:],ddof=1)))\n",
    "        yo_all[proi,:] = np.array([dum_lon, dum_lat])\n",
    "        for reconi in range(recon_period_len):\n",
    "            obvalue[proi,reconi] = proxies[data_period_id[reconi]][j]\n",
    "            ob_err[proi,reconi] = proxies[data_period_idstd[reconi]][j] ** 2\n",
    "            if proxy_err_eval in ['proxy_err_psm']:\n",
    "                ob_err0[proi,reconi]= DeepDA_psm.obs_estimate_r_tex86(np.array([31]), 'sst', 15)\n",
    "            else:\n",
    "                ob_err0[proi,reconi]= DeepDA_psm.obs_estimate_r_fixed_tex86(31)\n",
    "            #obvalue[proi,] = proxies['Lat'][j]\n",
    "\n",
    "            ob_err_comb[proi,reconi] = np.nansum([ob_err[proi,reconi], ob_err0[proi,reconi]])\n",
    "            if ob_err_comb[proi,reconi] == 0: ob_err_comb[proi,reconi] = np.nan\n",
    "            print('>>   {}. Proxy variance from PSM is {:.6f}, from PSM and selected interval is {:.6f} '.format(reconi,ob_err0[proi,reconi], ob_err_comb[proi,reconi]))\n",
    "            # Quality control\n",
    "            qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc)\n",
    "            if qc_i:\n",
    "                if proxy_qc is not None:\n",
    "                    print('    Pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "            else:\n",
    "                ob_err_comb[proi,reconi] = np.nan\n",
    "                if proxy_qc is not None:                    \n",
    "                    print('    Did not pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "        proi = proi + 1  # increasement\n",
    "        #except:\n",
    "        #    print('>>  Warning {}'.format(proxy_psm_type_i))\n",
    "        #    print('>>  search_tol too small for {}: mean sst is {}'.format(j, np.mean(prior_1grid)))\n",
    "            \n",
    "    elif proxy_psm_type_i in ['bayesreg_uk37']:\n",
    "        # \n",
    "        print('... bayesreg_uk37: To be done ...')\n",
    "        \n",
    "    elif proxy_psm_type_i in ['bayesreg_mgca_pooled_red', 'bayesreg_mgca_pooled_bcp']:\n",
    "        if proxy_psm_type_i in ['bayesreg_mgca_pooled_red']:\n",
    "            clearning_one = cleaningr\n",
    "            proxy_explain = 'reductive'\n",
    "        elif proxy_psm_type_i in ['bayesreg_mgca_pooled_bcp']:\n",
    "            clearning_one = cleaningb\n",
    "            proxy_explain = 'barker'\n",
    "        #try:\n",
    "        # prior_1grid = np.copy(Xb[lonlati,:])   # prior\n",
    "        salinity =  np.copy(Xb_sal[lonlati,:])\n",
    "        ph       =  np.copy(Xb_ph[lonlati,:])\n",
    "        omega    =  np.copy(Xb_omega[lonlati,:])\n",
    "\n",
    "        prediction_mgca = baymag.predict_mgca(prior_1grid, clearning_one, salinity, ph, omega, spp) # pool model for baymag reductive\n",
    "        #prediction_mgca = baymag.predict_mgca(prior_1grid, cleaningr, salinity, ph, omega, spp) # pool model for baymag reductive\n",
    "        pred_mgca_adj = baymag.sw_correction(prediction_mgca, np.array([geologic_age]))\n",
    "        Ye[proi,:] = np.mean(pred_mgca_adj.ensemble, axis = 1)\n",
    "        print('>>   {}. Mean of Ye is {:.6f}, variance is {:.6f} '.format(proxy_psm_type_i, np.mean(Ye[proi,:]), np.var(Ye[proi,:],ddof=1)))\n",
    "        yo_all[proi,:] = np.array([dum_lon, dum_lat])\n",
    "        \n",
    "        for reconi in range(recon_period_len):\n",
    "            obvalue[proi,reconi] = proxies[data_period_id[reconi]][j]\n",
    "            ob_err[proi,reconi]  = proxies[data_period_idstd[reconi]][j] ** 2\n",
    "            #obs_estimate_r_mgca_pooled(obs, cleaning, salinity, ph, omega, spp, age):\n",
    "            if proxy_err_eval in ['proxy_err_psm']:\n",
    "                ob_err0[proi,reconi] = DeepDA_psm.obs_estimate_r_mgca_pooled(obvalue[proi,reconi], clearning_one[0], np.mean(salinity), np.mean(ph), np.mean(omega), spp, geologic_age)\n",
    "            else:\n",
    "                ob_err0[proi,reconi] = DeepDA_psm.obs_estimate_r_fixed_mgca_pooled((15, 16), clearning_one[0], np.mean(salinity), np.mean(ph), np.mean(omega), spp, geologic_age)\n",
    "            ob_err_comb[proi,reconi] = np.nansum([ob_err[proi,reconi], ob_err0[proi,reconi]])\n",
    "            if ob_err_comb[proi,reconi] == 0: ob_err_comb[proi,reconi] = np.nan\n",
    "            print('>>   {}. Proxy variance from PSM is {:.6f}, from PSM and selected interval is {:.6f} '.format(reconi,ob_err0[proi,reconi], ob_err_comb[proi,reconi]))\n",
    "            # Quality control\n",
    "            qc_i = DeepDA_psm.obs_qc(Ye[proi,:], obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc)\n",
    "            if qc_i:\n",
    "                if proxy_qc is not None:\n",
    "                    print('      Pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "            else:\n",
    "                ob_err_comb[proi,reconi] = np.nan\n",
    "                if proxy_qc is not None:                    \n",
    "                    print('      Warning! Did not pass QC. ye {}, obs {}, obs_var {}, qc {}'.format(np.mean(Ye[proi,:]), obvalue[proi,reconi], ob_err_comb[proi,reconi], proxy_qc))\n",
    "            print('      {}: mean salinity {}, ph {}, omega {}'.format(proxy_explain,np.mean(salinity), np.mean(ph), np.mean(omega)))\n",
    "        proi = proi + 1  # increasement\n",
    "\n",
    "    else:\n",
    "        a = 1\n",
    "    \n",
    "    #innovi = obvalue[proi,:] - np.mean(Ye[proi,:])\n",
    "    #std3 = np.sqrt( ob_err0[proi,:] ) * 3\n",
    "    #print('Innovation {}, 3xStd {}'.format(innovi, std3))\n",
    "    #print( innovi > std3)\n",
    "    #ob_err0[proi,:] = np.ma.masked_where(innovi > std3, ob_err0[proi,:])\n",
    "    #print( 'new ob_err0 {}'.format(ob_err0[proi,:]))\n",
    "    \n",
    "print('')\n",
    "print('>>  obvalue'.format())\n",
    "print('>>  {}'.format(obvalue))\n",
    "print('>>  ob_err0'.format())\n",
    "print('>>  {}'.format(ob_err0))\n",
    "print('>>  from psm and interval:  ob_err_comb'.format( ob_err_comb))\n",
    "print('>>  {}'.format( ob_err_comb))\n",
    "\n",
    "print('>>  OKAY.')\n",
    "#print(Ye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  prior2proxyunit hdf5 file saved: /mnt/d/DeepDA/wrk/petmproxy3slices_v0.0.10gt2.csv.exp_petm78_ogt2_20200210_test0_precal_ye.hdf5\n",
      ">>  Step 1 finished. Run Step 2: DeepDA_main.ipynb now\n",
      ">>  Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mul450/miniconda3/envs/lmr_py3/lib/python3.6/site-packages/pandas/core/generic.py:2530: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->['File', 'Glassy', 'Proxy', 'Site', 'Type']]\n",
      "\n",
      "  pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "hdf5name = dir_proxy_save +'.' + nexp + '_precal_ye.hdf5'\n",
    "with h5py.File(hdf5name, 'w') as f:\n",
    "    if prior_variable2d_len>0:\n",
    "        f.create_dataset('Xb', data=Xb)\n",
    "    f.create_dataset('obvalue', data=obvalue)\n",
    "    f.create_dataset('Ye', data=np.transpose(Ye))\n",
    "    f.create_dataset('ob_err', data=ob_err)\n",
    "    f.create_dataset('ob_err0', data=ob_err0)\n",
    "    f.create_dataset('ob_err_comb', data=ob_err_comb)\n",
    "    f.create_dataset('yo_all', data=yo_all)\n",
    "    if prior_variable3d_len>0:\n",
    "        f.create_dataset('Xb3d', data=Xb3d)\n",
    "\n",
    "    metadata = {'Date': time.time(),\n",
    "                'proxy_dbversion':yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['dbversion'],\n",
    "                'exp_dir':yml_dict['core']['prior_dir'],\n",
    "                'Nens':str(prior_len)}\n",
    "    # save prior_variable_units\n",
    "    # asciiList = [n.encode(\"ascii\", \"ignore\") for n in strList]\n",
    "    # h5File.create_dataset('xxx', (len(asciiList),1),'S10', asciiList)\n",
    "    \n",
    "    f.attrs.update(metadata)\n",
    "# append proxy to hdf5 file\n",
    "proxies.to_hdf(hdf5name, key='proxies')\n",
    "print('>>  prior2proxyunit hdf5 file saved: {}'.format(hdf5name))\n",
    "print('>>  Step 1 finished. Run Step 2: DeepDA_main.ipynb now')\n",
    "print('>>  Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1296, 150)\n"
     ]
    }
   ],
   "source": [
    "print(Xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nansum([np.nan, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
