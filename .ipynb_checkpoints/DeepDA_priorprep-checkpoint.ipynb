{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Prepare prior for DeepDA\n",
    "\n",
    "OUTPUT:\n",
    "    example:\n",
    "    prior2proxyunit hdf5 file saved: /mnt/c/Users/mul450/Dropbox/git/deepDA/mlwrk/proxy/petmproxy3slices_v0.0.10gt1.csv.hdf5\n",
    "\n",
    "Mingsong Li\n",
    "1/15/2020\n",
    "'''\n",
    "from DeepDA_lib import modules_nc\n",
    "from DeepDA_lib import modules_psm_linear\n",
    "import h5py\n",
    "import time\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "try:\n",
    "    import bayspline\n",
    "except ImportError as e1:\n",
    "    print('Warning:', e1)\n",
    "try:\n",
    "    import bayspar\n",
    "except ImportError as e2:\n",
    "    print('Warning:', e2)\n",
    "try:\n",
    "    import bayfox\n",
    "except ImportError as e3:\n",
    "    print('Warning:', e3)\n",
    "try:\n",
    "    import baymag\n",
    "except ImportError as e4:\n",
    "    print('Warning:', e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_lon_offset = -180\n",
    "\n",
    "nc_file ='fields_biogem_2d.nc'\n",
    "#nc_field = 'ocn_sur_temp'\n",
    "t = 12  # last time slice, cGENIE\n",
    "k = 0   # first layer, SST\n",
    "\n",
    "f = open(\"DeepDA_config.yml\", 'r')\n",
    "yml_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "#print(yml_dict)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  Prior member size: 150\n",
      ">>  Number of prior variables is: 5. List:\n",
      "      ['ocn_sur_temp', 'atm_temp', 'atm_pCO2', 'ocn_sur_sal', 'ocn_ben_DIC_13C']\n",
      "    Shape of prior 2d grid (36, 36)\n",
      ">>  Last member: x.shape (36, 36)\n",
      "      149: ML.petm008.ID.9: ocn_sur_temp\n",
      ">>  Last member: x.shape (36, 36)\n",
      "      149: ML.petm008.ID.9: atm_temp\n",
      ">>  Last member: x.shape (36, 36)\n",
      "      149: ML.petm008.ID.9: atm_pCO2\n",
      ">>  Last member: x.shape (36, 36)\n",
      "      149: ML.petm008.ID.9: ocn_sur_sal\n",
      ">>  Last member: x.shape (36, 36)\n",
      "      149: ML.petm008.ID.9: ocn_ben_DIC_13C\n",
      ">>  OKAY. Xb ready, to be saved\n"
     ]
    }
   ],
   "source": [
    "# build Ye\n",
    "# If there is no field in the model, convert model unit to proxy unit\n",
    "\n",
    "dir_prior = yml_dict['core']['prior_dir']\n",
    "dir_prior_full = os.listdir(dir_prior)\n",
    "prior_len = len(dir_prior_full)\n",
    "#print('dir_prior: {}'.format(dir_prior))\n",
    "print('>>  Prior member size: {}'.format(prior_len))\n",
    "\n",
    "# prepare variable list for Xb\n",
    "prior_variable_dict = yml_dict['prior']['state_variables_info']\n",
    "prior_variable_len = len(prior_variable_dict)\n",
    "print('>>  Number of prior variables is: {}. List:'.format(prior_variable_len))\n",
    "print('      {}'.format(prior_variable_dict))\n",
    "\n",
    "# read first variable data, first time slice, to get the shape of prior grid\n",
    "x0 = Dataset(dir_prior+'/'+dir_prior_full[0]+'/'+nc_file).variables[prior_variable_dict[0]][0,:,:]\n",
    "print('    Shape of prior 2d grid {}'.format(x0.shape))\n",
    "dum_imax = x0.shape[0]  # lon\n",
    "dum_jmax = x0.shape[1]  # lat\n",
    "dum_ijmax = dum_imax*dum_jmax  # lonn * latn\n",
    "Xb_shape = (dum_ijmax*prior_variable_len, prior_len)  # lonn * latn * varn\n",
    "\n",
    "# read prior and save Xb\n",
    "#Xb = np.full((dum_ijmax, prior_len),np.nan)\n",
    "Xb = np.full(Xb_shape,np.nan)\n",
    "\n",
    "# loop for each member of a prior\n",
    "for i in range(prior_len):\n",
    "    name_nc = dir_prior+'/'+dir_prior_full[i]+'/'+nc_file\n",
    "    # loop for each variable of each member\n",
    "    for j in range(prior_variable_len):\n",
    "        j0 = dum_ijmax * j\n",
    "        j1 = dum_ijmax * (j+1)\n",
    "        nc_field = prior_variable_dict[j]\n",
    "        x = Dataset(name_nc).variables[nc_field][t,:,:]\n",
    "        \n",
    "        Xb[j0:j1,i] = x.reshape(dum_ijmax)\n",
    "        # print the last one data\n",
    "        if i > prior_len-2:\n",
    "            print('>>  Last member: x.shape {}'.format(x.shape))\n",
    "            print('      {}: {}: {}'.format(i, dir_prior_full[i], prior_variable_dict[j]))\n",
    "    #print(x)\n",
    "print('>>  OKAY. Xb ready, to be saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  recon_period 0 - 2. List: \n",
      "      [0 1 2]\n",
      ">>  OKAY.\n"
     ]
    }
   ],
   "source": [
    "# Now, prepare Ye\n",
    "# read config.yml settings\n",
    "dir_proxies = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['datadir_proxy'] +'/'+ yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['dbversion']\n",
    "proxy_psm_type = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_psm_type']\n",
    "proxy_assim2 = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['proxy_assim2']\n",
    "psm_d18osw_adjust = yml_dict['psm']['bayesreg_d18o_pooled']['psm_d18osw_adjust']\n",
    "#print(proxy_psm_type)\n",
    "#print(proxy_assim2)\n",
    "#print(psm_d18osw_adjust)\n",
    "data_period_id    = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['data_period_id']\n",
    "data_period_idstd = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['data_period_idstd']\n",
    "recon_period = yml_dict['core']['recon_period']\n",
    "recon_timescale = yml_dict['core']['recon_timescale_interval']\n",
    "recon_period_full = np.arange(recon_period[0],recon_period[1]+1,recon_timescale)\n",
    "recon_period_len = recon_period_full.shape[0]\n",
    "print('>>  recon_period {} - {}. List: '.format(recon_period[0], recon_period[1]))\n",
    "print('      {}'.format(recon_period_full))\n",
    "\n",
    "# read proxies database\n",
    "proxies = pandas.read_csv(dir_proxies)\n",
    "proxies_len = proxies.shape[0]\n",
    "\n",
    "# for saving proxy unit data Ye\n",
    "Ye       = np.full((proxies_len,prior_len),np.nan)\n",
    "Yevar    = np.full((proxies_len,prior_len),np.nan)\n",
    "obvalue  = np.full((proxies_len,recon_period_len),np.nan)\n",
    "ob_err   = np.full((proxies_len,recon_period_len),np.nan)\n",
    "print('>>  OKAY.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>  Data row 0, grid [lon lat] [18, 35], id 1278\n",
      "(150,)\n",
      "PSM for tex86 is bayesreg_tex86\n",
      ">>  bayesreg_tex86\n",
      ">>  id 0, Ye, first example [0.34970698 0.37306357 0.3362879  0.36570736 0.36444275 0.36125368\n",
      " 0.34395457 0.33602257 0.34064536 0.37008309]\n",
      ">>  id 0, Yevar, first example [0.00361887 0.00331821 0.00393469 0.00339721 0.00348944 0.00360821\n",
      " 0.0037488  0.00393938 0.00380695 0.00341618]\n",
      "[0.37319535        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "\n",
      ">>  Data row 1, grid [lon lat] [16, 29], id 1060\n",
      "(150,)\n",
      "PSM for d18o_m.subb is bayesreg_d18o_pooled\n",
      ">>  prediction_d18O.ensemble shape (150, 10000)\n",
      ">>  bayesreg_d18o_pooled\n",
      ">>  id 1, Ye, first example [-2.72533974 -2.91877863 -2.14718399 -2.90853384 -2.86401171 -2.77341891\n",
      " -2.47406199 -2.24562477 -2.32797808 -2.84585595]\n",
      ">>  id 1, Yevar, first example [0.29564533 0.29291655 0.3026987  0.29544975 0.2945149  0.30079429\n",
      " 0.29358001 0.29388169 0.29765818 0.30335835]\n",
      "[ 0.37319535 -2.93529643         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan]\n",
      "\n",
      ">>  Data row 2, grid [lon lat] [16, 29], id 1060\n",
      "(150,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-aa2989dc1e5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdata_psm_type_find\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Warning, this proxy type in database is not find in DTDA-config.yml dictionary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Warning, this proxy type in database appears more than 1 time in DTDA-config.yml dictionary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "# precal_Ye\n",
    "\n",
    "proi = 0\n",
    "for j in range(proxies_len):\n",
    "    # read lon lat for each line of proxy\n",
    "    dum_lat = proxies['Lat'][j]  # (paleo)latitude of this site\n",
    "    dum_lon = proxies['Lon'][j]  # (paleo)longitude of this site\n",
    "    lonlat = modules_nc.cal_find_ij(dum_lon,dum_lat,dum_lon_offset,dum_imax,dum_jmax) \n",
    "    \n",
    "    ######################## TO DO: including d13C or other proxies ##############\n",
    "    # find 1d grid location\n",
    "    lonlati = lonlat[1] * dum_jmax + lonlat[0]\n",
    "    # read prior\n",
    "    prior_1grid = np.copy(Xb[lonlati,:])   # prior\n",
    "    print('')\n",
    "    print('>>  Data row {}, grid [lon lat] {}, id {}'.format(j,lonlat,lonlati))\n",
    "    print(prior_1grid.shape)\n",
    "    ######################## TO DO: add  dum_ijmax * j etc. ##############\n",
    "    \n",
    "    #print(Xb[lonlati,i])\n",
    "    #print(name_nc)\n",
    "    #result = np.where(Xb[:,i] == Xb[lonlati,i])\n",
    "    #print(result)\n",
    "    \n",
    "    # Read proxy type from the database\n",
    "    data_psm_type = proxies['Proxy'][j]\n",
    "    # Read allowed proxy from the DTDA-config.yml\n",
    "    data_psm_type_find = 0\n",
    "    for key, value in proxy_assim2.items():\n",
    "        #print(key,value)\n",
    "        # find this proxy type exist or not, how many times it occurrs\n",
    "        if data_psm_type in proxy_assim2[key]:\n",
    "            data_psm_type_find = data_psm_type_find + 1\n",
    "    if data_psm_type_find == 1:\n",
    "        for key, value in proxy_psm_type.items():\n",
    "            if data_psm_type in proxy_assim2[key]:\n",
    "                data_psm_key = key\n",
    "        proxy_psm_type_i = proxy_psm_type[data_psm_key]\n",
    "        print('PSM for {} is {}'.format(data_psm_type,proxy_psm_type_i))\n",
    "        \n",
    "    elif data_psm_type_find == 0:\n",
    "        print('Warning, this proxy type in database is not find in DTDA-config.yml dictionary')\n",
    "    else:\n",
    "        print('Warning, this proxy type in database appears more than 1 time in DTDA-config.yml dictionary')\n",
    "    \n",
    "    \n",
    "    # Now PSM type has been found. Let's precal Ye\n",
    "    \n",
    "    if proxy_psm_type_i in ['bayesreg_d18o_pooled']:\n",
    "        # bayfox\n",
    "        d18o_localsw = modules_psm_linear.d18o_localsw(abs(dum_lat))\n",
    "        psm_d18osw_adjust = yml_dict['psm']['bayesreg_d18o_pooled']['psm_d18osw_adjust']\n",
    "        # total d18osw = d18o_localsw + d18o_adj + psm_d18osw_adjust\n",
    "        # d18o_adj has been included in the bayfox model\n",
    "        prediction_d18O = bayfox.predict_d18oc(prior_1grid,d18o_localsw+psm_d18osw_adjust) # pool model for bayfox\n",
    "        print('>>  prediction_d18O.ensemble shape {}'.format(prediction_d18O.ensemble.shape))\n",
    "        Ye[proi,:] = np.mean(prediction_d18O.ensemble, axis = 1)\n",
    "        Yevar[proi,:] = np.var(prediction_d18O.ensemble, axis = 1, ddof=1)\n",
    "        for reconi in range(recon_period_len):\n",
    "            obvalue[proi,reconi] = proxies[data_period_id[reconi]][j]\n",
    "            ob_err[proi,reconi] = proxies[data_period_idstd[reconi]][j] ** 2\n",
    "            #obvalue[proi,] = proxies['Lat'][j]\n",
    "        print('>>  bayesreg_d18o_pooled')\n",
    "        print('>>  id {}, Ye, first example {}'.format(proi,Ye[j,0:10]))\n",
    "        print('>>  id {}, Yevar, first example {}'.format(proi,Yevar[j,0:10]))\n",
    "        proi = proi + 1  # increasement\n",
    "        \n",
    "    elif proxy_psm_type_i in ['bayesreg_tex86']:\n",
    "        # bayfox\n",
    "        try:\n",
    "            # bayspar\n",
    "            search_tol_i = yml_dict['psm']['bayesreg_tex86']['search_tol']\n",
    "            nens_i = yml_dict['psm']['bayesreg_tex86']['nens']\n",
    "            prediction = bayspar.predict_tex_analog(prior_1grid, temptype = 'sst', search_tol = search_tol_i, nens=nens_i)\n",
    "            Ye[proi,:] = np.mean(prediction.ensemble, axis = 1)\n",
    "            Yevar[proi,:] = np.var(prediction.ensemble, axis = 1, ddof=1)\n",
    "            for reconi in range(recon_period_len):\n",
    "                obvalue[proi,reconi] = proxies[data_period_id[reconi]][j]\n",
    "                ob_err[proi,reconi] = proxies[data_period_idstd[reconi]][j] ** 2\n",
    "                #obvalue[proi,] = proxies['Lat'][j]\n",
    "            \n",
    "            print('>>  bayesreg_tex86')\n",
    "            print('>>  id {}, Ye, first example {}'.format(proi,Ye[j,0:10]))\n",
    "            print('>>  id {}, Yevar, first example {}'.format(proi,Yevar[j,0:10]))\n",
    "            proi = proi + 1  # increasement\n",
    "        except:\n",
    "            print('search_tol too small for {}: mean sst is {}'.format(ii, np.mean(sst)))\n",
    "    elif proxy_psm_type_i in ['bayesreg_uk37']:\n",
    "        # \n",
    "        a = 1\n",
    "    elif proxy_psm_type_i in ['bayesreg_mgca_pooled_red']:\n",
    "        #\n",
    "        a = 1\n",
    "    elif proxy_psm_type_i in ['bayesreg_mgca_pooled_bcp']:\n",
    "        #\n",
    "        a = 1\n",
    "    else:\n",
    "        a = 1\n",
    "    print(np.mean(Ye,axis=1))\n",
    "print('obvalue {},  ob_err {}'.format(obvalue, ob_err))\n",
    "print('>>  OKAY.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prior2proxyunit hdf5 file saved: /mnt/c/Users/mul450/Dropbox/git/deepDA/mlwrk/proxy/petmproxy3slices_v0.0.10gt3.csv.hdf5\n",
      "  Step 1 finished. Run Step 2: DeepDA_main.ipynb now\n",
      ">>  Done!\n"
     ]
    }
   ],
   "source": [
    "hdf5name = dir_proxies + '.hdf5'\n",
    "with h5py.File(hdf5name, 'w') as f:\n",
    "    #g = f.create_group('proxy')\n",
    "    #dset1 = g.create_dataset('data', data=proxies)\n",
    "    #g = f.create_group('prior2proxyunit')\n",
    "#    g = f.create_group('ML.petm004.SST')\n",
    "    f.create_dataset('Xb', data=Xb)\n",
    "    f.create_dataset('obvalue', data=obvalue)\n",
    "    f.create_dataset('Ye', data=np.transpose(Ye))\n",
    "    f.create_dataset('Yevar', data=np.transpose(Yevar))\n",
    "    f.create_dataset('ob_err', data=ob_err)\n",
    "    \n",
    "    #dset1 = g.create_dataset('Xb', data=Xb)\n",
    "    #dset2 = g.create_dataset('obvalue', data=obvalue)\n",
    "    #dset3 = g.create_dataset('Ye', data=Ye)\n",
    "    #dset4 = g.create_dataset('Yevar', data=Yevar)\n",
    "    #dset5 = g.create_dataset('ob_err', data=ob_err)\n",
    "\n",
    "    metadata = {'Date': time.time(),\n",
    "                'proxy_dbversion':yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['dbversion'],\n",
    "                'exp_dir':yml_dict['core']['prior_dir'],\n",
    "               'nc_file':nc_file,\n",
    "               'nc_field': nc_field,\n",
    "               'Nens':str(prior_len)}\n",
    "    f.attrs.update(metadata)\n",
    "print('  prior2proxyunit hdf5 file saved: {}'.format(hdf5name))\n",
    "print('  Step 1 finished. Run Step 2: DeepDA_main.ipynb now')\n",
    "print('>>  Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3888, 150)\n"
     ]
    }
   ],
   "source": [
    "print(Xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
