{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data assimilation for deep time\n",
    "Stage 1:    Prior: cGENIE only\n",
    "            Proxy: petmproxy3slices format database\n",
    "            PSM: bayesian proxy system model\n",
    "            DA: Mingsong Li, with LMR DA Core\n",
    "            \n",
    "            Mingsong Li\n",
    "            1/15/2020\n",
    "'''\n",
    "# Package\n",
    "import h5py\n",
    "import LMR_DA\n",
    "from lib import modules_nc\n",
    "from lib import modules_find_layer #.find_layer as find_layer\n",
    "from lib import modules_psm_linear\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import numpy.matlib as mat\n",
    "import scipy.stats as stats\n",
    "import pandas\n",
    "from sys import platform as sys_pf\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "if sys_pf == 'darwin':\n",
    "    import matplotlib\n",
    "    matplotlib.use(\"TkAgg\")\n",
    "    import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.basemap import Basemap, shiftgrid, cm\n",
    "\n",
    "try:\n",
    "    import bayspline\n",
    "except ImportError as e1:\n",
    "    print('Warning:', e1)\n",
    "try:\n",
    "    import bayspar\n",
    "except ImportError as e2:\n",
    "    print('Warning:', e2)\n",
    "try:\n",
    "    import bayfox\n",
    "except ImportError as e3:\n",
    "    print('Warning:', e3)\n",
    "try:\n",
    "    import baymag\n",
    "except ImportError as e4:\n",
    "    print('Warning:', e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read DTDA-config.yml\n",
    "f = open(\"DTDA-config.yml\", 'r')\n",
    "yml_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "loc=None\n",
    "dum_imax = 36  # lon\n",
    "dum_jmax = 36  # lat\n",
    "# ========= dataset for plot =========\n",
    "cGENIEGrid = yml_dict['core']['data_dir'] + '/data_misc/cGENIEGrid.csv'\n",
    "cGENIEGrid = pandas.read_csv(cGENIEGrid)\n",
    "#print(cGENIEGrid)\n",
    "cGENIEGridB_lat36 = cGENIEGrid['lat']\n",
    "cGENIEGridB_lon36 = cGENIEGrid['lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"obvalue\": shape (1, 3), type \"<f8\">\n",
      "recon intervals: 3, obser number 1\n",
      "recon intervals: 0, obser number 0\n",
      "-4.409823591726435\n",
      "0.5014141483029091\n",
      "obvalue -3.1044, mye -4.409823591726435, innov 1.3054235917264352\n",
      "[-2.9208903  -2.92892289 -2.9460591  -2.94903453 -2.94379304 -2.93678963\n",
      " -2.92748772 -2.91506768 -2.90378259 -2.89410571  0.         -3.02137897\n",
      " -3.01578927 -3.0202552  -2.98689168 -2.96039366]\n",
      "[1.56283980e+01 1.52720551e+01 1.49483772e+01 1.50130476e+01\n",
      " 1.48461373e+01 1.49580074e+01 1.50402823e+01 1.52286835e+01\n",
      " 1.56710208e+01 1.61733990e+01 9.96920997e+36 1.43326772e+01\n",
      " 1.47175994e+01 1.52907178e+01 1.54298405e+01 1.52353625e+01]\n",
      "[1.18153988e+01 1.14485700e+01 1.11025221e+01 1.11633083e+01\n",
      " 1.10032405e+01 1.11242529e+01 1.12186708e+01 1.14232853e+01\n",
      " 1.18803545e+01 1.23953652e+01 9.96920997e+36 1.03884979e+01\n",
      " 1.07807169e+01 1.13480055e+01 1.15306817e+01 1.13707948e+01]\n",
      "(1296, 150)\n",
      "recon intervals: 1, obser number 0\n",
      "-4.409823591726435\n",
      "0.5014141483029091\n",
      "obvalue -3.9734, mye -4.409823591726435, innov 0.4364235917264354\n",
      "[-2.9208903  -2.92892289 -2.9460591  -2.94903453 -2.94379304 -2.93678963\n",
      " -2.92748772 -2.91506768 -2.90378259 -2.89410571  0.         -3.02137897\n",
      " -3.01578927 -3.0202552  -2.98689168 -2.96039366]\n",
      "[1.56283980e+01 1.52720551e+01 1.49483772e+01 1.50130476e+01\n",
      " 1.48461373e+01 1.49580074e+01 1.50402823e+01 1.52286835e+01\n",
      " 1.56710208e+01 1.61733990e+01 9.96920997e+36 1.43326772e+01\n",
      " 1.47175994e+01 1.52907178e+01 1.54298405e+01 1.52353625e+01]\n",
      "[1.43536525e+01 1.39938040e+01 1.36626475e+01 1.37260193e+01\n",
      " 1.35613966e+01 1.36763231e+01 1.37626576e+01 1.39564792e+01\n",
      " 1.44037416e+01 1.49103430e+01 9.96920997e+36 1.30140762e+01\n",
      " 1.34014378e+01 1.39726072e+01 1.41262905e+01 1.39433769e+01]\n",
      "(1296, 150)\n",
      "recon intervals: 2, obser number 0\n",
      "-4.409823591726435\n",
      "0.5014141483029091\n",
      "obvalue -3.2864, mye -4.409823591726435, innov 1.1234235917264352\n",
      "[-2.9208903  -2.92892289 -2.9460591  -2.94903453 -2.94379304 -2.93678963\n",
      " -2.92748772 -2.91506768 -2.90378259 -2.89410571  0.         -3.02137897\n",
      " -3.01578927 -3.0202552  -2.98689168 -2.96039366]\n",
      "[1.56283980e+01 1.52720551e+01 1.49483772e+01 1.50130476e+01\n",
      " 1.48461373e+01 1.49580074e+01 1.50402823e+01 1.52286835e+01\n",
      " 1.56710208e+01 1.61733990e+01 9.96920997e+36 1.43326772e+01\n",
      " 1.47175994e+01 1.52907178e+01 1.54298405e+01 1.52353625e+01]\n",
      "[1.23470009e+01 1.19816340e+01 1.16387049e+01 1.17000326e+01\n",
      " 1.15390108e+01 1.16587486e+01 1.17514735e+01 1.19538277e+01\n",
      " 1.24088430e+01 1.29220924e+01 9.96920997e+36 1.09383888e+01\n",
      " 1.13295906e+01 1.18976919e+01 1.20742960e+01 1.19095865e+01]\n",
      "(1296, 150)\n",
      "start writing netCDF\n",
      "end writing netCDF\n",
      "All Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nexp = yml_dict['core']['nexp']\n",
    "nens = yml_dict['core']['nens']\n",
    "datadir_output = yml_dict['core']['datadir_output']\n",
    "recon_period = yml_dict['core']['recon_period']\n",
    "recon_timescale = yml_dict['core']['recon_timescale_interval']\n",
    "recon_period_full = np.arange(recon_period[0],recon_period[1]+1,recon_timescale)\n",
    "recon_period_len = recon_period_full.shape[0]\n",
    "\n",
    "# for saving DA product Xa\n",
    "Xa_output   = np.full((dum_imax, dum_jmax,nens,recon_period_len),np.nan)\n",
    "\n",
    "# NetCDF file name\n",
    "nc_filename = datadir_output + '/' + nexp + '.nc'\n",
    "# read preprior HDF5 file\n",
    "dir_proxies = yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['datadir_proxy'] +'/'+ yml_dict['proxies'][yml_dict['proxies']['use_from'][0]]['dbversion']\n",
    "hdf5name = dir_proxies + '.hdf5'\n",
    "\n",
    "with h5py.File(hdf5name, 'r') as f:\n",
    "    Xb = f.get('Xb')\n",
    "    #Xb = ma.masked_where(Xb>9.9e+36, Xb)\n",
    "    obvalue_full = f.get('obvalue')\n",
    "    Ye_full = f.get('Ye')\n",
    "    ob_err_full = f.get('ob_err')\n",
    "    Yevar = f.get('Yevar')\n",
    "    #print(Xb.shape) # (1296, 150)\n",
    "    #print(Ye_full.shape) # (150, 1)\n",
    "    print(obvalue_full)\n",
    "    ob_len = obvalue_full.shape[0]\n",
    "    print('recon intervals: {}, obser number {}'.format(recon_period_len,ob_len))\n",
    "    for reconi in range(recon_period_len):\n",
    "        for obi in range(ob_len):\n",
    "            print('recon intervals: {}, obser number {}'.format(reconi,obi))\n",
    "            obvalue  = obvalue_full[obi, reconi]\n",
    "            ob_err= ob_err_full[obi, reconi]\n",
    "            Ye = Ye_full[:,obi]\n",
    "            #Xa = LMR_DA.enkf_update_array(Xb, obm, Ye, obvar)\n",
    "            \n",
    "            # Get ensemble size from passed array: Xb has dims [state vect.,ens. members]\n",
    "            Nens = Xb.shape[1]\n",
    "            # ensemble mean background and perturbations\n",
    "            xbm = np.mean(Xb,axis=1)\n",
    "            Xbp = np.subtract(Xb,xbm[:,None])  # \"None\" means replicate in this dimension\n",
    "            #print(xbm.shape)  #  (1296,)  cGENIE\n",
    "            #print(Xbp.shape)  # (1296, 150)  cGENIE\n",
    "            # ensemble mean and variance of the background estimate of the proxy\n",
    "            mye   = np.mean(Ye)\n",
    "            varye = np.var(Ye,ddof=1)\n",
    "            print(mye)    # -4.410062826814151\n",
    "            print(varye)  # 0.5017489599276731\n",
    "            # lowercase ye has ensemble-mean removed \n",
    "            ye = np.subtract(Ye, mye)\n",
    "            # innovation\n",
    "            try:\n",
    "                innov = obvalue - mye\n",
    "            except:\n",
    "                print('innovation error. obvalue = ' + str(obvalue) + ' mye = ' + str(mye))\n",
    "                print('returning Xb unchanged...')\n",
    "                #return Xb\n",
    "            # innovation variance (denominator of serial Kalman gain)\n",
    "            kdenom = (varye + ob_err)  \n",
    "            #print('kdenom {}'.format(kdenom)) # 0.5622579034828427\n",
    "            # numerator of serial Kalman gain (cov(x,Hx))\n",
    "            kcov = np.dot(Xbp,np.transpose(ye)) / (Nens-1)\n",
    "            # Option to localize the gain\n",
    "            if loc is not None:\n",
    "                kcov = np.multiply(kcov,loc) \n",
    "            #print(kcov[36:72])\n",
    "            #print(kcov.shape)  # (1296, 1)\n",
    "            # Kalman gain\n",
    "            kmat = np.divide(kcov, kdenom)\n",
    "            \n",
    "            #print(kmat.shape)  # (1296, 1)\n",
    "            # update ensemble mean\n",
    "            xam = xbm + np.multiply(kmat,innov)\n",
    "            #print(xbm.shape)\n",
    "            #print(xam.shape)\n",
    "            print('obvalue {}, mye {}, innov {}'.format(obvalue, mye, innov))\n",
    "            print(kmat[36:52])\n",
    "            print(xbm[36:52])\n",
    "            print(xam[36:52])\n",
    "            \n",
    "            # update the ensemble members using the square-root approach\n",
    "            beta = 1./(1. + np.sqrt(ob_err/(varye+ob_err)))\n",
    "            kmat = np.multiply(beta,kmat)\n",
    "            ye   = np.array(ye)[np.newaxis]\n",
    "            kmat = np.array(kmat)[np.newaxis]\n",
    "            Xap  = Xbp - np.dot(kmat.T, ye)\n",
    "\n",
    "            # full state\n",
    "            Xa = np.add(xam[:,None], Xap)\n",
    "            print(Xa.shape)\n",
    "            # if masked array, making sure that fill_value = nan in the new array \n",
    "            if np.ma.isMaskedArray(Xa): \n",
    "                np.ma.set_fill_value(Xa, np.nan)\n",
    "            \n",
    "        Xa_output[:,:,:,reconi] = Xa.reshape(dum_imax,dum_jmax,nens)\n",
    "\n",
    "    print('start writing netCDF')\n",
    "    nf = Dataset(nc_filename, 'w', format='NETCDF4')\n",
    "\n",
    "    #Add global attributes\n",
    "    nf.description = 'DTDA' + nc_filename\n",
    "\n",
    "    #create a group\n",
    "    tempgrp = nf.createGroup('DA-sst')\n",
    "    #Specifying dimensions\n",
    "    tempgrp.createDimension('lon', len(cGENIEGridB_lat36))\n",
    "    tempgrp.createDimension('lat', len(cGENIEGridB_lon36))\n",
    "    z = np.arange(0,1,1)\n",
    "    tempgrp.createDimension('z', len(z))  # level\n",
    "    tempgrp.createDimension('nens', nens)  # number of ens\n",
    "    tempgrp.createDimension('time', recon_period_len)\n",
    "\n",
    "    # Building variables\n",
    "    longitude = tempgrp.createVariable('Longitude', 'f4', 'lon')\n",
    "    # Passing data into variables\n",
    "    longitude[:] = cGENIEGridB_lon36.values\n",
    "    \n",
    "    latitude = tempgrp.createVariable('Latitude', 'f4', 'lat')\n",
    "    latitude[:] = cGENIEGridB_lat36.values\n",
    "    \n",
    "    levels = tempgrp.createVariable('Levels', 'i4', 'z')\n",
    "    levels[:] = z\n",
    "    \n",
    "    XbNC_mean = tempgrp.createVariable('Xb_mean', 'f4', ('lat', 'lon','z'))\n",
    "    XbNC_mean[:,:,:] = xbm.reshape(dum_jmax,dum_imax,1)\n",
    "    \n",
    "    XbNC_variance = tempgrp.createVariable('Xb_variance', 'f4', ('lat', 'lon','z'))\n",
    "    XbNC_variance[:,:,:] = np.nanvar(Xbp,axis=1).reshape(dum_jmax,dum_imax,1)\n",
    "    \n",
    "    XaNC_mean = tempgrp.createVariable('Xa_mean', 'f4', ('lat', 'lon','z','time'))\n",
    "    XaNC_mean[:,:,:,:] = np.nanmean(Xa_output,axis=2).reshape(dum_jmax,dum_imax,1,recon_period_len)\n",
    "    \n",
    "    XaNC_variance = tempgrp.createVariable('Xa_variance', 'f4', ('lat', 'lon','z','time'))\n",
    "    XaNC_variance[:,:,:,:] = np.nanvar(Xa_output,axis=2).reshape(dum_jmax,dum_imax,1,recon_period_len)\n",
    "    \n",
    "    #XbNC_full = tempgrp.createVariable('Xb_full', 'f4', ('lat', 'lon', 'nens', 'z'))\n",
    "    #XbNC_full[:,:,:,:] = Xb.reshape(dum_jmax,dum_imax,nens,1)\n",
    "    \n",
    "    XaNC_full = tempgrp.createVariable('Xa_full', 'f4', ('lat', 'lon', 'nens', 'z','time'))\n",
    "    XaNC_full[:,:,:,:,:] = Xa_output.reshape(dum_jmax,dum_imax,nens,1,recon_period_len)\n",
    "    #redvarvalue = tempgrp.createVariable('reducedvariance', 'f4', 'time')\n",
    "    #nestbestid = tempgrp.createVariable('Time', 'i4', 'time')\n",
    "\n",
    "    #redvarvalue[:] = XavbsumMax[:]\n",
    "    #nestbestid = site_id    \n",
    "    \n",
    "    #Add local attributes to variable instances\n",
    "    longitude.units = 'degrees east'\n",
    "    latitude.units = 'degrees north'\n",
    "    levels.units = 'layer'\n",
    "    XbNC_mean.units = 'degC'\n",
    "    XbNC_variance.units = 'degC^2'\n",
    "    XbNC_full.units = 'degC'\n",
    "    XaNC_full.units = 'degC'\n",
    "    #variance.warning = 'test ...'\n",
    "    # Closing the dataset\n",
    "    nf.close()  # close the new file\n",
    "    print('end writing netCDF')\n",
    "print('All Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nf.close()  # close the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 36, 1, 3)\n",
      "(36, 36)\n",
      "26.228313\n",
      "1.5360518\n",
      "(36, 36, 1, 3)\n",
      "(36, 36)\n",
      "28.597527\n",
      "1.5360518\n",
      "(36, 36, 1, 3)\n",
      "(36, 36)\n",
      "26.724512\n",
      "1.5360518\n"
     ]
    }
   ],
   "source": [
    "nf = Dataset(nc_filename, 'r', format='NETCDF4')\n",
    "XaNC_mean = nf['DA-sst'].variables['Xa_mean']\n",
    "XaNC_variance = nf['DA-sst'].variables['Xa_variance']\n",
    "for reconi in range(recon_period_len):\n",
    "    Xam1 = XaNC_mean[:,:,0,reconi]\n",
    "    #Xam1 = Xam1.reshape(dum_jmax*dum_imax,1)\n",
    "    XaNC_var1 = XaNC_variance[:,:,0,reconi]\n",
    "    #XaNC_var1 = XaNC_var1.reshape(dum_jmax*dum_imax,1)\n",
    "    print(XaNC_mean.shape)\n",
    "    print(Xam1.shape)\n",
    "    print(np.nanmean(Xam1))\n",
    "    print(np.sqrt(np.nanmean(XaNC_var1)))\n",
    "nf.close()  # close the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
